SLURM_JOB_ID: 58071924
SLURM_JOB_USER: vsc37331
SLURM_JOB_ACCOUNT: intro_vsc37331
SLURM_JOB_NAME: GCN_Long_lc
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: batch
SLURM_NNODES: 1
SLURM_NODELIST: r25i13n23
SLURM_JOB_CPUS_PER_NODE: 16
Date: Wed Apr 16 12:15:51 CEST 2025
Walltime: 00-02:30:00
========================================================================
Collecting pip
  Using cached pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)
Collecting wheel
  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)
Using cached pip-25.0.1-py3-none-any.whl (1.8 MB)
Using cached wheel-0.45.1-py3-none-any.whl (72 kB)
Installing collected packages: wheel, pip
  Attempting uninstall: pip
    Found existing installation: pip 21.1.1
    Uninstalling pip-21.1.1:
      Successfully uninstalled pip-21.1.1
Successfully installed pip-25.0.1 wheel-0.45.1
Collecting numpy==1.22.4
  Using cached numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)
Using cached numpy-1.22.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)
Installing collected packages: numpy
Successfully installed numpy-1.22.4
Collecting scipy==1.7.0
  Using cached scipy-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (2.2 kB)
Requirement already satisfied: numpy<1.23.0,>=1.16.5 in ./gcn_env/lib/python3.9/site-packages (from scipy==1.7.0) (1.22.4)
Using cached scipy-1.7.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)
Installing collected packages: scipy
Successfully installed scipy-1.7.0
Collecting pandas==2.0.3
  Using cached pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)
Collecting python-dateutil>=2.8.2 (from pandas==2.0.3)
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas==2.0.3)
  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.1 (from pandas==2.0.3)
  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)
Requirement already satisfied: numpy>=1.20.3 in ./gcn_env/lib/python3.9/site-packages (from pandas==2.0.3) (1.22.4)
Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.0.3)
  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)
Using cached pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)
Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)
Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)
Installing collected packages: pytz, tzdata, six, python-dateutil, pandas
Successfully installed pandas-2.0.3 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2
Collecting scikit-learn==1.3.2
  Using cached scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)
Requirement already satisfied: numpy<2.0,>=1.17.3 in ./gcn_env/lib/python3.9/site-packages (from scikit-learn==1.3.2) (1.22.4)
Requirement already satisfied: scipy>=1.5.0 in ./gcn_env/lib/python3.9/site-packages (from scikit-learn==1.3.2) (1.7.0)
Collecting joblib>=1.1.1 (from scikit-learn==1.3.2)
  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)
Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.3.2)
  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Using cached scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)
Using cached joblib-1.4.2-py3-none-any.whl (301 kB)
Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Installing collected packages: threadpoolctl, joblib, scikit-learn
Successfully installed joblib-1.4.2 scikit-learn-1.3.2 threadpoolctl-3.6.0
Collecting matplotlib==3.4.2
  Using cached matplotlib-3.4.2-cp39-cp39-manylinux1_x86_64.whl.metadata (5.7 kB)
Collecting cycler>=0.10 (from matplotlib==3.4.2)
  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting kiwisolver>=1.0.1 (from matplotlib==3.4.2)
  Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)
Requirement already satisfied: numpy>=1.16 in ./gcn_env/lib/python3.9/site-packages (from matplotlib==3.4.2) (1.22.4)
Collecting pillow>=6.2.0 (from matplotlib==3.4.2)
  Using cached pillow-11.2.1-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (8.9 kB)
Collecting pyparsing>=2.2.1 (from matplotlib==3.4.2)
  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)
Requirement already satisfied: python-dateutil>=2.7 in ./gcn_env/lib/python3.9/site-packages (from matplotlib==3.4.2) (2.9.0.post0)
Requirement already satisfied: six>=1.5 in ./gcn_env/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib==3.4.2) (1.17.0)
Using cached matplotlib-3.4.2-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)
Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)
Using cached kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
Using cached pillow-11.2.1-cp39-cp39-manylinux_2_28_x86_64.whl (4.6 MB)
Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)
Installing collected packages: pyparsing, pillow, kiwisolver, cycler, matplotlib
Successfully installed cycler-0.12.1 kiwisolver-1.4.7 matplotlib-3.4.2 pillow-11.2.1 pyparsing-3.2.3
Collecting tabulate==0.9.0
  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)
Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)
Installing collected packages: tabulate
Successfully installed tabulate-0.9.0
Collecting datetime==4.3
  Using cached DateTime-4.3-py2.py3-none-any.whl.metadata (30 kB)
Requirement already satisfied: pytz in ./gcn_env/lib/python3.9/site-packages (from datetime==4.3) (2025.2)
Collecting zope.interface (from datetime==4.3)
  Using cached zope.interface-7.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)
Requirement already satisfied: setuptools in ./gcn_env/lib/python3.9/site-packages (from zope.interface->datetime==4.3) (56.0.0)
Using cached DateTime-4.3-py2.py3-none-any.whl (60 kB)
Using cached zope.interface-7.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253 kB)
Installing collected packages: zope.interface, datetime
Successfully installed datetime-4.3 zope.interface-7.2
Collecting EMP-PY==2.0.4
  Using cached EMP_PY-2.0.4-py3-none-any.whl.metadata (1.8 kB)
Requirement already satisfied: numpy in ./gcn_env/lib/python3.9/site-packages (from EMP-PY==2.0.4) (1.22.4)
Requirement already satisfied: pandas in ./gcn_env/lib/python3.9/site-packages (from EMP-PY==2.0.4) (2.0.3)
Requirement already satisfied: scipy in ./gcn_env/lib/python3.9/site-packages (from EMP-PY==2.0.4) (1.7.0)
Requirement already satisfied: scikit-learn in ./gcn_env/lib/python3.9/site-packages (from EMP-PY==2.0.4) (1.3.2)
Requirement already satisfied: python-dateutil>=2.8.2 in ./gcn_env/lib/python3.9/site-packages (from pandas->EMP-PY==2.0.4) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./gcn_env/lib/python3.9/site-packages (from pandas->EMP-PY==2.0.4) (2025.2)
Requirement already satisfied: tzdata>=2022.1 in ./gcn_env/lib/python3.9/site-packages (from pandas->EMP-PY==2.0.4) (2025.2)
Requirement already satisfied: joblib>=1.1.1 in ./gcn_env/lib/python3.9/site-packages (from scikit-learn->EMP-PY==2.0.4) (1.4.2)
Requirement already satisfied: threadpoolctl>=2.0.0 in ./gcn_env/lib/python3.9/site-packages (from scikit-learn->EMP-PY==2.0.4) (3.6.0)
Requirement already satisfied: six>=1.5 in ./gcn_env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->EMP-PY==2.0.4) (1.17.0)
Using cached EMP_PY-2.0.4-py3-none-any.whl (17 kB)
Installing collected packages: EMP-PY
Successfully installed EMP-PY-2.0.4
Collecting networkx==3.1
  Using cached networkx-3.1-py3-none-any.whl.metadata (5.3 kB)
Using cached networkx-3.1-py3-none-any.whl (2.1 MB)
Installing collected packages: networkx
Successfully installed networkx-3.1
Collecting torch==2.6.0
  Using cached torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl.metadata (28 kB)
Collecting filelock (from torch==2.6.0)
  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions>=4.10.0 (from torch==2.6.0)
  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)
Requirement already satisfied: networkx in ./gcn_env/lib/python3.9/site-packages (from torch==2.6.0) (3.1)
Collecting jinja2 (from torch==2.6.0)
  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.6.0)
  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)
Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0)
  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0)
  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0)
  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0)
  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0)
  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0)
  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0)
  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0)
  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0)
  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0)
  Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)
Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0)
  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0)
  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)
Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0)
  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting triton==3.2.0 (from torch==2.6.0)
  Using cached triton-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)
Collecting sympy==1.13.1 (from torch==2.6.0)
  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.6.0)
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.6.0)
  Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)
Using cached torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl (766.7 MB)
Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)
Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)
Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)
Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)
Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)
Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)
Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)
Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)
Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)
Using cached nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)
Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)
Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)
Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)
Using cached triton-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)
Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)
Using cached filelock-3.18.0-py3-none-any.whl (16 kB)
Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)
Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached MarkupSafe-3.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Installing collected packages: triton, nvidia-cusparselt-cu12, mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch
Successfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.3.2 jinja2-3.1.6 mpmath-1.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0 typing-extensions-4.13.2
Looking in links: https://pytorch-geometric.com/whl/torch-2.6.0+cu121.html
Collecting torch-scatter
  Using cached torch_scatter-2.1.2-cp39-cp39-linux_x86_64.whl
Collecting torch-sparse
  Using cached torch_sparse-0.6.18-cp39-cp39-linux_x86_64.whl
Collecting torch-cluster
  Using cached https://data.pyg.org/whl/torch-2.6.0%2Bcu121/torch_cluster-1.6.3%2Bpt26cu121-cp39-cp39-linux_x86_64.whl (3.4 MB)
Collecting torch-spline-conv
  Using cached torch_spline_conv-1.2.2-cp39-cp39-linux_x86_64.whl
Requirement already satisfied: scipy in ./gcn_env/lib/python3.9/site-packages (from torch-sparse) (1.7.0)
Requirement already satisfied: numpy<1.23.0,>=1.16.5 in ./gcn_env/lib/python3.9/site-packages (from scipy->torch-sparse) (1.22.4)
Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster
Successfully installed torch-cluster-1.6.3+pt26cu121 torch-scatter-2.1.2 torch-sparse-0.6.18 torch-spline-conv-1.2.2
Collecting torch-geometric==2.6.1
  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)
Collecting aiohttp (from torch-geometric==2.6.1)
  Using cached aiohttp-3.11.16-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Requirement already satisfied: fsspec in ./gcn_env/lib/python3.9/site-packages (from torch-geometric==2.6.1) (2025.3.2)
Requirement already satisfied: jinja2 in ./gcn_env/lib/python3.9/site-packages (from torch-geometric==2.6.1) (3.1.6)
Requirement already satisfied: numpy in ./gcn_env/lib/python3.9/site-packages (from torch-geometric==2.6.1) (1.22.4)
Collecting psutil>=5.8.0 (from torch-geometric==2.6.1)
  Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)
Requirement already satisfied: pyparsing in ./gcn_env/lib/python3.9/site-packages (from torch-geometric==2.6.1) (3.2.3)
Collecting requests (from torch-geometric==2.6.1)
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting tqdm (from torch-geometric==2.6.1)
  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->torch-geometric==2.6.1)
  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)
Collecting aiosignal>=1.1.2 (from aiohttp->torch-geometric==2.6.1)
  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)
Collecting async-timeout<6.0,>=4.0 (from aiohttp->torch-geometric==2.6.1)
  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)
Collecting attrs>=17.3.0 (from aiohttp->torch-geometric==2.6.1)
  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->torch-geometric==2.6.1)
  Using cached frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->torch-geometric==2.6.1)
  Using cached multidict-6.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)
Collecting propcache>=0.2.0 (from aiohttp->torch-geometric==2.6.1)
  Using cached propcache-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)
Collecting yarl<2.0,>=1.17.0 (from aiohttp->torch-geometric==2.6.1)
  Using cached yarl-1.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (71 kB)
Requirement already satisfied: MarkupSafe>=2.0 in ./gcn_env/lib/python3.9/site-packages (from jinja2->torch-geometric==2.6.1) (3.0.2)
Collecting charset-normalizer<4,>=2 (from requests->torch-geometric==2.6.1)
  Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)
Collecting idna<4,>=2.5 (from requests->torch-geometric==2.6.1)
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests->torch-geometric==2.6.1)
  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests->torch-geometric==2.6.1)
  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)
Requirement already satisfied: typing-extensions>=4.1.0 in ./gcn_env/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric==2.6.1) (4.13.2)
Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)
Using cached psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)
Using cached aiohttp-3.11.16-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)
Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)
Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)
Using cached attrs-25.3.0-py3-none-any.whl (63 kB)
Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)
Using cached charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)
Using cached frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached multidict-6.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)
Using cached propcache-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209 kB)
Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)
Using cached yarl-1.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (336 kB)
Installing collected packages: urllib3, tqdm, psutil, propcache, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, requests, aiosignal, aiohttp, torch-geometric
Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.1.31 charset-normalizer-3.4.1 frozenlist-1.5.0 idna-3.10 multidict-6.4.3 propcache-0.3.1 psutil-7.0.0 requests-2.32.3 torch-geometric-2.6.1 tqdm-4.67.1 urllib3-2.4.0 yarl-1.19.0
Package                  Version
------------------------ ---------------
aiohappyeyeballs         2.6.1
aiohttp                  3.11.16
aiosignal                1.3.2
async-timeout            5.0.1
attrs                    25.3.0
certifi                  2025.1.31
charset-normalizer       3.4.1
cycler                   0.12.1
DateTime                 4.3
EMP-PY                   2.0.4
filelock                 3.18.0
frozenlist               1.5.0
fsspec                   2025.3.2
idna                     3.10
Jinja2                   3.1.6
joblib                   1.4.2
kiwisolver               1.4.7
MarkupSafe               3.0.2
matplotlib               3.4.2
mpmath                   1.3.0
multidict                6.4.3
networkx                 3.1
numpy                    1.22.4
nvidia-cublas-cu12       12.4.5.8
nvidia-cuda-cupti-cu12   12.4.127
nvidia-cuda-nvrtc-cu12   12.4.127
nvidia-cuda-runtime-cu12 12.4.127
nvidia-cudnn-cu12        9.1.0.70
nvidia-cufft-cu12        11.2.1.3
nvidia-curand-cu12       10.3.5.147
nvidia-cusolver-cu12     11.6.1.9
nvidia-cusparse-cu12     12.3.1.170
nvidia-cusparselt-cu12   0.6.2
nvidia-nccl-cu12         2.21.5
nvidia-nvjitlink-cu12    12.4.127
nvidia-nvtx-cu12         12.4.127
pandas                   2.0.3
pillow                   11.2.1
pip                      25.0.1
propcache                0.3.1
psutil                   7.0.0
pyparsing                3.2.3
python-dateutil          2.9.0.post0
pytz                     2025.2
requests                 2.32.3
scikit-learn             1.3.2
scipy                    1.7.0
setuptools               56.0.0
six                      1.17.0
sympy                    1.13.1
tabulate                 0.9.0
threadpoolctl            3.6.0
torch                    2.6.0
torch_cluster            1.6.3+pt26cu121
torch-geometric          2.6.1
torch-scatter            2.1.2
torch-sparse             0.6.18
torch-spline-conv        1.2.2
tqdm                     4.67.1
triton                   3.2.0
typing_extensions        4.13.2
tzdata                   2025.2
urllib3                  2.4.0
wheel                    0.45.1
yarl                     1.19.0
zope.interface           7.2
[Checkpoint] All libraries imported successfully.
[Checkpoint] Configuration initialized
[Checkpoint] Using device: cpu
[Checkpoint] Working directory set to: /vsc-hard-mounts/leuven-data/373/vsc37331/Mobile_Vikings
[Checkpoint] ====== Script Started ======
[Checkpoint] ====== Starting Experiment setup ======
[Checkpoint] Identified 14055 users who churned in month 1
[Checkpoint] Loading training data with RMF features and dual edge weights
[Checkpoint] Loaded RMF, both edge types (c and l), and label data
[Checkpoint] Starting remove_nodes_and_create_data
[Checkpoint] Mapped 168351 node indices to USRs
[Checkpoint] Keeping all users including first month churners
[Checkpoint] Keeping all edges including those involving first month churners
[Checkpoint] Created mapping for 168351 users
[Checkpoint] Extracted call count weights with min=1, max=43452
[Checkpoint] Extracted call duration weights with min=4.000007, max=846610.283728
[Checkpoint] Created undirected edge index with shape: torch.Size([2, 1351754])
[Checkpoint] Created edge attributes with shape: torch.Size([1351754, 2])
[Checkpoint] Remaining feature columns: ['R_on', 'M_60_on', 'F_60_on', 'numDialing_60_on', 'numDialed_60_on']
[Checkpoint] Node feature tensor shape: torch.Size([168351, 5])
[Checkpoint] Label tensor shape: torch.Size([168351])
[Checkpoint] Label distribution: tensor([158126,  10225])
[Checkpoint] Created Data object with 168351 nodes, 1351754 edges, 5 features, and 2D edge attributes
[Checkpoint] Class distribution - Positives: 10225, Negatives: 158126
[Checkpoint] Loading validation data with RMF features and dual edge weights
[Checkpoint] Loaded RMF, both edge types (c and l), and label data
[Checkpoint] Starting remove_nodes_and_create_data
[Checkpoint] Mapped 168351 node indices to USRs
[Checkpoint] Keeping all users including first month churners
[Checkpoint] Keeping all edges including those involving first month churners
[Checkpoint] Created mapping for 168351 users
[Checkpoint] Extracted call count weights with min=1, max=39401
[Checkpoint] Extracted call duration weights with min=4.001433, max=938130.354898
[Checkpoint] Created undirected edge index with shape: torch.Size([2, 1315470])
[Checkpoint] Created edge attributes with shape: torch.Size([1315470, 2])
[Checkpoint] Remaining feature columns: ['R_on', 'M_60_on', 'F_60_on', 'numDialing_60_on', 'numDialed_60_on']
[Checkpoint] Node feature tensor shape: torch.Size([168351, 5])
[Checkpoint] Label tensor shape: torch.Size([168351])
[Checkpoint] Label distribution: tensor([155114,  13237])
[Checkpoint] Created Data object with 168351 nodes, 1315470 edges, 5 features, and 2D edge attributes
[Checkpoint] Loading test data with RMF features and dual edge weights
[Checkpoint] Loaded RMF, both edge types (c and l), and label data
[Checkpoint] Starting remove_nodes_and_create_data
[Checkpoint] Mapped 168351 node indices to USRs
[Checkpoint] Keeping all users including first month churners
[Checkpoint] Keeping all edges including those involving first month churners
[Checkpoint] Created mapping for 168351 users
[Checkpoint] Extracted call count weights with min=1, max=36743
[Checkpoint] Extracted call duration weights with min=4.001366, max=903198.693943
[Checkpoint] Created undirected edge index with shape: torch.Size([2, 1300608])
[Checkpoint] Created edge attributes with shape: torch.Size([1300608, 2])
[Checkpoint] Remaining feature columns: ['R_on', 'M_60_on', 'F_60_on', 'numDialing_60_on', 'numDialed_60_on']
[Checkpoint] Node feature tensor shape: torch.Size([168351, 5])
[Checkpoint] Label tensor shape: torch.Size([168351])
[Checkpoint] Label distribution: tensor([132605,  35746])
[Checkpoint] Created Data object with 168351 nodes, 1300608 edges, 5 features, and 2D edge attributes
[Checkpoint] Experiment initialization complete
[Checkpoint] ====== Starting Hyperparameter Tuning ======
[Checkpoint] Number of input features: 5
[Checkpoint] Testing 3×3×2×2×2 combinations

[Checkpoint] ====== Configuration 1/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.158946

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.150736

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.140950

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.129170

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.115248
[Checkpoint] Validation metrics - AUC: 0.588295, AUPRC: 0.095974, Loss: 0.103345
[Checkpoint] Validation lifts - @0.5%: 0.589786, @1%: 1.148644, @5%: 0.920208, @10%: 1.315261
[Checkpoint] New best model found! AUPRC: 0.095974 (previous best: 0.000000)

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.099888

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.084591

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.071213

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.061578

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.056456
[Checkpoint] Validation metrics - AUC: 0.580878, AUPRC: 0.094077, Loss: 0.074183
[Checkpoint] Validation lifts - @0.5%: 0.362945, @1%: 1.095746, @5%: 0.788750, @10%: 1.284287

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.054920

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.055648

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.056529

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.056130

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.054203
[Checkpoint] Validation metrics - AUC: 0.574944, AUPRC: 0.092092, Loss: 0.101491
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.604550, @5%: 0.607428, @10%: 1.259356

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.051345

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.048859

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.047508

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.047183

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.045193
[Checkpoint] Validation metrics - AUC: 0.563634, AUPRC: 0.087896, Loss: 0.112782
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.015114, @5%: 0.338467, @10%: 0.943573

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.042307

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.038781

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.035532

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.032945

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.030402
[Checkpoint] Validation metrics - AUC: 0.544662, AUPRC: 0.083079, Loss: 0.115541
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.024176, @10%: 0.502383

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.027600

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.024574

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.021695

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.018972

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.016280
[Checkpoint] Validation metrics - AUC: 0.536150, AUPRC: 0.081154, Loss: 0.124020
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.000000, @10%: 0.294630

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.013989

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.011747

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.010118

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.009029

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.008083
[Checkpoint] Validation metrics - AUC: 0.518134, AUPRC: 0.077141, Loss: 0.144990
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.000000, @10%: 0.235704

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.007356

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.006650

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.006253

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.005832

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.005578
[Checkpoint] Validation metrics - AUC: 0.520298, AUPRC: 0.077580, Loss: 0.167528
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.000000, @10%: 0.580951

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.005334

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.005005

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.004739

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.004473

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.004214
[Checkpoint] Validation metrics - AUC: 0.505391, AUPRC: 0.074996, Loss: 0.212010
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.004533, @10%: 0.659519

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.003971

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.095974

[Checkpoint] ====== Configuration 2/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 3/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.113156

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.107452

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.101488

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.094026

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.085410
[Checkpoint] Validation metrics - AUC: 0.585779, AUPRC: 0.095936, Loss: 0.081800
[Checkpoint] Validation lifts - @0.5%: 0.514173, @1%: 1.133531, @5%: 0.935318, @10%: 1.316016

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.076677

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.068191

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.061562

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.057490

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.055670
[Checkpoint] Validation metrics - AUC: 0.581170, AUPRC: 0.093947, Loss: 0.088987
[Checkpoint] Validation lifts - @0.5%: 0.287332, @1%: 1.088189, @5%: 0.705644, @10%: 1.304684

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.055138

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.054378

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.052935

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.051373

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.049531
[Checkpoint] Validation metrics - AUC: 0.571133, AUPRC: 0.090548, Loss: 0.124406
[Checkpoint] Validation lifts - @0.5%: 0.060491, @1%: 0.151137, @5%: 0.491080, @10%: 1.180033

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.047957

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.045283

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.042166

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.039167

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.035948
[Checkpoint] Validation metrics - AUC: 0.547263, AUPRC: 0.084020, Loss: 0.126347
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.027198, @10%: 0.541667

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.032613

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.029449

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.026297

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.023140

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.027457
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.558538, AUPRC: 0.046884, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 0.090736, @1%: 0.113353, @5%: 0.270472, @10%: 0.262901

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.095936

[Checkpoint] ====== Configuration 4/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 5/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 6/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.115855

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.107342

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.101132

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.094325

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.085569
[Checkpoint] Validation metrics - AUC: 0.545165, AUPRC: 0.087619, Loss: 0.081845
[Checkpoint] Validation lifts - @0.5%: 0.604909, @1%: 0.793471, @5%: 1.003314, @10%: 0.968503

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.074933

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.062983

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.051139

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.041165

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.034468
[Checkpoint] Validation metrics - AUC: 0.555293, AUPRC: 0.090234, Loss: 0.043328
[Checkpoint] Validation lifts - @0.5%: 0.786382, @1%: 0.997507, @5%: 0.945895, @10%: 1.221583

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.031564

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.031116

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.031905

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.031698

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.031201
[Checkpoint] Validation metrics - AUC: 0.579889, AUPRC: 0.093143, Loss: 0.068795
[Checkpoint] Validation lifts - @0.5%: 0.287332, @1%: 1.110860, @5%: 0.690534, @10%: 1.254068

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.030790

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.030161

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.029125

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.027906

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.027096
[Checkpoint] Validation metrics - AUC: 0.563284, AUPRC: 0.088670, Loss: 0.065965
[Checkpoint] Validation lifts - @0.5%: 0.030245, @1%: 0.113353, @5%: 0.498635, @10%: 1.088622

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.025885

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.024760

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.023645

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.022429

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.021222
[Checkpoint] Validation metrics - AUC: 0.547061, AUPRC: 0.084393, Loss: 0.062372
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.117859, @10%: 0.710135

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.019999

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.018663

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.017197

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.015755

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.014153
[Checkpoint] Validation metrics - AUC: 0.523996, AUPRC: 0.078389, Loss: 0.060506
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.006044, @10%: 0.132206

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.012560

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.011067

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.009874

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.008854

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.008166
[Checkpoint] Validation metrics - AUC: 0.516895, AUPRC: 0.076498, Loss: 0.058928
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.003022, @10%: 0.200953

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.007499

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.007066

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.006652

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.006155

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.005803
[Checkpoint] Validation metrics - AUC: 0.541029, AUPRC: 0.081509, Loss: 0.067977
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.001511, @10%: 0.744131

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.005421

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.005160

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.004901

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.004555

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.004044
[Checkpoint] Validation metrics - AUC: 0.504890, AUPRC: 0.074510, Loss: 0.087346
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.000000, @10%: 0.590772

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.003754

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.003618

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.003270

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.003131

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.002979
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.453779, AUPRC: 0.062288, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.358111, @10%: 0.661785

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.093143

[Checkpoint] ====== Configuration 7/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 8/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 9/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 10/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.092933

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 11/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 12/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 13/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 14/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 15/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 16/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 17/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.188162

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.228530

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.156591

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.145281

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.114682
[Checkpoint] Validation metrics - AUC: 0.582407, AUPRC: 0.095171, Loss: 0.091583
[Checkpoint] Validation lifts - @0.5%: 0.650277, @1%: 1.050405, @5%: 1.025979, @10%: 1.269177

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.088041

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.064911

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.054555

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.055212

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.058324
[Checkpoint] Validation metrics - AUC: 0.570452, AUPRC: 0.090479, Loss: 0.117748
[Checkpoint] Validation lifts - @0.5%: 0.075614, @1%: 0.113353, @5%: 0.645203, @10%: 1.132439

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.057438

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.051529

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.042025

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.033381

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.026735
[Checkpoint] Validation metrics - AUC: 0.544524, AUPRC: 0.082566, Loss: 0.148465
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.012088, @10%: 0.441190

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.019657

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.011865

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.095171

[Checkpoint] ====== Configuration 18/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.095961

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.079627

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.064654

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.039648

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.030724
[Checkpoint] Validation metrics - AUC: 0.588171, AUPRC: 0.096191, Loss: 0.045544
[Checkpoint] Validation lifts - @0.5%: 0.514173, @1%: 1.118417, @5%: 0.929274, @10%: 1.330370
[Checkpoint] New best model found! AUPRC: 0.096191 (previous best: 0.095974)

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.031710

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.034162

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.033501

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.030817

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.029427
[Checkpoint] Validation metrics - AUC: 0.581012, AUPRC: 0.096272, Loss: 0.098091
[Checkpoint] Validation lifts - @0.5%: 1.618132, @1%: 1.141088, @5%: 0.859768, @10%: 1.319793
[Checkpoint] New best model found! AUPRC: 0.096272 (previous best: 0.096191)

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.029840

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.028447

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.024518

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.020300

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.016974
[Checkpoint] Validation metrics - AUC: 0.544938, AUPRC: 0.082374, Loss: 0.084333
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.142035, @10%: 0.454789

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.014218

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.011158

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.008195

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.006022

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.004658
[Checkpoint] Validation metrics - AUC: 0.518382, AUPRC: 0.076959, Loss: 0.080177
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.000000, @10%: 0.451767

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.003790

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.003156

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.002692

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.002545

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.002450
[Checkpoint] Validation metrics - AUC: 0.536381, AUPRC: 0.080156, Loss: 0.121261
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.000000, @10%: 0.668584

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.002155

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.001793

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.001427

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.001239

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.001083
[Checkpoint] Validation metrics - AUC: 0.519517, AUPRC: 0.077197, Loss: 0.165395
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.000000, @10%: 0.634589

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.001018

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.000920

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.000925

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.096272

[Checkpoint] ====== Configuration 19/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 20/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 21/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.183155

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.421481

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.239393

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.179090

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.183650
[Checkpoint] Validation metrics - AUC: 0.547806, AUPRC: 0.087269, Loss: 0.113323
[Checkpoint] Validation lifts - @0.5%: 0.589786, @1%: 0.982393, @5%: 0.917186, @10%: 1.075779

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.142021

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.121228

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.104523

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.081640

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.065511
[Checkpoint] Validation metrics - AUC: 0.519218, AUPRC: 0.080165, Loss: 0.081257
[Checkpoint] Validation lifts - @0.5%: 0.604909, @1%: 0.574322, @5%: 0.595340, @10%: 0.747153

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.062738

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.066204

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.070343

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.072150

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.069041
[Checkpoint] Validation metrics - AUC: 0.586040, AUPRC: 0.100202, Loss: 0.151010
[Checkpoint] Validation lifts - @0.5%: 2.238164, @1%: 2.115924, @5%: 1.164993, @10%: 1.332636
[Checkpoint] New best model found! AUPRC: 0.100202 (previous best: 0.096272)

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.063136

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.057932

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.054426

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.051545

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.048946
[Checkpoint] Validation metrics - AUC: 0.570877, AUPRC: 0.091794, Loss: 0.140545
[Checkpoint] Validation lifts - @0.5%: 1.315677, @1%: 0.846370, @5%: 0.663336, @10%: 1.067469

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.046680

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.043619

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.038312

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.031925

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.023633
[Checkpoint] Validation metrics - AUC: 0.527553, AUPRC: 0.078952, Loss: 0.117935
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.007555, @10%: 0.275744

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.016262

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.011202

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.008090

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.006426

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.005567
[Checkpoint] Validation metrics - AUC: 0.486301, AUPRC: 0.071061, Loss: 0.157012
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.001511, @10%: 0.381509

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.004786

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.004176

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.003848

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.003853

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.003956
[Checkpoint] Validation metrics - AUC: 0.524030, AUPRC: 0.079726, Loss: 0.170982
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.410996, @10%: 0.673117

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.004133

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.004386

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.004363

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.004652

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.005044
[Checkpoint] Validation metrics - AUC: 0.531592, AUPRC: 0.081878, Loss: 0.235701
[Checkpoint] Validation lifts - @0.5%: 0.030245, @1%: 0.060455, @5%: 0.897543, @10%: 0.787192

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.005150

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.004487

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.004454

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.003700

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.003431
[Checkpoint] Validation metrics - AUC: 0.559738, AUPRC: 0.085103, Loss: 0.283422
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.525833, @10%: 0.732799

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.003266

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.002963

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.002654

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.002486

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.002303
[Checkpoint] Validation metrics - AUC: 0.552597, AUPRC: 0.082147, Loss: 0.318973
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.214564, @10%: 0.682183

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.002377

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.002260

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.002188

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.002092

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.002078
[Checkpoint] Validation metrics - AUC: 0.537703, AUPRC: 0.079674, Loss: 0.335805
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.123903, @10%: 0.656497

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.002000

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.001963

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.001946

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.001882

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.001817
[Checkpoint] Validation metrics - AUC: 0.546993, AUPRC: 0.081783, Loss: 0.350541
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.167723, @10%: 0.675384

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.001810

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.001890

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.001729

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.001742

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.001690
[Checkpoint] Validation metrics - AUC: 0.546784, AUPRC: 0.082127, Loss: 0.369871
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.241762, @10%: 0.689737

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.001659

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.001727

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.001644

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.001597

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.001739
[Checkpoint] Validation metrics - AUC: 0.549812, AUPRC: 0.082729, Loss: 0.375873
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.323357, @10%: 0.718445

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.001608

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.001636

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.001595

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.001556

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.001636
[Checkpoint] Validation metrics - AUC: 0.546771, AUPRC: 0.083596, Loss: 0.382723
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.382287, @10%: 0.729021

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.001568

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.001512

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.001529

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.001467

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.001455
[Checkpoint] Validation metrics - AUC: 0.509529, AUPRC: 0.078203, Loss: 0.385531
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.456327, @10%: 0.740353

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.001479

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.001495

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.001431

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.001408

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.001470
[Checkpoint] Validation metrics - AUC: 0.492451, AUPRC: 0.073575, Loss: 0.385949
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.509212, @10%: 0.752441

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.001468

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.001367

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.001459

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.001336

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.001386
[Checkpoint] Validation metrics - AUC: 0.494335, AUPRC: 0.074163, Loss: 0.386757
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.540943, @10%: 0.756218
[Checkpoint] Early stopping at epoch 90 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.100202

[Checkpoint] ====== Configuration 22/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.089077

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.156840

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.126812

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.091817

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.064089
[Checkpoint] Validation metrics - AUC: 0.437544, AUPRC: 0.068585, Loss: 0.061667
[Checkpoint] Validation lifts - @0.5%: 0.559541, @1%: 0.544095, @5%: 0.888477, @10%: 1.048582

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.062913

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.051430

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.039065

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.033984

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.035134
[Checkpoint] Validation metrics - AUC: 0.552091, AUPRC: 0.089738, Loss: 0.067602
[Checkpoint] Validation lifts - @0.5%: 0.544418, @1%: 0.823699, @5%: 1.152905, @10%: 1.174744

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.038376

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.040362

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.040468

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.038672

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.036572
[Checkpoint] Validation metrics - AUC: 0.551232, AUPRC: 0.088055, Loss: 0.043721
[Checkpoint] Validation lifts - @0.5%: 1.255186, @1%: 1.088189, @5%: 0.954962, @10%: 0.976813

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.035247

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.034155

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.033300

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.032271

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.031836
[Checkpoint] Validation metrics - AUC: 0.492331, AUPRC: 0.073689, Loss: 0.043428
[Checkpoint] Validation lifts - @0.5%: 0.589786, @1%: 0.506310, @5%: 0.568142, @10%: 0.795502

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.032108

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.032304

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.031602

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.030465

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.029008
[Checkpoint] Validation metrics - AUC: 0.480666, AUPRC: 0.071487, Loss: 0.044084
[Checkpoint] Validation lifts - @0.5%: 0.559541, @1%: 0.483640, @5%: 0.531877, @10%: 0.660274

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.027886

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.026381

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.024281

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.020552

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.016066
[Checkpoint] Validation metrics - AUC: 0.392564, AUPRC: 0.061786, Loss: 0.088387
[Checkpoint] Validation lifts - @0.5%: 0.559541, @1%: 0.491197, @5%: 0.595340, @10%: 0.831764

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.011780

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.008541

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.006838

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.005610

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.004937
[Checkpoint] Validation metrics - AUC: 0.398455, AUPRC: 0.062084, Loss: 0.145524
[Checkpoint] Validation lifts - @0.5%: 0.468805, @1%: 0.423185, @5%: 0.717732, @10%: 0.714668

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.004475

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.004199

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.003949

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.003925

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.003949
[Checkpoint] Validation metrics - AUC: 0.458397, AUPRC: 0.070117, Loss: 0.186883
[Checkpoint] Validation lifts - @0.5%: 0.105859, @1%: 0.370287, @5%: 0.994248, @10%: 0.886158

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.003812

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.003725

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.003571

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.003520

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.003116
[Checkpoint] Validation metrics - AUC: 0.455667, AUPRC: 0.069229, Loss: 0.221430
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.747952, @10%: 0.804568

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.002907

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.002503

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.002281

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.002092

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.002063
[Checkpoint] Validation metrics - AUC: 0.468794, AUPRC: 0.069749, Loss: 0.257937
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.349044, @10%: 0.697292

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.001923

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.001736

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.001716

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.001597

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.001491
[Checkpoint] Validation metrics - AUC: 0.481946, AUPRC: 0.071748, Loss: 0.275833
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.238740, @10%: 0.670851

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.001399

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.001357

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.001320

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.001312

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.001200
[Checkpoint] Validation metrics - AUC: 0.496714, AUPRC: 0.074251, Loss: 0.293151
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.250829, @10%: 0.678405

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.001157

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.001114

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.001075

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.001008

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.000994
[Checkpoint] Validation metrics - AUC: 0.499001, AUPRC: 0.074503, Loss: 0.285105
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.244784, @10%: 0.683694

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.000939

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.000992

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.000927

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.000910

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.000877
[Checkpoint] Validation metrics - AUC: 0.500914, AUPRC: 0.074626, Loss: 0.278998
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.241762, @10%: 0.685960

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.000862

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.089738

[Checkpoint] ====== Configuration 23/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.097614

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.098114

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.129509

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.095965

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.100906
[Checkpoint] Validation metrics - AUC: 0.584668, AUPRC: 0.098626, Loss: 0.088833
[Checkpoint] Validation lifts - @0.5%: 1.860096, @1%: 1.957230, @5%: 1.139305, @10%: 1.203452

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.076802

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.076243

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.064568

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.062488

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.063027
[Checkpoint] Validation metrics - AUC: 0.586286, AUPRC: 0.099515, Loss: 0.093030
[Checkpoint] Validation lifts - @0.5%: 2.207918, @1%: 2.017685, @5%: 1.155927, @10%: 1.316771

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.058025

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.054215

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.099515

[Checkpoint] ====== Configuration 24/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.059113

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.244009

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.101280

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.062780

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.080584
[Checkpoint] Validation metrics - AUC: 0.549812, AUPRC: 0.088314, Loss: 0.043018
[Checkpoint] Validation lifts - @0.5%: 0.438559, @1%: 0.528981, @5%: 1.025979, @10%: 1.128661

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.054947

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.041716

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.048266

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.047467

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.042112
[Checkpoint] Validation metrics - AUC: 0.436236, AUPRC: 0.072159, Loss: 0.041740
[Checkpoint] Validation lifts - @0.5%: 1.103959, @1%: 1.277111, @5%: 1.409777, @10%: 1.123373

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.037574

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.035628

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.088314

[Checkpoint] ====== Configuration 25/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 26/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 27/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 28/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 29/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.173903

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.167677

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.164600

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.162500

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.160914
[Checkpoint] Validation metrics - AUC: 0.522848, AUPRC: 0.079591, Loss: 0.156119
[Checkpoint] Validation lifts - @0.5%: 0.120982, @1%: 0.287161, @5%: 0.729820, @10%: 0.846874

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.159565

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.158317

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.157409

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.156419

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.155370
[Checkpoint] Validation metrics - AUC: 0.495225, AUPRC: 0.074607, Loss: 0.155969
[Checkpoint] Validation lifts - @0.5%: 0.257086, @1%: 0.370287, @5%: 0.648225, @10%: 0.794747

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.154504

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.153529

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.152882

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.151930

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.151197
[Checkpoint] Validation metrics - AUC: 0.517387, AUPRC: 0.078581, Loss: 0.156266
[Checkpoint] Validation lifts - @0.5%: 0.287332, @1%: 0.385400, @5%: 0.682979, @10%: 0.877848

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.150234

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.149630

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.148729

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.148100

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.147235
[Checkpoint] Validation metrics - AUC: 0.508161, AUPRC: 0.077548, Loss: 0.149816
[Checkpoint] Validation lifts - @0.5%: 0.468805, @1%: 0.498753, @5%: 0.711688, @10%: 0.925442

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.146431

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.145344

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.144580

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.143665

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.142684
[Checkpoint] Validation metrics - AUC: 0.459506, AUPRC: 0.073850, Loss: 0.142927
[Checkpoint] Validation lifts - @0.5%: 1.527396, @1%: 1.481147, @5%: 1.133261, @10%: 0.845363

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.141794

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.140725

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.139454

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.138432

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.137122
[Checkpoint] Validation metrics - AUC: 0.444995, AUPRC: 0.070004, Loss: 0.138708
[Checkpoint] Validation lifts - @0.5%: 1.134205, @1%: 1.413135, @5%: 1.000292, @10%: 0.801546

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.136052

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.134718

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.133361

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.131865

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.130373
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.439598, AUPRC: 0.085628, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 0.620032, @1%: 0.612107, @5%: 0.741908, @10%: 0.699558

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.085628

[Checkpoint] ====== Configuration 30/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.090767

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.083898

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.080550

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.078892

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.077605
[Checkpoint] Validation metrics - AUC: 0.419690, AUPRC: 0.062654, Loss: 0.073166
[Checkpoint] Validation lifts - @0.5%: 0.574664, @1%: 0.574322, @5%: 0.485036, @10%: 0.503138

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.076611

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.075546

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.074669

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.073862

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.073135
[Checkpoint] Validation metrics - AUC: 0.439991, AUPRC: 0.065961, Loss: 0.071239
[Checkpoint] Validation lifts - @0.5%: 0.362945, @1%: 0.385400, @5%: 0.515256, @10%: 0.569619

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.072726

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.072086

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.071484

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.071081

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.070440
[Checkpoint] Validation metrics - AUC: 0.451536, AUPRC: 0.068251, Loss: 0.070643
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.370287, @5%: 0.578719, @10%: 0.667829

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.069944

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.069447

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.069005

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.068497

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.067886
[Checkpoint] Validation metrics - AUC: 0.443031, AUPRC: 0.066786, Loss: 0.071542
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.392957, @5%: 0.598362, @10%: 0.682938

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.067359

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.066733

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.066274

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.065618

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.065081
[Checkpoint] Validation metrics - AUC: 0.445313, AUPRC: 0.066376, Loss: 0.070272
[Checkpoint] Validation lifts - @0.5%: 0.302455, @1%: 0.400514, @5%: 0.545476, @10%: 0.613436

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.064560

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.063880

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.063239

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.062628

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.061974
[Checkpoint] Validation metrics - AUC: 0.436798, AUPRC: 0.064747, Loss: 0.068854
[Checkpoint] Validation lifts - @0.5%: 0.302455, @1%: 0.400514, @5%: 0.516767, @10%: 0.551488

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.061188

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.060457

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.059891

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.059084

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.058371
[Checkpoint] Validation metrics - AUC: 0.435736, AUPRC: 0.064551, Loss: 0.067052
[Checkpoint] Validation lifts - @0.5%: 0.317577, @1%: 0.392957, @5%: 0.504679, @10%: 0.545444

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.057439

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.056764

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.055939

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.055204

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.054340
[Checkpoint] Validation metrics - AUC: 0.430765, AUPRC: 0.063996, Loss: 0.064463
[Checkpoint] Validation lifts - @0.5%: 0.332700, @1%: 0.430742, @5%: 0.498635, @10%: 0.533357

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.053391

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.052615

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.051826

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.050954

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.050114
[Checkpoint] Validation metrics - AUC: 0.430053, AUPRC: 0.063951, Loss: 0.062758
[Checkpoint] Validation lifts - @0.5%: 0.393191, @1%: 0.408071, @5%: 0.513745, @10%: 0.537889

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.049244

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.048352

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.047308

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.046492

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.045691
[Checkpoint] Validation metrics - AUC: 0.430414, AUPRC: 0.064014, Loss: 0.061161
[Checkpoint] Validation lifts - @0.5%: 0.408314, @1%: 0.415628, @5%: 0.512234, @10%: 0.531846

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.044814

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.043982

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.043133

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.042204

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.041469
[Checkpoint] Validation metrics - AUC: 0.433549, AUPRC: 0.064717, Loss: 0.059159
[Checkpoint] Validation lifts - @0.5%: 0.408314, @1%: 0.483640, @5%: 0.553032, @10%: 0.595305

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.040663

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.039812

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.039042

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.038395

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.037678
[Checkpoint] Validation metrics - AUC: 0.540217, AUPRC: 0.084169, Loss: 0.055848
[Checkpoint] Validation lifts - @0.5%: 0.453682, @1%: 0.536538, @5%: 0.796305, @10%: 0.976058

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.036961

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.036234

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.035644

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.035024

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.034308
[Checkpoint] Validation metrics - AUC: 0.545918, AUPRC: 0.086607, Loss: 0.052019
[Checkpoint] Validation lifts - @0.5%: 0.423436, @1%: 0.589436, @5%: 1.012380, @10%: 0.966237

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.033976

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.033295

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.032824

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.032363

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.032002
[Checkpoint] Validation metrics - AUC: 0.549755, AUPRC: 0.087904, Loss: 0.048217
[Checkpoint] Validation lifts - @0.5%: 0.574664, @1%: 0.778358, @5%: 0.841635, @10%: 1.131683

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.031549

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.031085

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.030684

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.030363

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.029984
[Checkpoint] Validation metrics - AUC: 0.551104, AUPRC: 0.088575, Loss: 0.045633
[Checkpoint] Validation lifts - @0.5%: 0.635155, @1%: 0.506310, @5%: 0.734353, @10%: 1.219317

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.029651

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.029441

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.029151

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.028847

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.028593
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.535244, AUPRC: 0.082009, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 0.211718, @1%: 0.226706, @5%: 0.725287, @10%: 0.711646

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.088575

[Checkpoint] ====== Configuration 31/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.107992

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.105462

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.104276

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.103383

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.102417
[Checkpoint] Validation metrics - AUC: 0.436637, AUPRC: 0.064902, Loss: 0.102344
[Checkpoint] Validation lifts - @0.5%: 0.332700, @1%: 0.370287, @5%: 0.506190, @10%: 0.537889

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.101745

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.101199

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.100445

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.100042

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.099524
[Checkpoint] Validation metrics - AUC: 0.452192, AUPRC: 0.067609, Loss: 0.101639
[Checkpoint] Validation lifts - @0.5%: 0.257086, @1%: 0.408071, @5%: 0.559076, @10%: 0.659519

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.098948

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.098571

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.098086

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.097628

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.097226
[Checkpoint] Validation metrics - AUC: 0.503167, AUPRC: 0.076204, Loss: 0.102701
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.370287, @5%: 0.646714, @10%: 0.799280

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.096770

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.096304

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.095890

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.095419

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.095106
[Checkpoint] Validation metrics - AUC: 0.484603, AUPRC: 0.073006, Loss: 0.104795
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.377844, @5%: 0.625560, @10%: 0.747908

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.094592

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.094038

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.093439

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.092991

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.092556
[Checkpoint] Validation metrics - AUC: 0.499002, AUPRC: 0.075258, Loss: 0.105080
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.385400, @5%: 0.649736, @10%: 0.774349

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.091974

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.091493

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.090850

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.090309

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.089624
[Checkpoint] Validation metrics - AUC: 0.474334, AUPRC: 0.071336, Loss: 0.104622
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.415628, @5%: 0.645203, @10%: 0.759240

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.088928

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.088245

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.087615

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.086967

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.086257
[Checkpoint] Validation metrics - AUC: 0.508032, AUPRC: 0.076466, Loss: 0.105733
[Checkpoint] Validation lifts - @0.5%: 0.287332, @1%: 0.415628, @5%: 0.649736, @10%: 0.778882

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.085533

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.084762

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.083905

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.083032

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.082401
[Checkpoint] Validation metrics - AUC: 0.453179, AUPRC: 0.068459, Loss: 0.107415
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.430742, @5%: 0.628582, @10%: 0.735821

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.081534

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.080654

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.079820

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.078911

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.078173
[Checkpoint] Validation metrics - AUC: 0.474598, AUPRC: 0.071634, Loss: 0.110542
[Checkpoint] Validation lifts - @0.5%: 0.302455, @1%: 0.438299, @5%: 0.661825, @10%: 0.785681

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.077214

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.076434

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.075326

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.074495

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.073488
[Checkpoint] Validation metrics - AUC: 0.537813, AUPRC: 0.083958, Loss: 0.113739
[Checkpoint] Validation lifts - @0.5%: 0.317577, @1%: 0.415628, @5%: 0.843146, @10%: 1.031962

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.072772

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.071778

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.070697

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.069668

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.068711
[Checkpoint] Validation metrics - AUC: 0.544163, AUPRC: 0.086103, Loss: 0.114989
[Checkpoint] Validation lifts - @0.5%: 0.438559, @1%: 0.551652, @5%: 0.936829, @10%: 0.877092

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.067797

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.066933

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.066004

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.064953

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.063976
[Checkpoint] Validation metrics - AUC: 0.546168, AUPRC: 0.087510, Loss: 0.115328
[Checkpoint] Validation lifts - @0.5%: 0.741014, @1%: 0.937052, @5%: 0.905098, @10%: 1.033473

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.062967

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.061917

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.060898

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.060109

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.059276
[Checkpoint] Validation metrics - AUC: 0.543261, AUPRC: 0.086263, Loss: 0.125864
[Checkpoint] Validation lifts - @0.5%: 0.710768, @1%: 0.544095, @5%: 0.645203, @10%: 1.087866

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.058052

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.057276

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.056197

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.055223

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.054190
[Checkpoint] Validation metrics - AUC: 0.538165, AUPRC: 0.084285, Loss: 0.138229
[Checkpoint] Validation lifts - @0.5%: 0.181473, @1%: 0.151137, @5%: 0.424595, @10%: 0.918643

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.053257

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.052273

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.050954

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.050163

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.048604
[Checkpoint] Validation metrics - AUC: 0.531119, AUPRC: 0.082131, Loss: 0.150478
[Checkpoint] Validation lifts - @0.5%: 0.060491, @1%: 0.037784, @5%: 0.161679, @10%: 0.710135

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.047453

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.046247

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.044757

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.043441

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.042005
[Checkpoint] Validation metrics - AUC: 0.522629, AUPRC: 0.080003, Loss: 0.165790
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.039286, @10%: 0.432880

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.040724

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.039374

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.038039

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.036634

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.035499
[Checkpoint] Validation metrics - AUC: 0.514259, AUPRC: 0.077972, Loss: 0.184563
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.021154, @10%: 0.237971

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.034226

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.032997

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.031995

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.030873

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.029895
[Checkpoint] Validation metrics - AUC: 0.509064, AUPRC: 0.076704, Loss: 0.203125
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.012088, @10%: 0.165446

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.028904

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.027824

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.026964

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.026105

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.025384
[Checkpoint] Validation metrics - AUC: 0.507981, AUPRC: 0.076328, Loss: 0.205142
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.009066, @10%: 0.142782

[Checkpoint] --- Epoch 96/200 ---
[Checkpoint] Epoch 96 training loss: 0.024417

[Checkpoint] --- Epoch 97/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 98/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 99/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.087510

[Checkpoint] ====== Configuration 32/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 33/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.177630

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.175418

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.173695

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.171975

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.170342
[Checkpoint] Validation metrics - AUC: 0.596122, AUPRC: 0.099805, Loss: 0.168731
[Checkpoint] Validation lifts - @0.5%: 1.527396, @1%: 1.277111, @5%: 1.083398, @10%: 1.329614

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.168659

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.166943

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.165203

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.163358

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.161400
[Checkpoint] Validation metrics - AUC: 0.584127, AUPRC: 0.094271, Loss: 0.159949
[Checkpoint] Validation lifts - @0.5%: 0.362945, @1%: 0.959723, @5%: 0.711688, @10%: 1.281265

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.159376

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.157292

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.155048

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.152744

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.150218
[Checkpoint] Validation metrics - AUC: 0.582777, AUPRC: 0.093802, Loss: 0.148836
[Checkpoint] Validation lifts - @0.5%: 0.317577, @1%: 0.974836, @5%: 0.701111, @10%: 1.279754

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.147613

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.144911

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.142049

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.139047

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.135944
[Checkpoint] Validation metrics - AUC: 0.582378, AUPRC: 0.093465, Loss: 0.134920
[Checkpoint] Validation lifts - @0.5%: 0.302455, @1%: 0.831256, @5%: 0.686001, @10%: 1.274466

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.132703

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.129324

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.125989

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.122400

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.118845
[Checkpoint] Validation metrics - AUC: 0.580563, AUPRC: 0.092737, Loss: 0.118746
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.596993, @5%: 0.628582, @10%: 1.251802

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.115186

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.111578

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.107776

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.103995

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.100322
[Checkpoint] Validation metrics - AUC: 0.577280, AUPRC: 0.091720, Loss: 0.101847
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.317389, @5%: 0.595340, @10%: 1.241981

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.096494

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.092908

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.089257

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.085711

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.082289
[Checkpoint] Validation metrics - AUC: 0.572076, AUPRC: 0.090513, Loss: 0.086939
[Checkpoint] Validation lifts - @0.5%: 0.030245, @1%: 0.113353, @5%: 0.536410, @10%: 1.202697

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.078934

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.075742

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.072683

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.069797

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.067070
[Checkpoint] Validation metrics - AUC: 0.565129, AUPRC: 0.088859, Loss: 0.076450
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.463882, @10%: 1.075779

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.064372

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.061945

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.059630

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.057348

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.055227
[Checkpoint] Validation metrics - AUC: 0.558125, AUPRC: 0.086853, Loss: 0.071706
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.288604, @10%: 0.880114

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.053249

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.051151

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.049089

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.046821

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.044800
[Checkpoint] Validation metrics - AUC: 0.551357, AUPRC: 0.084776, Loss: 0.071794
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.060441, @10%: 0.661030

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.042220

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.039805

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.037372

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.034978

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.032643
[Checkpoint] Validation metrics - AUC: 0.542438, AUPRC: 0.082384, Loss: 0.075544
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.015110, @10%: 0.410216

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.030314

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.027806

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.025876

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.023645

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.021273
[Checkpoint] Validation metrics - AUC: 0.534509, AUPRC: 0.080775, Loss: 0.083400
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.003022, @10%: 0.302941

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.019451

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.017481

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.015965

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.014411

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.013479
[Checkpoint] Validation metrics - AUC: 0.524766, AUPRC: 0.078798, Loss: 0.089756
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.001511, @10%: 0.118608

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.012541

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.011648

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.010624

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.010028

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.009248
[Checkpoint] Validation metrics - AUC: 0.518611, AUPRC: 0.077662, Loss: 0.105839
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.001511, @10%: 0.132961

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.008640

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.008072

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.007675

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.007362

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.007215
[Checkpoint] Validation metrics - AUC: 0.517263, AUPRC: 0.077124, Loss: 0.120003
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.003022, @10%: 0.231172

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.007015

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.006374

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.006406

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.006168

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.005727
[Checkpoint] Validation metrics - AUC: 0.518713, AUPRC: 0.077193, Loss: 0.151502
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.006044, @10%: 0.522025
[Checkpoint] Early stopping at epoch 80 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.099805

[Checkpoint] ====== Configuration 34/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.077862

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.075763

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.074135

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.072657

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.071324
[Checkpoint] Validation metrics - AUC: 0.588757, AUPRC: 0.096409, Loss: 0.070539
[Checkpoint] Validation lifts - @0.5%: 1.814727, @1%: 1.405578, @5%: 1.083398, @10%: 1.031207

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.069977

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.068610

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.067271

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.065784

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.064319
[Checkpoint] Validation metrics - AUC: 0.588108, AUPRC: 0.094735, Loss: 0.063915
[Checkpoint] Validation lifts - @0.5%: 0.287332, @1%: 1.171315, @5%: 0.861279, @10%: 1.325082

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.062807

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.061196

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.059562

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.057837

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.056115
[Checkpoint] Validation metrics - AUC: 0.591497, AUPRC: 0.096202, Loss: 0.056085
[Checkpoint] Validation lifts - @0.5%: 0.332700, @1%: 1.103303, @5%: 0.805371, @10%: 1.327348

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.054350

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.052523

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.050683

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.048866

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.047023
[Checkpoint] Validation metrics - AUC: 0.589635, AUPRC: 0.095413, Loss: 0.047943
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 1.073076, @5%: 0.713199, @10%: 1.314505

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.045229

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.043460

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.041735

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.040121

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.038579
[Checkpoint] Validation metrics - AUC: 0.585833, AUPRC: 0.094351, Loss: 0.041254
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 1.110860, @5%: 0.666358, @10%: 1.292597

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.037124

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.035777

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.034541

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.033436

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.032462
[Checkpoint] Validation metrics - AUC: 0.582128, AUPRC: 0.093355, Loss: 0.037724
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.733016, @5%: 0.646714, @10%: 1.263889

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.031535

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.030772

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.030065

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.029540

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.028984
[Checkpoint] Validation metrics - AUC: 0.578019, AUPRC: 0.092123, Loss: 0.037872
[Checkpoint] Validation lifts - @0.5%: 0.287332, @1%: 0.196479, @5%: 0.634626, @10%: 1.251046

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.028552

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.028104

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.027707

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.027349

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.026850
[Checkpoint] Validation metrics - AUC: 0.575529, AUPRC: 0.091219, Loss: 0.040648
[Checkpoint] Validation lifts - @0.5%: 0.060491, @1%: 0.105796, @5%: 0.602895, @10%: 1.177011

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.026475

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.025916

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.025497

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.024861

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.024238
[Checkpoint] Validation metrics - AUC: 0.568666, AUPRC: 0.088831, Loss: 0.043537
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.518278, @10%: 0.970770

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.023410

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.022538

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.021407

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.020379

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.019124
[Checkpoint] Validation metrics - AUC: 0.553560, AUPRC: 0.084602, Loss: 0.044906
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.202476, @10%: 0.581706

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.017987

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.016605

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.015309

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.013849

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.012713
[Checkpoint] Validation metrics - AUC: 0.538079, AUPRC: 0.081367, Loss: 0.047640
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.066485, @10%: 0.403417

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.011374

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.010127

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.009110

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.008050

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.007247
[Checkpoint] Validation metrics - AUC: 0.526059, AUPRC: 0.079287, Loss: 0.050298
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.001511, @10%: 0.253835

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.006556

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.005897

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.005425

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.004823

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.004485
[Checkpoint] Validation metrics - AUC: 0.525862, AUPRC: 0.078846, Loss: 0.058855
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.001511, @10%: 0.253835

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.004165

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.003877

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.003636

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.003412

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.003251
[Checkpoint] Validation metrics - AUC: 0.523218, AUPRC: 0.078083, Loss: 0.069181
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.004533, @10%: 0.334670

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.003142

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.003368

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.002914

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.002691

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.002821
[Checkpoint] Validation metrics - AUC: 0.521752, AUPRC: 0.078020, Loss: 0.077563
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.007555, @10%: 0.407194

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.002429

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.002650

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.002290

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.002418

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.002144
[Checkpoint] Validation metrics - AUC: 0.532585, AUPRC: 0.079813, Loss: 0.096775
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.007557, @5%: 0.010577, @10%: 0.633078
[Checkpoint] Early stopping at epoch 80 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.096409

[Checkpoint] ====== Configuration 35/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 36/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 37/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 38/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 39/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 40/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 41/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 42/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.081656

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.078396

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.075823

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.073333

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.071100
[Checkpoint] Validation metrics - AUC: 0.424574, AUPRC: 0.063225, Loss: 0.069465
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.317389, @5%: 0.417040, @10%: 0.491806

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.068854

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.066636

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.064426

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.062190

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.059898
[Checkpoint] Validation metrics - AUC: 0.500454, AUPRC: 0.076565, Loss: 0.059077
[Checkpoint] Validation lifts - @0.5%: 0.589786, @1%: 0.680118, @5%: 0.779684, @10%: 0.877092

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.057586

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.055218

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.052866

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.050509

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.048132
[Checkpoint] Validation metrics - AUC: 0.577823, AUPRC: 0.092802, Loss: 0.048349
[Checkpoint] Validation lifts - @0.5%: 0.257086, @1%: 0.801028, @5%: 0.625560, @10%: 1.246513

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.045826

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.043641

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.041515

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.039509

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.037656
[Checkpoint] Validation metrics - AUC: 0.581623, AUPRC: 0.093442, Loss: 0.040082
[Checkpoint] Validation lifts - @0.5%: 0.302455, @1%: 0.778358, @5%: 0.692045, @10%: 1.264645

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.036049

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.034573

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.033318

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.032264

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.031387
[Checkpoint] Validation metrics - AUC: 0.580422, AUPRC: 0.092954, Loss: 0.037407
[Checkpoint] Validation lifts - @0.5%: 0.499050, @1%: 0.536538, @5%: 0.701111, @10%: 1.245002

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.030743

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.030146

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.029694

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.029394

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.029108
[Checkpoint] Validation metrics - AUC: 0.577410, AUPRC: 0.092316, Loss: 0.039850
[Checkpoint] Validation lifts - @0.5%: 1.073714, @1%: 0.748130, @5%: 0.764574, @10%: 1.211762

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.028800

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.028438

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.028071

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.027548

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.026927
[Checkpoint] Validation metrics - AUC: 0.573729, AUPRC: 0.090532, Loss: 0.043299
[Checkpoint] Validation lifts - @0.5%: 0.559541, @1%: 0.491197, @5%: 0.753997, @10%: 1.022896

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.026148

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.025364

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.024383

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.023174

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.021861
[Checkpoint] Validation metrics - AUC: 0.566669, AUPRC: 0.087859, Loss: 0.045058
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.578719, @10%: 0.840074

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.020298

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.018768

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.017121

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.015474

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.013745
[Checkpoint] Validation metrics - AUC: 0.549537, AUPRC: 0.083446, Loss: 0.044359
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.066485, @10%: 0.512959

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.012061

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.021633

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.093442

[Checkpoint] ====== Configuration 43/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.099198

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.098631

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.095871

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.094487

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.092941
[Checkpoint] Validation metrics - AUC: 0.544792, AUPRC: 0.082960, Loss: 0.095172
[Checkpoint] Validation lifts - @0.5%: 0.438559, @1%: 0.528981, @5%: 0.741908, @10%: 0.870293

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.091388

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.090009

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.088606

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.087042

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.085338
[Checkpoint] Validation metrics - AUC: 0.561172, AUPRC: 0.086581, Loss: 0.088824
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.302275, @5%: 0.598362, @10%: 0.886913

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.083596

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.081795

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.079833

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.077859

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.075700
[Checkpoint] Validation metrics - AUC: 0.571470, AUPRC: 0.089409, Loss: 0.081628
[Checkpoint] Validation lifts - @0.5%: 0.015123, @1%: 0.007557, @5%: 0.625560, @10%: 0.996455

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.073489

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.071347

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.068878

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.066275

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.063550
[Checkpoint] Validation metrics - AUC: 0.561527, AUPRC: 0.086278, Loss: 0.075824
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.288604, @10%: 0.840074

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.060711

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.057585

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.054088

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.050301

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.045996
[Checkpoint] Validation metrics - AUC: 0.542580, AUPRC: 0.082228, Loss: 0.074038
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.021154, @10%: 0.468387

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.041519

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.036388

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.031644

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.027105

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.023071
[Checkpoint] Validation metrics - AUC: 0.509457, AUPRC: 0.075869, Loss: 0.079013
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.004533, @10%: 0.288587

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.020111

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.017570

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.015088

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.013063

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.011454
[Checkpoint] Validation metrics - AUC: 0.482584, AUPRC: 0.071348, Loss: 0.090386
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.006044, @10%: 0.074035

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.010165

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.008978

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.008053

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.007320

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.006616
[Checkpoint] Validation metrics - AUC: 0.467436, AUPRC: 0.068539, Loss: 0.105562
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.006044, @10%: 0.065725

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.005954

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.005502

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.005062

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.004672

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.004326
[Checkpoint] Validation metrics - AUC: 0.480624, AUPRC: 0.070505, Loss: 0.120658
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.009066, @10%: 0.162424

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.004053

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.003788

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.003586

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.003390

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.003210
[Checkpoint] Validation metrics - AUC: 0.492382, AUPRC: 0.072270, Loss: 0.137781
[Checkpoint] Validation lifts - @0.5%: 0.030245, @1%: 0.022671, @5%: 0.010577, @10%: 0.410972

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.003049

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.002890

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.002657

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.002542

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.002462
[Checkpoint] Validation metrics - AUC: 0.503818, AUPRC: 0.074160, Loss: 0.150163
[Checkpoint] Validation lifts - @0.5%: 0.075614, @1%: 0.045341, @5%: 0.015110, @10%: 0.528824

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.002375

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.002258

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.002101

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.002052

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.002034
[Checkpoint] Validation metrics - AUC: 0.516941, AUPRC: 0.076561, Loss: 0.160302
[Checkpoint] Validation lifts - @0.5%: 0.105859, @1%: 0.060455, @5%: 0.018132, @10%: 0.607392

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.001999

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.001889

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.001798

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.001822

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.001800
[Checkpoint] Validation metrics - AUC: 0.534194, AUPRC: 0.079579, Loss: 0.170547
[Checkpoint] Validation lifts - @0.5%: 0.136105, @1%: 0.083126, @5%: 0.021154, @10%: 0.618724

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.001859

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.001974

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.002050

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.002076

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.001592
[Checkpoint] Validation metrics - AUC: 0.547245, AUPRC: 0.081868, Loss: 0.185952
[Checkpoint] Validation lifts - @0.5%: 0.120982, @1%: 0.090682, @5%: 0.021154, @10%: 0.621746

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.001690

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.001860

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.001441

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.001752

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.001687
[Checkpoint] Validation metrics - AUC: 0.552158, AUPRC: 0.082671, Loss: 0.193814
[Checkpoint] Validation lifts - @0.5%: 0.105859, @1%: 0.083126, @5%: 0.018132, @10%: 0.617968

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.001390

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.001633

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.001212

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.001396

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.001162
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.545650, AUPRC: 0.081268, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 0.105859, @1%: 0.068012, @5%: 0.057419, @10%: 0.563575

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.089409

[Checkpoint] ====== Configuration 44/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 45/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 46/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 47/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.099809

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.097442

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.094508

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.093220

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.091916
[Checkpoint] Validation metrics - AUC: 0.426376, AUPRC: 0.063792, Loss: 0.094843
[Checkpoint] Validation lifts - @0.5%: 0.499050, @1%: 0.513867, @5%: 0.480503, @10%: 0.531846

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.090322

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.089454

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.088372

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.087198

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.086117
[Checkpoint] Validation metrics - AUC: 0.540633, AUPRC: 0.087585, Loss: 0.091695
[Checkpoint] Validation lifts - @0.5%: 1.149327, @1%: 1.080633, @5%: 1.219389, @10%: 1.142260

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.084893

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.083876

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.082581

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.081318

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.079848
[Checkpoint] Validation metrics - AUC: 0.562427, AUPRC: 0.092217, Loss: 0.076042
[Checkpoint] Validation lifts - @0.5%: 1.587886, @1%: 1.654955, @5%: 1.240543, @10%: 1.132439

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.078534

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.077015

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.075361

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.073761

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.072068
[Checkpoint] Validation metrics - AUC: 0.562576, AUPRC: 0.091617, Loss: 0.094998
[Checkpoint] Validation lifts - @0.5%: 1.663500, @1%: 1.586943, @5%: 1.202768, @10%: 1.127150

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.070171

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.068052

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.066162

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.063903

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.061403
[Checkpoint] Validation metrics - AUC: 0.549995, AUPRC: 0.088349, Loss: 0.105452
[Checkpoint] Validation lifts - @0.5%: 1.451782, @1%: 1.405578, @5%: 1.160460, @10%: 1.094665

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.058445

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.055224

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.051278

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.047184

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.092217

[Checkpoint] ====== Configuration 48/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.055575

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.053308

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 49/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 50/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.071559

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.071433

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.071403

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.071267

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.071110
[Checkpoint] Validation metrics - AUC: 0.560297, AUPRC: 0.090608, Loss: 0.070618
[Checkpoint] Validation lifts - @0.5%: 2.480127, @1%: 1.654955, @5%: 1.090953, @10%: 1.059159

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.071060

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.070977

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.070871

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.070821

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.070746
[Checkpoint] Validation metrics - AUC: 0.552066, AUPRC: 0.088224, Loss: 0.070436
[Checkpoint] Validation lifts - @0.5%: 2.117182, @1%: 1.450919, @5%: 1.048644, @10%: 1.046316

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.070629

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.070556

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.070407

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.070412

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.070311
[Checkpoint] Validation metrics - AUC: 0.535640, AUPRC: 0.083472, Loss: 0.070242
[Checkpoint] Validation lifts - @0.5%: 0.937609, @1%: 0.944609, @5%: 0.973094, @10%: 0.984368

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.070275

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.070187

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.070100

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.070054

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.069975
[Checkpoint] Validation metrics - AUC: 0.525243, AUPRC: 0.082033, Loss: 0.070036
[Checkpoint] Validation lifts - @0.5%: 0.967855, @1%: 0.944609, @5%: 0.965539, @10%: 0.997211

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.069971

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.069864

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.069804

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.069710

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.069683
[Checkpoint] Validation metrics - AUC: 0.517655, AUPRC: 0.081211, Loss: 0.069815
[Checkpoint] Validation lifts - @0.5%: 1.028345, @1%: 1.103303, @5%: 0.991226, @10%: 1.007032

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.069617

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.069545

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.069531

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.069454

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.069368
[Checkpoint] Validation metrics - AUC: 0.508092, AUPRC: 0.079736, Loss: 0.069586
[Checkpoint] Validation lifts - @0.5%: 0.998100, @1%: 1.080633, @5%: 1.010869, @10%: 0.993433

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.069295

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.069279

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.069214

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.069158

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.069077
[Checkpoint] Validation metrics - AUC: 0.504378, AUPRC: 0.079048, Loss: 0.069354
[Checkpoint] Validation lifts - @0.5%: 1.119082, @1%: 0.974836, @5%: 1.012380, @10%: 0.988901

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.069067

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.069000

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.068936

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.068859

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.068769
[Checkpoint] Validation metrics - AUC: 0.523058, AUPRC: 0.081632, Loss: 0.069119
[Checkpoint] Validation lifts - @0.5%: 0.756136, @1%: 0.906825, @5%: 1.000292, @10%: 0.985879

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.068729

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.068711

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.068651

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.068589

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.068505
[Checkpoint] Validation metrics - AUC: 0.557637, AUPRC: 0.087674, Loss: 0.068884
[Checkpoint] Validation lifts - @0.5%: 0.710768, @1%: 0.884154, @5%: 0.979138, @10%: 0.985879

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.068467

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.068424

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.068402

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.068294

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.068250
[Checkpoint] Validation metrics - AUC: 0.579299, AUPRC: 0.092540, Loss: 0.068639
[Checkpoint] Validation lifts - @0.5%: 1.285432, @1%: 1.125974, @5%: 0.998781, @10%: 0.998722

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.068221

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.068154

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.068118

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.068033

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.067994
[Checkpoint] Validation metrics - AUC: 0.577925, AUPRC: 0.091267, Loss: 0.068383
[Checkpoint] Validation lifts - @0.5%: 1.058591, @1%: 0.959723, @5%: 0.936829, @10%: 0.974547

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.067874

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.067883

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.067832

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.067738

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.067712
[Checkpoint] Validation metrics - AUC: 0.577300, AUPRC: 0.091097, Loss: 0.068124
[Checkpoint] Validation lifts - @0.5%: 1.164450, @1%: 0.997507, @5%: 0.921719, @10%: 0.953394

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.067670

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.067582

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.067553

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.067505

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.067407
[Checkpoint] Validation metrics - AUC: 0.578120, AUPRC: 0.091489, Loss: 0.067907
[Checkpoint] Validation lifts - @0.5%: 1.028345, @1%: 0.937052, @5%: 0.846168, @10%: 0.942817

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.067358

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.067327

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.067250

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.067158

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.067148
[Checkpoint] Validation metrics - AUC: 0.576314, AUPRC: 0.091694, Loss: 0.067700
[Checkpoint] Validation lifts - @0.5%: 1.164450, @1%: 1.005064, @5%: 0.835591, @10%: 0.929975

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.067060

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.067009

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.066964

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.066888

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.066834
[Checkpoint] Validation metrics - AUC: 0.571814, AUPRC: 0.090474, Loss: 0.067502
[Checkpoint] Validation lifts - @0.5%: 0.937609, @1%: 0.914381, @5%: 0.811415, @10%: 0.888424

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.066789

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.066697

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.066669

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.066593

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.066571
[Checkpoint] Validation metrics - AUC: 0.567388, AUPRC: 0.088698, Loss: 0.067343
[Checkpoint] Validation lifts - @0.5%: 0.846873, @1%: 0.831256, @5%: 0.750975, @10%: 0.866516

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.066499

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.066417

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.066363

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.066344

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.066255
[Checkpoint] Validation metrics - AUC: 0.562740, AUPRC: 0.086646, Loss: 0.067241
[Checkpoint] Validation lifts - @0.5%: 0.680523, @1%: 0.649891, @5%: 0.698089, @10%: 0.800790

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.066205

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.066101

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.066068

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.065984

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.065904
[Checkpoint] Validation metrics - AUC: 0.561223, AUPRC: 0.087295, Loss: 0.067252
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.045341, @5%: 0.781195, @10%: 1.192876

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.065835

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.065808

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.065710

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.065649

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.065537
[Checkpoint] Validation metrics - AUC: 0.560154, AUPRC: 0.087841, Loss: 0.067419
[Checkpoint] Validation lifts - @0.5%: 0.196595, @1%: 0.324945, @5%: 0.725287, @10%: 1.213273

[Checkpoint] --- Epoch 96/200 ---
[Checkpoint] Epoch 96 training loss: 0.065503

[Checkpoint] --- Epoch 97/200 ---
[Checkpoint] Epoch 97 training loss: 0.065407

[Checkpoint] --- Epoch 98/200 ---
[Checkpoint] Epoch 98 training loss: 0.065340

[Checkpoint] --- Epoch 99/200 ---
[Checkpoint] Epoch 99 training loss: 0.065288

[Checkpoint] --- Epoch 100/200 ---
[Checkpoint] Epoch 100 training loss: 0.065215
[Checkpoint] Validation metrics - AUC: 0.563693, AUPRC: 0.090152, Loss: 0.067124
[Checkpoint] Validation lifts - @0.5%: 0.907364, @1%: 0.702789, @5%: 0.735864, @10%: 1.235181

[Checkpoint] --- Epoch 101/200 ---
[Checkpoint] Epoch 101 training loss: 0.065147

[Checkpoint] --- Epoch 102/200 ---
[Checkpoint] Epoch 102 training loss: 0.065034

[Checkpoint] --- Epoch 103/200 ---
[Checkpoint] Epoch 103 training loss: 0.064991

[Checkpoint] --- Epoch 104/200 ---
[Checkpoint] Epoch 104 training loss: 0.064914

[Checkpoint] --- Epoch 105/200 ---
[Checkpoint] Epoch 105 training loss: 0.064829
[Checkpoint] Validation metrics - AUC: 0.567524, AUPRC: 0.090148, Loss: 0.066349
[Checkpoint] Validation lifts - @0.5%: 0.635155, @1%: 0.566765, @5%: 0.686001, @10%: 1.223850

[Checkpoint] --- Epoch 106/200 ---
[Checkpoint] Epoch 106 training loss: 0.064733

[Checkpoint] --- Epoch 107/200 ---
[Checkpoint] Epoch 107 training loss: 0.064682

[Checkpoint] --- Epoch 108/200 ---
[Checkpoint] Epoch 108 training loss: 0.064614

[Checkpoint] --- Epoch 109/200 ---
[Checkpoint] Epoch 109 training loss: 0.064513

[Checkpoint] --- Epoch 110/200 ---
[Checkpoint] Epoch 110 training loss: 0.064433
[Checkpoint] Validation metrics - AUC: 0.573619, AUPRC: 0.090560, Loss: 0.065584
[Checkpoint] Validation lifts - @0.5%: 0.347823, @1%: 0.377844, @5%: 0.643692, @10%: 1.210251

[Checkpoint] --- Epoch 111/200 ---
[Checkpoint] Epoch 111 training loss: 0.064392

[Checkpoint] --- Epoch 112/200 ---
[Checkpoint] Epoch 112 training loss: 0.064276

[Checkpoint] --- Epoch 113/200 ---
[Checkpoint] Epoch 113 training loss: 0.064227

[Checkpoint] --- Epoch 114/200 ---
[Checkpoint] Epoch 114 training loss: 0.064143

[Checkpoint] --- Epoch 115/200 ---
[Checkpoint] Epoch 115 training loss: 0.064074
[Checkpoint] Validation metrics - AUC: 0.579222, AUPRC: 0.091742, Loss: 0.064938
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.211592, @5%: 0.639159, @10%: 1.206474

[Checkpoint] --- Epoch 116/200 ---
[Checkpoint] Epoch 116 training loss: 0.063977

[Checkpoint] --- Epoch 117/200 ---
[Checkpoint] Epoch 117 training loss: 0.063908

[Checkpoint] --- Epoch 118/200 ---
[Checkpoint] Epoch 118 training loss: 0.063820

[Checkpoint] --- Epoch 119/200 ---
[Checkpoint] Epoch 119 training loss: 0.063784

[Checkpoint] --- Epoch 120/200 ---
[Checkpoint] Epoch 120 training loss: 0.063699
[Checkpoint] Validation metrics - AUC: 0.580350, AUPRC: 0.092630, Loss: 0.064381
[Checkpoint] Validation lifts - @0.5%: 0.514173, @1%: 0.408071, @5%: 0.695067, @10%: 1.246513

[Checkpoint] --- Epoch 121/200 ---
[Checkpoint] Epoch 121 training loss: 0.063609

[Checkpoint] --- Epoch 122/200 ---
[Checkpoint] Epoch 122 training loss: 0.063519

[Checkpoint] --- Epoch 123/200 ---
[Checkpoint] Epoch 123 training loss: 0.063454

[Checkpoint] --- Epoch 124/200 ---
[Checkpoint] Epoch 124 training loss: 0.063390

[Checkpoint] --- Epoch 125/200 ---
[Checkpoint] Epoch 125 training loss: 0.063312
[Checkpoint] Validation metrics - AUC: 0.580536, AUPRC: 0.095254, Loss: 0.063793
[Checkpoint] Validation lifts - @0.5%: 2.177673, @1%: 1.692739, @5%: 0.855235, @10%: 1.240470

[Checkpoint] --- Epoch 126/200 ---
[Checkpoint] Epoch 126 training loss: 0.063228

[Checkpoint] --- Epoch 127/200 ---
[Checkpoint] Epoch 127 training loss: 0.063155

[Checkpoint] --- Epoch 128/200 ---
[Checkpoint] Epoch 128 training loss: 0.063061

[Checkpoint] --- Epoch 129/200 ---
[Checkpoint] Epoch 129 training loss: 0.063000

[Checkpoint] --- Epoch 130/200 ---
[Checkpoint] Epoch 130 training loss: 0.062921
[Checkpoint] Validation metrics - AUC: 0.580096, AUPRC: 0.095409, Loss: 0.063353
[Checkpoint] Validation lifts - @0.5%: 2.162550, @1%: 1.919445, @5%: 0.886966, @10%: 1.220828

[Checkpoint] --- Epoch 131/200 ---
[Checkpoint] Epoch 131 training loss: 0.062818

[Checkpoint] --- Epoch 132/200 ---
[Checkpoint] Epoch 132 training loss: 0.062751

[Checkpoint] --- Epoch 133/200 ---
[Checkpoint] Epoch 133 training loss: 0.062686

[Checkpoint] --- Epoch 134/200 ---
[Checkpoint] Epoch 134 training loss: 0.062572

[Checkpoint] --- Epoch 135/200 ---
[Checkpoint] Epoch 135 training loss: 0.062506
[Checkpoint] Validation metrics - AUC: 0.579594, AUPRC: 0.092916, Loss: 0.063016
[Checkpoint] Validation lifts - @0.5%: 0.892241, @1%: 0.680118, @5%: 0.729820, @10%: 1.221583

[Checkpoint] --- Epoch 136/200 ---
[Checkpoint] Epoch 136 training loss: 0.062428

[Checkpoint] --- Epoch 137/200 ---
[Checkpoint] Epoch 137 training loss: 0.062338

[Checkpoint] --- Epoch 138/200 ---
[Checkpoint] Epoch 138 training loss: 0.062277

[Checkpoint] --- Epoch 139/200 ---
[Checkpoint] Epoch 139 training loss: 0.062219

[Checkpoint] --- Epoch 140/200 ---
[Checkpoint] Epoch 140 training loss: 0.062093
[Checkpoint] Validation metrics - AUC: 0.579044, AUPRC: 0.091636, Loss: 0.062615
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 0.256934, @5%: 0.646714, @10%: 1.201941

[Checkpoint] --- Epoch 141/200 ---
[Checkpoint] Epoch 141 training loss: 0.062071

[Checkpoint] --- Epoch 142/200 ---
[Checkpoint] Epoch 142 training loss: 0.061923

[Checkpoint] --- Epoch 143/200 ---
[Checkpoint] Epoch 143 training loss: 0.061837

[Checkpoint] --- Epoch 144/200 ---
[Checkpoint] Epoch 144 training loss: 0.061764

[Checkpoint] --- Epoch 145/200 ---
[Checkpoint] Epoch 145 training loss: 0.061685
[Checkpoint] Validation metrics - AUC: 0.579217, AUPRC: 0.092570, Loss: 0.062150
[Checkpoint] Validation lifts - @0.5%: 0.846873, @1%: 0.710346, @5%: 0.750975, @10%: 1.177011

[Checkpoint] --- Epoch 146/200 ---
[Checkpoint] Epoch 146 training loss: 0.061610

[Checkpoint] --- Epoch 147/200 ---
[Checkpoint] Epoch 147 training loss: 0.061517

[Checkpoint] --- Epoch 148/200 ---
[Checkpoint] Epoch 148 training loss: 0.061437

[Checkpoint] --- Epoch 149/200 ---
[Checkpoint] Epoch 149 training loss: 0.061346

[Checkpoint] --- Epoch 150/200 ---
[Checkpoint] Epoch 150 training loss: 0.061269
[Checkpoint] Validation metrics - AUC: 0.578053, AUPRC: 0.092071, Loss: 0.061726
[Checkpoint] Validation lifts - @0.5%: 0.801505, @1%: 0.596993, @5%: 0.740397, @10%: 1.145281

[Checkpoint] --- Epoch 151/200 ---
[Checkpoint] Epoch 151 training loss: 0.061176

[Checkpoint] --- Epoch 152/200 ---
[Checkpoint] Epoch 152 training loss: 0.061104

[Checkpoint] --- Epoch 153/200 ---
[Checkpoint] Epoch 153 training loss: 0.060982

[Checkpoint] --- Epoch 154/200 ---
[Checkpoint] Epoch 154 training loss: 0.060890

[Checkpoint] --- Epoch 155/200 ---
[Checkpoint] Epoch 155 training loss: 0.060797
[Checkpoint] Validation metrics - AUC: 0.576760, AUPRC: 0.090939, Loss: 0.061195
[Checkpoint] Validation lifts - @0.5%: 0.287332, @1%: 0.204036, @5%: 0.681468, @10%: 1.124128

[Checkpoint] --- Epoch 156/200 ---
[Checkpoint] Epoch 156 training loss: 0.060737

[Checkpoint] --- Epoch 157/200 ---
[Checkpoint] Epoch 157 training loss: 0.060617

[Checkpoint] --- Epoch 158/200 ---
[Checkpoint] Epoch 158 training loss: 0.060578

[Checkpoint] --- Epoch 159/200 ---
[Checkpoint] Epoch 159 training loss: 0.060417

[Checkpoint] --- Epoch 160/200 ---
[Checkpoint] Epoch 160 training loss: 0.060343
[Checkpoint] Validation metrics - AUC: 0.574842, AUPRC: 0.090277, Loss: 0.060666
[Checkpoint] Validation lifts - @0.5%: 0.120982, @1%: 0.113353, @5%: 0.652759, @10%: 1.072002

[Checkpoint] --- Epoch 161/200 ---
[Checkpoint] Epoch 161 training loss: 0.060246

[Checkpoint] --- Epoch 162/200 ---
[Checkpoint] Epoch 162 training loss: 0.060150

[Checkpoint] --- Epoch 163/200 ---
[Checkpoint] Epoch 163 training loss: 0.060058

[Checkpoint] --- Epoch 164/200 ---
[Checkpoint] Epoch 164 training loss: 0.059984

[Checkpoint] --- Epoch 165/200 ---
[Checkpoint] Epoch 165 training loss: 0.059882
[Checkpoint] Validation metrics - AUC: 0.572289, AUPRC: 0.089467, Loss: 0.060165
[Checkpoint] Validation lifts - @0.5%: 0.090736, @1%: 0.105796, @5%: 0.684490, @10%: 1.003254

[Checkpoint] --- Epoch 166/200 ---
[Checkpoint] Epoch 166 training loss: 0.059782

[Checkpoint] --- Epoch 167/200 ---
[Checkpoint] Epoch 167 training loss: 0.059651

[Checkpoint] --- Epoch 168/200 ---
[Checkpoint] Epoch 168 training loss: 0.059587

[Checkpoint] --- Epoch 169/200 ---
[Checkpoint] Epoch 169 training loss: 0.059474

[Checkpoint] --- Epoch 170/200 ---
[Checkpoint] Epoch 170 training loss: 0.059400
[Checkpoint] Validation metrics - AUC: 0.570251, AUPRC: 0.088862, Loss: 0.059682
[Checkpoint] Validation lifts - @0.5%: 0.015123, @1%: 0.022671, @5%: 0.690534, @10%: 0.951128

[Checkpoint] --- Epoch 171/200 ---
[Checkpoint] Epoch 171 training loss: 0.059243

[Checkpoint] --- Epoch 172/200 ---
[Checkpoint] Epoch 172 training loss: 0.059153

[Checkpoint] --- Epoch 173/200 ---
[Checkpoint] Epoch 173 training loss: 0.059083

[Checkpoint] --- Epoch 174/200 ---
[Checkpoint] Epoch 174 training loss: 0.058969

[Checkpoint] --- Epoch 175/200 ---
[Checkpoint] Epoch 175 training loss: 0.058876
[Checkpoint] Validation metrics - AUC: 0.567649, AUPRC: 0.088280, Loss: 0.059033
[Checkpoint] Validation lifts - @0.5%: 0.120982, @1%: 0.173808, @5%: 0.660314, @10%: 0.872559

[Checkpoint] --- Epoch 176/200 ---
[Checkpoint] Epoch 176 training loss: 0.058758

[Checkpoint] --- Epoch 177/200 ---
[Checkpoint] Epoch 177 training loss: 0.058665

[Checkpoint] --- Epoch 178/200 ---
[Checkpoint] Epoch 178 training loss: 0.058547

[Checkpoint] --- Epoch 179/200 ---
[Checkpoint] Epoch 179 training loss: 0.058445

[Checkpoint] --- Epoch 180/200 ---
[Checkpoint] Epoch 180 training loss: 0.058321
[Checkpoint] Validation metrics - AUC: 0.564309, AUPRC: 0.087903, Loss: 0.058530
[Checkpoint] Validation lifts - @0.5%: 0.529295, @1%: 0.468526, @5%: 0.607428, @10%: 0.807590

[Checkpoint] --- Epoch 181/200 ---
[Checkpoint] Epoch 181 training loss: 0.058191

[Checkpoint] --- Epoch 182/200 ---
[Checkpoint] Epoch 182 training loss: 0.058083

[Checkpoint] --- Epoch 183/200 ---
[Checkpoint] Epoch 183 training loss: 0.057979

[Checkpoint] --- Epoch 184/200 ---
[Checkpoint] Epoch 184 training loss: 0.057835

[Checkpoint] --- Epoch 185/200 ---
[Checkpoint] Epoch 185 training loss: 0.057764
[Checkpoint] Validation metrics - AUC: 0.560557, AUPRC: 0.086590, Loss: 0.057990
[Checkpoint] Validation lifts - @0.5%: 0.015123, @1%: 0.075569, @5%: 0.562098, @10%: 0.768306

[Checkpoint] --- Epoch 186/200 ---
[Checkpoint] Epoch 186 training loss: 0.057624

[Checkpoint] --- Epoch 187/200 ---
[Checkpoint] Epoch 187 training loss: 0.057512

[Checkpoint] --- Epoch 188/200 ---
[Checkpoint] Epoch 188 training loss: 0.057416

[Checkpoint] --- Epoch 189/200 ---
[Checkpoint] Epoch 189 training loss: 0.057294

[Checkpoint] --- Epoch 190/200 ---
[Checkpoint] Epoch 190 training loss: 0.057174
[Checkpoint] Validation metrics - AUC: 0.556546, AUPRC: 0.085505, Loss: 0.057282
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.436683, @10%: 0.737332

[Checkpoint] --- Epoch 191/200 ---
[Checkpoint] Epoch 191 training loss: 0.057082

[Checkpoint] --- Epoch 192/200 ---
[Checkpoint] Epoch 192 training loss: 0.056938

[Checkpoint] --- Epoch 193/200 ---
[Checkpoint] Epoch 193 training loss: 0.056812

[Checkpoint] --- Epoch 194/200 ---
[Checkpoint] Epoch 194 training loss: 0.056688

[Checkpoint] --- Epoch 195/200 ---
[Checkpoint] Epoch 195 training loss: 0.056572
[Checkpoint] Validation metrics - AUC: 0.552032, AUPRC: 0.084491, Loss: 0.056676
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.368688, @10%: 0.664052

[Checkpoint] --- Epoch 196/200 ---
[Checkpoint] Epoch 196 training loss: 0.056448

[Checkpoint] --- Epoch 197/200 ---
[Checkpoint] Epoch 197 training loss: 0.056366

[Checkpoint] --- Epoch 198/200 ---
[Checkpoint] Epoch 198 training loss: 0.056210

[Checkpoint] --- Epoch 199/200 ---
[Checkpoint] Epoch 199 training loss: 0.056077

[Checkpoint] --- Epoch 200/200 ---
[Checkpoint] Epoch 200 training loss: 0.055943
[Checkpoint] Validation metrics - AUC: 0.547192, AUPRC: 0.083601, Loss: 0.056244
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.370199, @10%: 0.615702
[Checkpoint] Configuration completed. Best AUPRC: 0.095409

[Checkpoint] ====== Configuration 51/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 52/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 5390660
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 53/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 54/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 55/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 56/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 5392772
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 57/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 58/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 59/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 60/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 5412644
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 61/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 62/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 63/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 64/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 5445668
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.059487

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.058485

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.057648

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.057250

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.056644
[Checkpoint] Validation metrics - AUC: 0.545995, AUPRC: 0.089064, Loss: 0.053348
[Checkpoint] Validation lifts - @0.5%: 0.861995, @1%: 0.869040, @5%: 1.063755, @10%: 1.118085

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.056326

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.055973

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.055708

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.055396

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.055254
[Checkpoint] Validation metrics - AUC: 0.522177, AUPRC: 0.081873, Loss: 0.052870
[Checkpoint] Validation lifts - @0.5%: 0.302455, @1%: 0.392957, @5%: 0.817459, @10%: 1.007787

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.054981

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.054788

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.054669

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.054383

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.054310
[Checkpoint] Validation metrics - AUC: 0.503497, AUPRC: 0.076988, Loss: 0.052707
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.392957, @5%: 0.667869, @10%: 0.821188

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.054027

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.053915

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.053738

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.053637

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.053460
[Checkpoint] Validation metrics - AUC: 0.476478, AUPRC: 0.072338, Loss: 0.051216
[Checkpoint] Validation lifts - @0.5%: 0.438559, @1%: 0.476083, @5%: 0.692045, @10%: 0.794747

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.053390

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.053222

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.053160

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.052905

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.052864
[Checkpoint] Validation metrics - AUC: 0.469051, AUPRC: 0.073564, Loss: 0.049601
[Checkpoint] Validation lifts - @0.5%: 1.179573, @1%: 1.284668, @5%: 1.125706, @10%: 0.903533

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.052738

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.052619

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.052478

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.052339

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.052207
[Checkpoint] Validation metrics - AUC: 0.526142, AUPRC: 0.084515, Loss: 0.049286
[Checkpoint] Validation lifts - @0.5%: 1.482027, @1%: 1.405578, @5%: 1.308539, @10%: 1.133194

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.052165

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.052070

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.052011

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.051884

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.051808
[Checkpoint] Validation metrics - AUC: 0.548049, AUPRC: 0.088899, Loss: 0.049078
[Checkpoint] Validation lifts - @0.5%: 1.527396, @1%: 1.571829, @5%: 1.353870, @10%: 1.140749

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.051602

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.051526

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.051469

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.051310

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.051287
[Checkpoint] Validation metrics - AUC: 0.533236, AUPRC: 0.087276, Loss: 0.048812
[Checkpoint] Validation lifts - @0.5%: 1.769359, @1%: 1.821206, @5%: 1.452086, @10%: 1.145281

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.051175

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.051038

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.050972

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.050852

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.050762
[Checkpoint] Validation metrics - AUC: 0.532426, AUPRC: 0.089329, Loss: 0.048486
[Checkpoint] Validation lifts - @0.5%: 2.359146, @1%: 2.168822, @5%: 1.526125, @10%: 1.152081

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.050623

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.050619

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.050474

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.050317

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.050231
[Checkpoint] Validation metrics - AUC: 0.536111, AUPRC: 0.091023, Loss: 0.047761
[Checkpoint] Validation lifts - @0.5%: 2.283532, @1%: 2.221720, @5%: 1.556346, @10%: 1.148303

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.050071

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.049964

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.049992

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.049821

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.049794
[Checkpoint] Validation metrics - AUC: 0.530661, AUPRC: 0.089558, Loss: 0.046799
[Checkpoint] Validation lifts - @0.5%: 2.283532, @1%: 2.108367, @5%: 1.465685, @10%: 1.149814

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.049634

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.049589

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.049476

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.049372

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.049368
[Checkpoint] Validation metrics - AUC: 0.525177, AUPRC: 0.088096, Loss: 0.045878
[Checkpoint] Validation lifts - @0.5%: 2.192796, @1%: 2.032798, @5%: 1.433953, @10%: 1.149814

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.049206

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.049128

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.048956

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.048921

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.048796
[Checkpoint] Validation metrics - AUC: 0.522023, AUPRC: 0.087192, Loss: 0.045175
[Checkpoint] Validation lifts - @0.5%: 2.086936, @1%: 1.979900, @5%: 1.391645, @10%: 1.150570

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.048691

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.048614

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.048556

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.048466

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.048360
[Checkpoint] Validation metrics - AUC: 0.515848, AUPRC: 0.085990, Loss: 0.044471
[Checkpoint] Validation lifts - @0.5%: 2.011323, @1%: 1.904332, @5%: 1.376535, @10%: 1.143770

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.048241

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.048203

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.048095

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.047934

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.047836
[Checkpoint] Validation metrics - AUC: 0.520778, AUPRC: 0.086576, Loss: 0.044003
[Checkpoint] Validation lifts - @0.5%: 1.965955, @1%: 1.843877, @5%: 1.356892, @10%: 1.146037

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.047823

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.047647

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.047588

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.047423

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.047364
[Checkpoint] Validation metrics - AUC: 0.517663, AUPRC: 0.086016, Loss: 0.043718
[Checkpoint] Validation lifts - @0.5%: 1.920586, @1%: 1.851433, @5%: 1.344803, @10%: 1.147548

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.047318

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.047143

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.047002

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.046941

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.046846
[Checkpoint] Validation metrics - AUC: 0.516157, AUPRC: 0.085822, Loss: 0.043223
[Checkpoint] Validation lifts - @0.5%: 1.981077, @1%: 1.874104, @5%: 1.332715, @10%: 1.148303

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.046726

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.046620

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.046552

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.046410

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.046352
[Checkpoint] Validation metrics - AUC: 0.512745, AUPRC: 0.085255, Loss: 0.042594
[Checkpoint] Validation lifts - @0.5%: 1.981077, @1%: 1.919445, @5%: 1.331204, @10%: 1.147548

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.046259

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.046111

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.045970

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.045899

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.045851
[Checkpoint] Validation metrics - AUC: 0.507622, AUPRC: 0.084451, Loss: 0.042034
[Checkpoint] Validation lifts - @0.5%: 1.844973, @1%: 1.911888, @5%: 1.332715, @10%: 1.146037

[Checkpoint] --- Epoch 96/200 ---
[Checkpoint] Epoch 96 training loss: 0.045685

[Checkpoint] --- Epoch 97/200 ---
[Checkpoint] Epoch 97 training loss: 0.045588

[Checkpoint] --- Epoch 98/200 ---
[Checkpoint] Epoch 98 training loss: 0.045454

[Checkpoint] --- Epoch 99/200 ---
[Checkpoint] Epoch 99 training loss: 0.045406

[Checkpoint] --- Epoch 100/200 ---
[Checkpoint] Epoch 100 training loss: 0.045307
[Checkpoint] Validation metrics - AUC: 0.506088, AUPRC: 0.083937, Loss: 0.041874
[Checkpoint] Validation lifts - @0.5%: 1.920586, @1%: 1.806092, @5%: 1.325160, @10%: 1.149059

[Checkpoint] --- Epoch 101/200 ---
[Checkpoint] Epoch 101 training loss: 0.045266

[Checkpoint] --- Epoch 102/200 ---
[Checkpoint] Epoch 102 training loss: 0.045111

[Checkpoint] --- Epoch 103/200 ---
[Checkpoint] Epoch 103 training loss: 0.044971

[Checkpoint] --- Epoch 104/200 ---
[Checkpoint] Epoch 104 training loss: 0.044944

[Checkpoint] --- Epoch 105/200 ---
[Checkpoint] Epoch 105 training loss: 0.044811
[Checkpoint] Validation metrics - AUC: 0.512122, AUPRC: 0.084510, Loss: 0.041540
[Checkpoint] Validation lifts - @0.5%: 2.026446, @1%: 1.753194, @5%: 1.316094, @10%: 1.144526

[Checkpoint] --- Epoch 106/200 ---
[Checkpoint] Epoch 106 training loss: 0.044708

[Checkpoint] --- Epoch 107/200 ---
[Checkpoint] Epoch 107 training loss: 0.044616

[Checkpoint] --- Epoch 108/200 ---
[Checkpoint] Epoch 108 training loss: 0.044446

[Checkpoint] --- Epoch 109/200 ---
[Checkpoint] Epoch 109 training loss: 0.044349

[Checkpoint] --- Epoch 110/200 ---
[Checkpoint] Epoch 110 training loss: 0.044251
[Checkpoint] Validation metrics - AUC: 0.506750, AUPRC: 0.083574, Loss: 0.041023
[Checkpoint] Validation lifts - @0.5%: 1.950832, @1%: 1.738080, @5%: 1.311561, @10%: 1.142260

[Checkpoint] --- Epoch 111/200 ---
[Checkpoint] Epoch 111 training loss: 0.044222

[Checkpoint] --- Epoch 112/200 ---
[Checkpoint] Epoch 112 training loss: 0.044099

[Checkpoint] --- Epoch 113/200 ---
[Checkpoint] Epoch 113 training loss: 0.043902

[Checkpoint] --- Epoch 114/200 ---
[Checkpoint] Epoch 114 training loss: 0.043933

[Checkpoint] --- Epoch 115/200 ---
[Checkpoint] Epoch 115 training loss: 0.043729
[Checkpoint] Validation metrics - AUC: 0.504366, AUPRC: 0.083000, Loss: 0.040712
[Checkpoint] Validation lifts - @0.5%: 1.814727, @1%: 1.700296, @5%: 1.308539, @10%: 1.141504

[Checkpoint] --- Epoch 116/200 ---
[Checkpoint] Epoch 116 training loss: 0.043658

[Checkpoint] --- Epoch 117/200 ---
[Checkpoint] Epoch 117 training loss: 0.043647

[Checkpoint] --- Epoch 118/200 ---
[Checkpoint] Epoch 118 training loss: 0.043409

[Checkpoint] --- Epoch 119/200 ---
[Checkpoint] Epoch 119 training loss: 0.043402

[Checkpoint] --- Epoch 120/200 ---
[Checkpoint] Epoch 120 training loss: 0.043271
[Checkpoint] Validation metrics - AUC: 0.507087, AUPRC: 0.083052, Loss: 0.040634
[Checkpoint] Validation lifts - @0.5%: 1.844973, @1%: 1.670069, @5%: 1.308539, @10%: 1.141504

[Checkpoint] --- Epoch 121/200 ---
[Checkpoint] Epoch 121 training loss: 0.043155

[Checkpoint] --- Epoch 122/200 ---
[Checkpoint] Epoch 122 training loss: 0.043113

[Checkpoint] --- Epoch 123/200 ---
[Checkpoint] Epoch 123 training loss: 0.042892

[Checkpoint] --- Epoch 124/200 ---
[Checkpoint] Epoch 124 training loss: 0.042735

[Checkpoint] --- Epoch 125/200 ---
[Checkpoint] Epoch 125 training loss: 0.042655
[Checkpoint] Validation metrics - AUC: 0.526022, AUPRC: 0.085842, Loss: 0.040778
[Checkpoint] Validation lifts - @0.5%: 1.875218, @1%: 1.579386, @5%: 1.316094, @10%: 1.142260
[Checkpoint] Early stopping at epoch 125 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.091023

[Checkpoint] ====== Configuration 65/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.178404

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.177629

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.177059

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.176610

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.176105
[Checkpoint] Validation metrics - AUC: 0.565816, AUPRC: 0.092270, Loss: 0.174785
[Checkpoint] Validation lifts - @0.5%: 2.585986, @1%: 1.654955, @5%: 1.152905, @10%: 1.075779

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.175765

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.175364

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.174927

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.174477

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.174124
[Checkpoint] Validation metrics - AUC: 0.560601, AUPRC: 0.094099, Loss: 0.173164
[Checkpoint] Validation lifts - @0.5%: 1.376168, @1%: 1.927002, @5%: 1.520081, @10%: 1.248024

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.173739

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.173349

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.172891

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.172550

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.172113
[Checkpoint] Validation metrics - AUC: 0.549321, AUPRC: 0.090193, Loss: 0.171457
[Checkpoint] Validation lifts - @0.5%: 1.058591, @1%: 1.216656, @5%: 1.449063, @10%: 1.224605

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.171740

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.171352

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.171029

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.170623

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.170252
[Checkpoint] Validation metrics - AUC: 0.545650, AUPRC: 0.089281, Loss: 0.169700
[Checkpoint] Validation lifts - @0.5%: 1.043468, @1%: 1.375351, @5%: 1.430931, @10%: 1.202697

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.169800

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.169486

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.169109

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.168700

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.168321
[Checkpoint] Validation metrics - AUC: 0.535329, AUPRC: 0.086869, Loss: 0.168002
[Checkpoint] Validation lifts - @0.5%: 1.028345, @1%: 1.216656, @5%: 1.420354, @10%: 1.191365

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.168019

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.167594

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.167198

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.166838

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.166467
[Checkpoint] Validation metrics - AUC: 0.523301, AUPRC: 0.084104, Loss: 0.166328
[Checkpoint] Validation lifts - @0.5%: 0.967855, @1%: 0.891711, @5%: 1.406755, @10%: 1.180033

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.166052

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.165672

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.165275

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.164947

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.164538
[Checkpoint] Validation metrics - AUC: 0.519444, AUPRC: 0.083165, Loss: 0.164548
[Checkpoint] Validation lifts - @0.5%: 0.922486, @1%: 0.869040, @5%: 1.399200, @10%: 1.158880

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.164099

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.163735

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.163366

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.162914

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.162516
[Checkpoint] Validation metrics - AUC: 0.524354, AUPRC: 0.083756, Loss: 0.162710
[Checkpoint] Validation lifts - @0.5%: 0.937609, @1%: 0.974836, @5%: 1.384090, @10%: 1.121862

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.162114

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.161721

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.161309

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.160949

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.160531
[Checkpoint] Validation metrics - AUC: 0.526393, AUPRC: 0.083798, Loss: 0.160802
[Checkpoint] Validation lifts - @0.5%: 0.952732, @1%: 1.027734, @5%: 1.379557, @10%: 1.117329

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.160122

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.159736

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.159318

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.158869

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.158495
[Checkpoint] Validation metrics - AUC: 0.534652, AUPRC: 0.085050, Loss: 0.158914
[Checkpoint] Validation lifts - @0.5%: 0.801505, @1%: 1.141088, @5%: 1.402222, @10%: 1.089377

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.157991

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.157555

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.157207

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.156680

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.156305
[Checkpoint] Validation metrics - AUC: 0.547697, AUPRC: 0.084645, Loss: 0.156873
[Checkpoint] Validation lifts - @0.5%: 0.982977, @1%: 1.095746, @5%: 0.883944, @10%: 0.883136

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.155843

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.155428

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.154942

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.154476

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.154060
[Checkpoint] Validation metrics - AUC: 0.555300, AUPRC: 0.084745, Loss: 0.154690
[Checkpoint] Validation lifts - @0.5%: 0.967855, @1%: 1.080633, @5%: 0.657292, @10%: 0.942062

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.153491

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.153099

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.152682

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.152158

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.151666
[Checkpoint] Validation metrics - AUC: 0.562776, AUPRC: 0.086948, Loss: 0.152264
[Checkpoint] Validation lifts - @0.5%: 1.119082, @1%: 0.710346, @5%: 0.536410, @10%: 0.973036

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.151178

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.150707

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.150211

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.149740

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.149183
[Checkpoint] Validation metrics - AUC: 0.562478, AUPRC: 0.086872, Loss: 0.149601
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.151137, @5%: 0.454816, @10%: 0.968503

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.148697

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.148150

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.147635

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.147122

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.146544
[Checkpoint] Validation metrics - AUC: 0.558398, AUPRC: 0.086312, Loss: 0.146667
[Checkpoint] Validation lifts - @0.5%: 0.045368, @1%: 0.022671, @5%: 0.365666, @10%: 0.928464

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.146086

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.145480

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.144953

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.144418

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.143812
[Checkpoint] Validation metrics - AUC: 0.555653, AUPRC: 0.085945, Loss: 0.143179
[Checkpoint] Validation lifts - @0.5%: 0.015123, @1%: 0.007557, @5%: 0.330912, @10%: 0.873315

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.143209

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.142726

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.142143

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.141527

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.140945
[Checkpoint] Validation metrics - AUC: 0.552080, AUPRC: 0.085201, Loss: 0.138939
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.287093, @10%: 0.791725
[Checkpoint] Early stopping at epoch 85 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.094099

[Checkpoint] ====== Configuration 66/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.081075

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.080575

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.080099

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.079782

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.079399
[Checkpoint] Validation metrics - AUC: 0.584773, AUPRC: 0.096850, Loss: 0.078660
[Checkpoint] Validation lifts - @0.5%: 2.283532, @1%: 1.564272, @5%: 1.081887, @10%: 1.031962

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.079124

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.078858

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.078558

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.078290

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.078076
[Checkpoint] Validation metrics - AUC: 0.584077, AUPRC: 0.095653, Loss: 0.077620
[Checkpoint] Validation lifts - @0.5%: 1.860096, @1%: 1.435806, @5%: 1.127217, @10%: 1.034984

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.077791

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.077553

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.077282

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.077037

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.076834
[Checkpoint] Validation metrics - AUC: 0.584875, AUPRC: 0.098252, Loss: 0.076562
[Checkpoint] Validation lifts - @0.5%: 2.994300, @1%: 2.138595, @5%: 1.183125, @10%: 1.073512

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.076543

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.076317

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.076062

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.075804

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.075564
[Checkpoint] Validation metrics - AUC: 0.584103, AUPRC: 0.099253, Loss: 0.075540
[Checkpoint] Validation lifts - @0.5%: 2.964055, @1%: 2.599564, @5%: 1.319116, @10%: 1.144526

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.075316

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.075127

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.074862

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.074640

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.074387
[Checkpoint] Validation metrics - AUC: 0.583098, AUPRC: 0.098019, Loss: 0.074540
[Checkpoint] Validation lifts - @0.5%: 2.873318, @1%: 1.942116, @5%: 1.338759, @10%: 1.141504

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.074191

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.073943

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.073727

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.073489

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.073275
[Checkpoint] Validation metrics - AUC: 0.585929, AUPRC: 0.098422, Loss: 0.073532
[Checkpoint] Validation lifts - @0.5%: 2.419636, @1%: 1.390464, @5%: 1.078865, @10%: 1.435379

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.073048

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.072750

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.072577

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.072334

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.072092
[Checkpoint] Validation metrics - AUC: 0.585781, AUPRC: 0.096349, Loss: 0.072530
[Checkpoint] Validation lifts - @0.5%: 0.998100, @1%: 1.012621, @5%: 0.914164, @10%: 1.408938

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.071854

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.071609

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.071396

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.071139

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.070932
[Checkpoint] Validation metrics - AUC: 0.581458, AUPRC: 0.092913, Loss: 0.071550
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 1.148644, @5%: 0.725287, @10%: 1.316016

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.070694

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.070474

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.070211

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.069965

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.069727
[Checkpoint] Validation metrics - AUC: 0.583454, AUPRC: 0.093613, Loss: 0.070477
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 1.141088, @5%: 0.702622, @10%: 1.296374

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.069455

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.069241

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.068989

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.068721

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.068497
[Checkpoint] Validation metrics - AUC: 0.583664, AUPRC: 0.093632, Loss: 0.069371
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 1.148644, @5%: 0.676935, @10%: 1.281265

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.068257

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.067972

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.067744

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.067499

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.067194
[Checkpoint] Validation metrics - AUC: 0.582231, AUPRC: 0.093169, Loss: 0.068268
[Checkpoint] Validation lifts - @0.5%: 0.272209, @1%: 1.118417, @5%: 0.666358, @10%: 1.268422

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.066945

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.066693

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.066428

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.066169

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.065896
[Checkpoint] Validation metrics - AUC: 0.578232, AUPRC: 0.092136, Loss: 0.067240
[Checkpoint] Validation lifts - @0.5%: 0.257086, @1%: 1.065519, @5%: 0.657292, @10%: 1.259356

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.065632

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.065369

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.065105

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.064816

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.064553
[Checkpoint] Validation metrics - AUC: 0.574926, AUPRC: 0.091331, Loss: 0.066120
[Checkpoint] Validation lifts - @0.5%: 0.257086, @1%: 1.057962, @5%: 0.633115, @10%: 1.242736

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.064266

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.063986

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.063735

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.063462

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.063163
[Checkpoint] Validation metrics - AUC: 0.572462, AUPRC: 0.090548, Loss: 0.064855
[Checkpoint] Validation lifts - @0.5%: 0.241964, @1%: 0.680118, @5%: 0.589296, @10%: 1.217806

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.062861

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.062595

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.062281

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.061988

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.061740
[Checkpoint] Validation metrics - AUC: 0.572984, AUPRC: 0.090073, Loss: 0.063337
[Checkpoint] Validation lifts - @0.5%: 0.196595, @1%: 0.219149, @5%: 0.540943, @10%: 1.199675

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.061381

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.061112

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.060790

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.060474

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.060171
[Checkpoint] Validation metrics - AUC: 0.570181, AUPRC: 0.089250, Loss: 0.061893
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.007557, @5%: 0.494102, @10%: 1.127150

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.059858

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.059549

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.059216

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.058926

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.058564
[Checkpoint] Validation metrics - AUC: 0.565143, AUPRC: 0.087882, Loss: 0.060520
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.404952, @10%: 1.056892

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.058240

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.057898

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.057568

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.057204

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.056905
[Checkpoint] Validation metrics - AUC: 0.561029, AUPRC: 0.086941, Loss: 0.058357
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.327890, @10%: 0.957171

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.056522

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.056189

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.055784

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.055434

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.055020
[Checkpoint] Validation metrics - AUC: 0.555666, AUPRC: 0.085696, Loss: 0.057044
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.279538, @10%: 0.860472
[Checkpoint] Early stopping at epoch 95 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.099253

[Checkpoint] ====== Configuration 67/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 68/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 5470628
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 69/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 70/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.092103

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.089408

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.088019

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.086966

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.086205
[Checkpoint] Validation metrics - AUC: 0.532085, AUPRC: 0.086399, Loss: 0.080779
[Checkpoint] Validation lifts - @0.5%: 1.028345, @1%: 1.261997, @5%: 1.375024, @10%: 1.146037

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.085607

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.085007

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.084520

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.084201

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.083710
[Checkpoint] Validation metrics - AUC: 0.504625, AUPRC: 0.076781, Loss: 0.079866
[Checkpoint] Validation lifts - @0.5%: 0.438559, @1%: 0.468526, @5%: 0.702622, @10%: 0.832520

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.083285

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.082838

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.082604

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.082214

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.081995
[Checkpoint] Validation metrics - AUC: 0.491948, AUPRC: 0.075001, Loss: 0.079372
[Checkpoint] Validation lifts - @0.5%: 0.423436, @1%: 0.476083, @5%: 0.702622, @10%: 0.817411

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.081808

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.081458

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.081092

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.080906

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.080673
[Checkpoint] Validation metrics - AUC: 0.500107, AUPRC: 0.083255, Loss: 0.080855
[Checkpoint] Validation lifts - @0.5%: 1.875218, @1%: 1.798535, @5%: 1.358403, @10%: 1.143015

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.080398

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.080186

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.079770

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.079576

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.079451
[Checkpoint] Validation metrics - AUC: 0.498648, AUPRC: 0.084586, Loss: 0.076770
[Checkpoint] Validation lifts - @0.5%: 2.298655, @1%: 2.138595, @5%: 1.438486, @10%: 1.148303

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.079208

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.078993

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.078683

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.078590

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.078280
[Checkpoint] Validation metrics - AUC: 0.506865, AUPRC: 0.084921, Loss: 0.069939
[Checkpoint] Validation lifts - @0.5%: 2.238164, @1%: 1.874104, @5%: 1.331204, @10%: 1.155102

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.078011

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.077824

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.077568

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.077244

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.077090
[Checkpoint] Validation metrics - AUC: 0.511624, AUPRC: 0.085139, Loss: 0.065535
[Checkpoint] Validation lifts - @0.5%: 1.996200, @1%: 1.851433, @5%: 1.304006, @10%: 1.154347

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.076845

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.076564

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.076365

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.076246

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.075974
[Checkpoint] Validation metrics - AUC: 0.512812, AUPRC: 0.085116, Loss: 0.062177
[Checkpoint] Validation lifts - @0.5%: 1.890341, @1%: 1.927002, @5%: 1.282852, @10%: 1.161146

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.075706

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.075422

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.075274

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.075064

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.074788
[Checkpoint] Validation metrics - AUC: 0.516302, AUPRC: 0.085557, Loss: 0.059649
[Checkpoint] Validation lifts - @0.5%: 1.890341, @1%: 1.896775, @5%: 1.270764, @10%: 1.161902

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.074538

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.074374

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.073999

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.073744

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.073536
[Checkpoint] Validation metrics - AUC: 0.511799, AUPRC: 0.084791, Loss: 0.057362
[Checkpoint] Validation lifts - @0.5%: 1.829850, @1%: 1.881661, @5%: 1.269253, @10%: 1.158124

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.073299

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.073045

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.072851

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.072614

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.072337
[Checkpoint] Validation metrics - AUC: 0.518233, AUPRC: 0.085686, Loss: 0.054576
[Checkpoint] Validation lifts - @0.5%: 1.860096, @1%: 1.874104, @5%: 1.269253, @10%: 1.159635

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.072134

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.072003

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.071719

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.071587

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.071155
[Checkpoint] Validation metrics - AUC: 0.523809, AUPRC: 0.086519, Loss: 0.052012
[Checkpoint] Validation lifts - @0.5%: 1.814727, @1%: 1.843877, @5%: 1.264720, @10%: 1.162657

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.070935

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.070679

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.070542

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.070108

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.069887
[Checkpoint] Validation metrics - AUC: 0.528149, AUPRC: 0.087333, Loss: 0.049805
[Checkpoint] Validation lifts - @0.5%: 1.875218, @1%: 1.828763, @5%: 1.264720, @10%: 1.167190

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.069742

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.069442

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.069316

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.069009

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.068666
[Checkpoint] Validation metrics - AUC: 0.544021, AUPRC: 0.090195, Loss: 0.047717
[Checkpoint] Validation lifts - @0.5%: 1.905464, @1%: 1.821206, @5%: 1.266231, @10%: 1.167190

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.068605

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.068202

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.067986

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.067639

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.067344
[Checkpoint] Validation metrics - AUC: 0.541968, AUPRC: 0.089806, Loss: 0.045779
[Checkpoint] Validation lifts - @0.5%: 1.890341, @1%: 1.828763, @5%: 1.267742, @10%: 1.167945

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.067122

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.066918

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.066611

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.066412

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.066134
[Checkpoint] Validation metrics - AUC: 0.543940, AUPRC: 0.090255, Loss: 0.044813
[Checkpoint] Validation lifts - @0.5%: 1.920586, @1%: 1.821206, @5%: 1.267742, @10%: 1.165679

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.065711

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.065621

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.065289

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.065059

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.064847
[Checkpoint] Validation metrics - AUC: 0.547394, AUPRC: 0.090862, Loss: 0.043743
[Checkpoint] Validation lifts - @0.5%: 1.905464, @1%: 1.813649, @5%: 1.267742, @10%: 1.170212

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.064456

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.064271

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.063893

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.063725

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.063374
[Checkpoint] Validation metrics - AUC: 0.547762, AUPRC: 0.090924, Loss: 0.042891
[Checkpoint] Validation lifts - @0.5%: 1.905464, @1%: 1.806092, @5%: 1.266231, @10%: 1.168701

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.063099

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.062904

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.062568

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.062239

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.062059
[Checkpoint] Validation metrics - AUC: 0.547423, AUPRC: 0.090928, Loss: 0.042270
[Checkpoint] Validation lifts - @0.5%: 1.860096, @1%: 1.783422, @5%: 1.264720, @10%: 1.174744

[Checkpoint] --- Epoch 96/200 ---
[Checkpoint] Epoch 96 training loss: 0.061749

[Checkpoint] --- Epoch 97/200 ---
[Checkpoint] Epoch 97 training loss: 0.061549

[Checkpoint] --- Epoch 98/200 ---
[Checkpoint] Epoch 98 training loss: 0.061170

[Checkpoint] --- Epoch 99/200 ---
[Checkpoint] Epoch 99 training loss: 0.060971

[Checkpoint] --- Epoch 100/200 ---
[Checkpoint] Epoch 100 training loss: 0.060715
[Checkpoint] Validation metrics - AUC: 0.547321, AUPRC: 0.090975, Loss: 0.042102
[Checkpoint] Validation lifts - @0.5%: 1.860096, @1%: 1.768308, @5%: 1.267742, @10%: 1.173989

[Checkpoint] --- Epoch 101/200 ---
[Checkpoint] Epoch 101 training loss: 0.060378

[Checkpoint] --- Epoch 102/200 ---
[Checkpoint] Epoch 102 training loss: 0.060108

[Checkpoint] --- Epoch 103/200 ---
[Checkpoint] Epoch 103 training loss: 0.059786

[Checkpoint] --- Epoch 104/200 ---
[Checkpoint] Epoch 104 training loss: 0.059469

[Checkpoint] --- Epoch 105/200 ---
[Checkpoint] Epoch 105 training loss: 0.059198
[Checkpoint] Validation metrics - AUC: 0.547078, AUPRC: 0.090899, Loss: 0.041916
[Checkpoint] Validation lifts - @0.5%: 1.829850, @1%: 1.753194, @5%: 1.267742, @10%: 1.170967

[Checkpoint] --- Epoch 106/200 ---
[Checkpoint] Epoch 106 training loss: 0.058849

[Checkpoint] --- Epoch 107/200 ---
[Checkpoint] Epoch 107 training loss: 0.058616

[Checkpoint] --- Epoch 108/200 ---
[Checkpoint] Epoch 108 training loss: 0.058448

[Checkpoint] --- Epoch 109/200 ---
[Checkpoint] Epoch 109 training loss: 0.058021

[Checkpoint] --- Epoch 110/200 ---
[Checkpoint] Epoch 110 training loss: 0.057775
[Checkpoint] Validation metrics - AUC: 0.547073, AUPRC: 0.090871, Loss: 0.041950
[Checkpoint] Validation lifts - @0.5%: 1.844973, @1%: 1.775865, @5%: 1.267742, @10%: 1.171723

[Checkpoint] --- Epoch 111/200 ---
[Checkpoint] Epoch 111 training loss: 0.057447

[Checkpoint] --- Epoch 112/200 ---
[Checkpoint] Epoch 112 training loss: 0.057272

[Checkpoint] --- Epoch 113/200 ---
[Checkpoint] Epoch 113 training loss: 0.056931

[Checkpoint] --- Epoch 114/200 ---
[Checkpoint] Epoch 114 training loss: 0.056751

[Checkpoint] --- Epoch 115/200 ---
[Checkpoint] Epoch 115 training loss: 0.056560
[Checkpoint] Validation metrics - AUC: 0.544373, AUPRC: 0.089952, Loss: 0.042041
[Checkpoint] Validation lifts - @0.5%: 1.860096, @1%: 1.806092, @5%: 1.267742, @10%: 1.168701

[Checkpoint] --- Epoch 116/200 ---
[Checkpoint] Epoch 116 training loss: 0.056015

[Checkpoint] --- Epoch 117/200 ---
[Checkpoint] Epoch 117 training loss: 0.055868

[Checkpoint] --- Epoch 118/200 ---
[Checkpoint] Epoch 118 training loss: 0.055570

[Checkpoint] --- Epoch 119/200 ---
[Checkpoint] Epoch 119 training loss: 0.055257

[Checkpoint] --- Epoch 120/200 ---
[Checkpoint] Epoch 120 training loss: 0.054940
[Checkpoint] Validation metrics - AUC: 0.542827, AUPRC: 0.089501, Loss: 0.042262
[Checkpoint] Validation lifts - @0.5%: 1.965955, @1%: 1.821206, @5%: 1.272275, @10%: 1.166434

[Checkpoint] --- Epoch 121/200 ---
[Checkpoint] Epoch 121 training loss: 0.054781

[Checkpoint] --- Epoch 122/200 ---
[Checkpoint] Epoch 122 training loss: 0.054362

[Checkpoint] --- Epoch 123/200 ---
[Checkpoint] Epoch 123 training loss: 0.054241

[Checkpoint] --- Epoch 124/200 ---
[Checkpoint] Epoch 124 training loss: 0.053927

[Checkpoint] --- Epoch 125/200 ---
[Checkpoint] Epoch 125 training loss: 0.053731
[Checkpoint] Validation metrics - AUC: 0.541335, AUPRC: 0.089222, Loss: 0.042459
[Checkpoint] Validation lifts - @0.5%: 2.041568, @1%: 1.806092, @5%: 1.273786, @10%: 1.163413

[Checkpoint] --- Epoch 126/200 ---
[Checkpoint] Epoch 126 training loss: 0.053316

[Checkpoint] --- Epoch 127/200 ---
[Checkpoint] Epoch 127 training loss: 0.053182

[Checkpoint] --- Epoch 128/200 ---
[Checkpoint] Epoch 128 training loss: 0.052818

[Checkpoint] --- Epoch 129/200 ---
[Checkpoint] Epoch 129 training loss: 0.052499

[Checkpoint] --- Epoch 130/200 ---
[Checkpoint] Epoch 130 training loss: 0.052237
[Checkpoint] Validation metrics - AUC: 0.548831, AUPRC: 0.091316, Loss: 0.042494
[Checkpoint] Validation lifts - @0.5%: 2.177673, @1%: 1.821206, @5%: 1.272275, @10%: 1.155858

[Checkpoint] --- Epoch 131/200 ---
[Checkpoint] Epoch 131 training loss: 0.052157

[Checkpoint] --- Epoch 132/200 ---
[Checkpoint] Epoch 132 training loss: 0.051851

[Checkpoint] --- Epoch 133/200 ---
[Checkpoint] Epoch 133 training loss: 0.051572

[Checkpoint] --- Epoch 134/200 ---
[Checkpoint] Epoch 134 training loss: 0.051260

[Checkpoint] --- Epoch 135/200 ---
[Checkpoint] Epoch 135 training loss: 0.050958
[Checkpoint] Validation metrics - AUC: 0.548659, AUPRC: 0.091266, Loss: 0.042576
[Checkpoint] Validation lifts - @0.5%: 2.238164, @1%: 1.753194, @5%: 1.278319, @10%: 1.147548

[Checkpoint] --- Epoch 136/200 ---
[Checkpoint] Epoch 136 training loss: 0.050657

[Checkpoint] --- Epoch 137/200 ---
[Checkpoint] Epoch 137 training loss: 0.050338

[Checkpoint] --- Epoch 138/200 ---
[Checkpoint] Epoch 138 training loss: 0.050185

[Checkpoint] --- Epoch 139/200 ---
[Checkpoint] Epoch 139 training loss: 0.049855

[Checkpoint] --- Epoch 140/200 ---
[Checkpoint] Epoch 140 training loss: 0.049617
[Checkpoint] Validation metrics - AUC: 0.548321, AUPRC: 0.091193, Loss: 0.042442
[Checkpoint] Validation lifts - @0.5%: 2.177673, @1%: 1.753194, @5%: 1.279830, @10%: 1.144526

[Checkpoint] --- Epoch 141/200 ---
[Checkpoint] Epoch 141 training loss: 0.049408

[Checkpoint] --- Epoch 142/200 ---
[Checkpoint] Epoch 142 training loss: 0.049131

[Checkpoint] --- Epoch 143/200 ---
[Checkpoint] Epoch 143 training loss: 0.048810

[Checkpoint] --- Epoch 144/200 ---
[Checkpoint] Epoch 144 training loss: 0.048606

[Checkpoint] --- Epoch 145/200 ---
[Checkpoint] Epoch 145 training loss: 0.048345
[Checkpoint] Validation metrics - AUC: 0.550333, AUPRC: 0.091327, Loss: 0.042095
[Checkpoint] Validation lifts - @0.5%: 2.011323, @1%: 1.692739, @5%: 1.276808, @10%: 1.143015

[Checkpoint] --- Epoch 146/200 ---
[Checkpoint] Epoch 146 training loss: 0.048159

[Checkpoint] --- Epoch 147/200 ---
[Checkpoint] Epoch 147 training loss: 0.047909

[Checkpoint] --- Epoch 148/200 ---
[Checkpoint] Epoch 148 training loss: 0.047476

[Checkpoint] --- Epoch 149/200 ---
[Checkpoint] Epoch 149 training loss: 0.047253

[Checkpoint] --- Epoch 150/200 ---
[Checkpoint] Epoch 150 training loss: 0.046952
[Checkpoint] Validation metrics - AUC: 0.552965, AUPRC: 0.091611, Loss: 0.041862
[Checkpoint] Validation lifts - @0.5%: 1.875218, @1%: 1.730523, @5%: 1.273786, @10%: 1.138482

[Checkpoint] --- Epoch 151/200 ---
[Checkpoint] Epoch 151 training loss: 0.046779

[Checkpoint] --- Epoch 152/200 ---
[Checkpoint] Epoch 152 training loss: 0.046440

[Checkpoint] --- Epoch 153/200 ---
[Checkpoint] Epoch 153 training loss: 0.046204

[Checkpoint] --- Epoch 154/200 ---
[Checkpoint] Epoch 154 training loss: 0.046068

[Checkpoint] --- Epoch 155/200 ---
[Checkpoint] Epoch 155 training loss: 0.045754
[Checkpoint] Validation metrics - AUC: 0.555594, AUPRC: 0.091897, Loss: 0.041540
[Checkpoint] Validation lifts - @0.5%: 1.860096, @1%: 1.685182, @5%: 1.278319, @10%: 1.137727

[Checkpoint] --- Epoch 156/200 ---
[Checkpoint] Epoch 156 training loss: 0.045544

[Checkpoint] --- Epoch 157/200 ---
[Checkpoint] Epoch 157 training loss: 0.045402

[Checkpoint] --- Epoch 158/200 ---
[Checkpoint] Epoch 158 training loss: 0.045034

[Checkpoint] --- Epoch 159/200 ---
[Checkpoint] Epoch 159 training loss: 0.044778

[Checkpoint] --- Epoch 160/200 ---
[Checkpoint] Epoch 160 training loss: 0.044491
[Checkpoint] Validation metrics - AUC: 0.557994, AUPRC: 0.092080, Loss: 0.040999
[Checkpoint] Validation lifts - @0.5%: 1.723991, @1%: 1.662512, @5%: 1.284363, @10%: 1.136971

[Checkpoint] --- Epoch 161/200 ---
[Checkpoint] Epoch 161 training loss: 0.044249

[Checkpoint] --- Epoch 162/200 ---
[Checkpoint] Epoch 162 training loss: 0.044116

[Checkpoint] --- Epoch 163/200 ---
[Checkpoint] Epoch 163 training loss: 0.043852

[Checkpoint] --- Epoch 164/200 ---
[Checkpoint] Epoch 164 training loss: 0.043562

[Checkpoint] --- Epoch 165/200 ---
[Checkpoint] Epoch 165 training loss: 0.043302
[Checkpoint] Validation metrics - AUC: 0.560046, AUPRC: 0.092225, Loss: 0.040605
[Checkpoint] Validation lifts - @0.5%: 1.557641, @1%: 1.639841, @5%: 1.302495, @10%: 1.136216

[Checkpoint] --- Epoch 166/200 ---
[Checkpoint] Epoch 166 training loss: 0.043117

[Checkpoint] --- Epoch 167/200 ---
[Checkpoint] Epoch 167 training loss: 0.042964

[Checkpoint] --- Epoch 168/200 ---
[Checkpoint] Epoch 168 training loss: 0.042739

[Checkpoint] --- Epoch 169/200 ---
[Checkpoint] Epoch 169 training loss: 0.042370

[Checkpoint] --- Epoch 170/200 ---
[Checkpoint] Epoch 170 training loss: 0.042224
[Checkpoint] Validation metrics - AUC: 0.561358, AUPRC: 0.092131, Loss: 0.040426
[Checkpoint] Validation lifts - @0.5%: 1.512273, @1%: 1.564272, @5%: 1.299473, @10%: 1.133194

[Checkpoint] --- Epoch 171/200 ---
[Checkpoint] Epoch 171 training loss: 0.041902

[Checkpoint] --- Epoch 172/200 ---
[Checkpoint] Epoch 172 training loss: 0.041649

[Checkpoint] --- Epoch 173/200 ---
[Checkpoint] Epoch 173 training loss: 0.041479

[Checkpoint] --- Epoch 174/200 ---
[Checkpoint] Epoch 174 training loss: 0.041117

[Checkpoint] --- Epoch 175/200 ---
[Checkpoint] Epoch 175 training loss: 0.041045
[Checkpoint] Validation metrics - AUC: 0.562103, AUPRC: 0.091972, Loss: 0.040789
[Checkpoint] Validation lifts - @0.5%: 1.285432, @1%: 1.443362, @5%: 1.308539, @10%: 1.126395

[Checkpoint] --- Epoch 176/200 ---
[Checkpoint] Epoch 176 training loss: 0.040838

[Checkpoint] --- Epoch 177/200 ---
[Checkpoint] Epoch 177 training loss: 0.040515

[Checkpoint] --- Epoch 178/200 ---
[Checkpoint] Epoch 178 training loss: 0.040369

[Checkpoint] --- Epoch 179/200 ---
[Checkpoint] Epoch 179 training loss: 0.039993

[Checkpoint] --- Epoch 180/200 ---
[Checkpoint] Epoch 180 training loss: 0.039803
[Checkpoint] Validation metrics - AUC: 0.561801, AUPRC: 0.091645, Loss: 0.042190
[Checkpoint] Validation lifts - @0.5%: 1.194695, @1%: 1.330009, @5%: 1.314583, @10%: 1.112797

[Checkpoint] --- Epoch 181/200 ---
[Checkpoint] Epoch 181 training loss: 0.039594

[Checkpoint] --- Epoch 182/200 ---
[Checkpoint] Epoch 182 training loss: 0.039323

[Checkpoint] --- Epoch 183/200 ---
[Checkpoint] Epoch 183 training loss: 0.038981

[Checkpoint] --- Epoch 184/200 ---
[Checkpoint] Epoch 184 training loss: 0.038907

[Checkpoint] --- Epoch 185/200 ---
[Checkpoint] Epoch 185 training loss: 0.038644
[Checkpoint] Validation metrics - AUC: 0.560988, AUPRC: 0.091309, Loss: 0.044226
[Checkpoint] Validation lifts - @0.5%: 1.119082, @1%: 1.269554, @5%: 1.329693, @10%: 1.087866

[Checkpoint] --- Epoch 186/200 ---
[Checkpoint] Epoch 186 training loss: 0.038382

[Checkpoint] --- Epoch 187/200 ---
[Checkpoint] Epoch 187 training loss: 0.038076

[Checkpoint] --- Epoch 188/200 ---
[Checkpoint] Epoch 188 training loss: 0.037822

[Checkpoint] --- Epoch 189/200 ---
[Checkpoint] Epoch 189 training loss: 0.037579

[Checkpoint] --- Epoch 190/200 ---
[Checkpoint] Epoch 190 training loss: 0.037356
[Checkpoint] Validation metrics - AUC: 0.560191, AUPRC: 0.091045, Loss: 0.048753
[Checkpoint] Validation lifts - @0.5%: 1.088836, @1%: 1.216656, @5%: 1.322138, @10%: 1.047827

[Checkpoint] --- Epoch 191/200 ---
[Checkpoint] Epoch 191 training loss: 0.037034

[Checkpoint] --- Epoch 192/200 ---
[Checkpoint] Epoch 192 training loss: 0.036823

[Checkpoint] --- Epoch 193/200 ---
[Checkpoint] Epoch 193 training loss: 0.036745

[Checkpoint] --- Epoch 194/200 ---
[Checkpoint] Epoch 194 training loss: 0.036406

[Checkpoint] --- Epoch 195/200 ---
[Checkpoint] Epoch 195 training loss: 0.036129
[Checkpoint] Validation metrics - AUC: 0.559502, AUPRC: 0.090808, Loss: 0.053858
[Checkpoint] Validation lifts - @0.5%: 1.073714, @1%: 1.163758, @5%: 1.341781, @10%: 1.000233

[Checkpoint] --- Epoch 196/200 ---
[Checkpoint] Epoch 196 training loss: 0.035695

[Checkpoint] --- Epoch 197/200 ---
[Checkpoint] Epoch 197 training loss: 0.035521

[Checkpoint] --- Epoch 198/200 ---
[Checkpoint] Epoch 198 training loss: 0.035264

[Checkpoint] --- Epoch 199/200 ---
[Checkpoint] Epoch 199 training loss: 0.035000

[Checkpoint] --- Epoch 200/200 ---
[Checkpoint] Epoch 200 training loss: 0.034667
[Checkpoint] Validation metrics - AUC: 0.559029, AUPRC: 0.090680, Loss: 0.057095
[Checkpoint] Validation lifts - @0.5%: 1.043468, @1%: 1.193986, @5%: 1.352359, @10%: 0.991922
[Checkpoint] Configuration completed. Best AUPRC: 0.092225

[Checkpoint] ====== Configuration 71/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.102342

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.101027

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.100312

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.099755

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.099353
[Checkpoint] Validation metrics - AUC: 0.439828, AUPRC: 0.068780, Loss: 0.099929
[Checkpoint] Validation lifts - @0.5%: 0.468805, @1%: 0.498753, @5%: 0.873367, @10%: 1.085600

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.098974

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.098720

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.098340

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.097976

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.097825
[Checkpoint] Validation metrics - AUC: 0.488559, AUPRC: 0.076728, Loss: 0.099693
[Checkpoint] Validation lifts - @0.5%: 0.438559, @1%: 0.551652, @5%: 0.945895, @10%: 1.103731

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.097508

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.097285

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.097080

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.096901

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.096803
[Checkpoint] Validation metrics - AUC: 0.560984, AUPRC: 0.092012, Loss: 0.099803
[Checkpoint] Validation lifts - @0.5%: 1.512273, @1%: 1.503817, @5%: 1.287385, @10%: 1.139238

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.096440

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.096300

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.096089

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.095896

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.095666
[Checkpoint] Validation metrics - AUC: 0.556306, AUPRC: 0.092774, Loss: 0.097829
[Checkpoint] Validation lifts - @0.5%: 1.950832, @1%: 1.881661, @5%: 1.316094, @10%: 1.143770

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.095504

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.095327

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.095239

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.094971

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.094711
[Checkpoint] Validation metrics - AUC: 0.549898, AUPRC: 0.091892, Loss: 0.093945
[Checkpoint] Validation lifts - @0.5%: 2.102059, @1%: 1.866547, @5%: 1.322138, @10%: 1.145281

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.094662

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.094437

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.094273

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.094137

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.094041
[Checkpoint] Validation metrics - AUC: 0.549894, AUPRC: 0.091649, Loss: 0.089260
[Checkpoint] Validation lifts - @0.5%: 1.981077, @1%: 1.836320, @5%: 1.319116, @10%: 1.147548

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.093765

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.093562

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.093428

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.093287

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.092977
[Checkpoint] Validation metrics - AUC: 0.550030, AUPRC: 0.091579, Loss: 0.086828
[Checkpoint] Validation lifts - @0.5%: 1.935709, @1%: 1.858990, @5%: 1.314583, @10%: 1.147548

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.092919

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.092761

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.092515

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.092438

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.092239
[Checkpoint] Validation metrics - AUC: 0.550397, AUPRC: 0.091636, Loss: 0.084784
[Checkpoint] Validation lifts - @0.5%: 1.890341, @1%: 1.858990, @5%: 1.307028, @10%: 1.146037

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.091970

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.091793

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.091730

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.091450

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.091455
[Checkpoint] Validation metrics - AUC: 0.552226, AUPRC: 0.091880, Loss: 0.082636
[Checkpoint] Validation lifts - @0.5%: 1.844973, @1%: 1.866547, @5%: 1.304006, @10%: 1.142260

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.091143

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.090956

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.090876

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.090534

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.090554
[Checkpoint] Validation metrics - AUC: 0.553290, AUPRC: 0.091963, Loss: 0.081028
[Checkpoint] Validation lifts - @0.5%: 1.814727, @1%: 1.866547, @5%: 1.300984, @10%: 1.141504

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.090244

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.090073

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.089754

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.089590

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.089449
[Checkpoint] Validation metrics - AUC: 0.553605, AUPRC: 0.091928, Loss: 0.078715
[Checkpoint] Validation lifts - @0.5%: 1.799605, @1%: 1.874104, @5%: 1.297962, @10%: 1.141504

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.089345

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.089043

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.088972

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.088726

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.088491
[Checkpoint] Validation metrics - AUC: 0.555978, AUPRC: 0.092201, Loss: 0.077498
[Checkpoint] Validation lifts - @0.5%: 1.784482, @1%: 1.866547, @5%: 1.296451, @10%: 1.140749

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.088226

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.088085

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.087832

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.087669

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.087379
[Checkpoint] Validation metrics - AUC: 0.557400, AUPRC: 0.092234, Loss: 0.077105
[Checkpoint] Validation lifts - @0.5%: 1.829850, @1%: 1.881661, @5%: 1.300984, @10%: 1.138482

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.087227

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.087014

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.086840

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.086453

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.086407
[Checkpoint] Validation metrics - AUC: 0.558845, AUPRC: 0.092286, Loss: 0.076840
[Checkpoint] Validation lifts - @0.5%: 1.844973, @1%: 1.866547, @5%: 1.294940, @10%: 1.135460

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.086020

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.085886

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.085474

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.085396

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.085131
[Checkpoint] Validation metrics - AUC: 0.558466, AUPRC: 0.092111, Loss: 0.076470
[Checkpoint] Validation lifts - @0.5%: 1.829850, @1%: 1.851433, @5%: 1.294940, @10%: 1.133949

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.085016

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.084635

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.084374

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.084038

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.083864
[Checkpoint] Validation metrics - AUC: 0.557310, AUPRC: 0.091792, Loss: 0.076253
[Checkpoint] Validation lifts - @0.5%: 1.814727, @1%: 1.821206, @5%: 1.297962, @10%: 1.132439

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.083619

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.083315

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.083007

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.082850

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.082623
[Checkpoint] Validation metrics - AUC: 0.554046, AUPRC: 0.091118, Loss: 0.076024
[Checkpoint] Validation lifts - @0.5%: 1.754236, @1%: 1.798535, @5%: 1.296451, @10%: 1.128661

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.082124

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.081868

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.081565

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.081198

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.080766
[Checkpoint] Validation metrics - AUC: 0.549831, AUPRC: 0.090356, Loss: 0.076048
[Checkpoint] Validation lifts - @0.5%: 1.754236, @1%: 1.745637, @5%: 1.293429, @10%: 1.124128

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.080561

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.080083

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.079820

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.079333

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.078953
[Checkpoint] Validation metrics - AUC: 0.542352, AUPRC: 0.089075, Loss: 0.076110
[Checkpoint] Validation lifts - @0.5%: 1.708868, @1%: 1.715410, @5%: 1.282852, @10%: 1.126395
[Checkpoint] Early stopping at epoch 95 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.092774

[Checkpoint] ====== Configuration 72/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 5602212
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Final Evaluation ======
[Checkpoint] Evaluating best model
[Checkpoint] Best config (lr=0.01, hidden=256, layers=3, alpha=0.5, gamma=1.0):
[Checkpoint] Test AUPRC=0.220397
[Checkpoint] Test AUC=0.527924
[Checkpoint] Test EMP=4.891018
[Checkpoint] Test MP=4.757031
[Checkpoint] Test Lift@0.5%=1.058410
[Checkpoint] Test Lift@1%=1.049386
[Checkpoint] Test Lift@5%=0.887430
[Checkpoint] Test Lift@10%=1.059985

[Checkpoint] Saving best model predictions for analysis
[Checkpoint] Predictions saved as best_model_predictions_20250416_125114.csv
[Checkpoint] ====== Script Finished ======
