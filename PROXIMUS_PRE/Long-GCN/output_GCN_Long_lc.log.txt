SLURM_JOB_ID: 58109231
SLURM_JOB_USER: vsc37331
SLURM_JOB_ACCOUNT: intro_vsc37331
SLURM_JOB_NAME: GCN_Long_lc
SLURM_CLUSTER_NAME: genius
SLURM_JOB_PARTITION: batch
SLURM_NNODES: 1
SLURM_NODELIST: r27i27n03
SLURM_JOB_CPUS_PER_NODE: 28
Date: Mon Apr 28 22:16:10 CEST 2025
Walltime: 00-05:00:00
========================================================================
[Checkpoint] All libraries imported successfully.
[Checkpoint] Configuration initialized
[Checkpoint] Using device: cpu
[Checkpoint] Working directory set to: /vsc-hard-mounts/leuven-data/373/vsc37331/ProximusPre
[Checkpoint] ====== Script Started ======
[Checkpoint] ====== Starting Experiment setup ======
[Checkpoint] Identified 33099 users who churned in month 1
[Checkpoint] Loading training data with RMF features and dual edge weights
[Checkpoint] Loaded RMF, both edge types (c and l), and label data
[Checkpoint] Starting remove_nodes_and_create_data
[Checkpoint] Mapped 1409874 node indices to USRs
[Checkpoint] Keeping all users including first month churners
[Checkpoint] Keeping all edges including those involving first month churners
[Checkpoint] Created mapping for 1409874 users
[Checkpoint] Extracted call count weights with min=0.201896517994655, max=713.043343474163
[Checkpoint] Extracted call duration weights with min=1.00948258997328, max=205624.595419795
[Checkpoint] Created undirected edge index with shape: torch.Size([2, 4862414])
[Checkpoint] Created edge attributes with shape: torch.Size([4862414, 2])
[Checkpoint] Remaining feature columns: ['R_on', 'M_60_on', 'F_60_on', 'numDialing_60_on', 'numDialed_60_on']
[Checkpoint] Node feature tensor shape: torch.Size([1409874, 5])
[Checkpoint] Label tensor shape: torch.Size([1409874])
[Checkpoint] Label distribution: tensor([1395416,   14458])
[Checkpoint] Created Data object with 1409874 nodes, 4862414 edges, 5 features, and 2D edge attributes
[Checkpoint] Class distribution - Positives: 14458, Negatives: 1395416
[Checkpoint] Loading validation data with RMF features and dual edge weights
[Checkpoint] Loaded RMF, both edge types (c and l), and label data
[Checkpoint] Starting remove_nodes_and_create_data
[Checkpoint] Mapped 1409874 node indices to USRs
[Checkpoint] Keeping all users including first month churners
[Checkpoint] Keeping all edges including those involving first month churners
[Checkpoint] Created mapping for 1409874 users
[Checkpoint] Extracted call count weights with min=0.0907179532894125, max=349.156172034706
[Checkpoint] Extracted call duration weights with min=0.453589766447062, max=98551.0240147951
[Checkpoint] Created undirected edge index with shape: torch.Size([2, 5130656])
[Checkpoint] Created edge attributes with shape: torch.Size([5130656, 2])
[Checkpoint] Remaining feature columns: ['R_on', 'M_60_on', 'F_60_on', 'numDialing_60_on', 'numDialed_60_on']
[Checkpoint] Node feature tensor shape: torch.Size([1409874, 5])
[Checkpoint] Label tensor shape: torch.Size([1409874])
[Checkpoint] Label distribution: tensor([1385781,   24093])
[Checkpoint] Created Data object with 1409874 nodes, 5130656 edges, 5 features, and 2D edge attributes
[Checkpoint] Loading test data with RMF features and dual edge weights
[Checkpoint] Loaded RMF, both edge types (c and l), and label data
[Checkpoint] Starting remove_nodes_and_create_data
[Checkpoint] Mapped 1409874 node indices to USRs
[Checkpoint] Keeping all users including first month churners
[Checkpoint] Keeping all edges including those involving first month churners
[Checkpoint] Created mapping for 1409874 users
[Checkpoint] Extracted call count weights with min=0.0407622039783662, max=128.213545031947
[Checkpoint] Extracted call duration weights with min=0.203811019891831, max=52357.8472403308
[Checkpoint] Created undirected edge index with shape: torch.Size([2, 5144852])
[Checkpoint] Created edge attributes with shape: torch.Size([5144852, 2])
[Checkpoint] Remaining feature columns: ['R_on', 'M_60_on', 'F_60_on', 'numDialing_60_on', 'numDialed_60_on']
[Checkpoint] Node feature tensor shape: torch.Size([1409874, 5])
[Checkpoint] Label tensor shape: torch.Size([1409874])
[Checkpoint] Label distribution: tensor([1347842,   62032])
[Checkpoint] Created Data object with 1409874 nodes, 5144852 edges, 5 features, and 2D edge attributes
[Checkpoint] Experiment initialization complete
[Checkpoint] ====== Starting Hyperparameter Tuning ======
[Checkpoint] Number of input features: 5
[Checkpoint] Testing 3×3×2×2×2 combinations

[Checkpoint] ====== Configuration 1/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 2/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.105137

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.094613

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.083350

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.070534

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.056451
[Checkpoint] Validation metrics - AUC: 0.433481, AUPRC: 0.014522, Loss: 0.041620
[Checkpoint] Validation lifts - @0.5%: 1.178827, @1%: 1.091661, @5%: 0.769526, @10%: 0.738806
[Checkpoint] New best model found! AUPRC: 0.014522 (previous best: 0.000000)

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.042294

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.029539

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.019659

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.013333

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.010162
[Checkpoint] Validation metrics - AUC: 0.426666, AUPRC: 0.013979, Loss: 0.014476
[Checkpoint] Validation lifts - @0.5%: 0.439985, @1%: 0.502247, @5%: 0.622594, @10%: 0.679867

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.009064

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.009059

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.009438

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.009785

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.009956
[Checkpoint] Validation metrics - AUC: 0.434163, AUPRC: 0.014207, Loss: 0.027275
[Checkpoint] Validation lifts - @0.5%: 0.107921, @1%: 0.356969, @5%: 0.671571, @10%: 0.700620

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.009805

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.014522

[Checkpoint] ====== Configuration 3/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 4/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 5/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 6/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 7/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 8/72 ======
[Checkpoint] Training with lr=0.01, hidden=32, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.038118

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 9/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.190428

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.169576

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.138831

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.103758

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.068396
[Checkpoint] Validation metrics - AUC: 0.430916, AUPRC: 0.014242, Loss: 0.044273
[Checkpoint] Validation lifts - @0.5%: 0.622620, @1%: 0.709787, @5%: 0.698965, @10%: 0.726769

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.039426

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.022082

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.015673

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.015264

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.016851
[Checkpoint] Validation metrics - AUC: 0.430097, AUPRC: 0.014136, Loss: 0.033805
[Checkpoint] Validation lifts - @0.5%: 0.273953, @1%: 0.493945, @5%: 0.661610, @10%: 0.700620

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.018475

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.019526

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.019881

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.019479

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.018497
[Checkpoint] Validation metrics - AUC: 0.434804, AUPRC: 0.014204, Loss: 0.056308
[Checkpoint] Validation lifts - @0.5%: 0.249048, @1%: 0.464890, @5%: 0.656629, @10%: 0.695640

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.017064

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.015733

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.015764

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.017283

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.016793
[Checkpoint] Validation metrics - AUC: 0.428915, AUPRC: 0.013689, Loss: 0.061297
[Checkpoint] Validation lifts - @0.5%: 0.033206, @1%: 0.024905, @5%: 0.094634, @10%: 0.462376

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.015486

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.014837

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.014653

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.014499

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.014163
[Checkpoint] Validation metrics - AUC: 0.437365, AUPRC: 0.014511, Loss: 0.060530
[Checkpoint] Validation lifts - @0.5%: 0.083016, @1%: 0.427533, @5%: 0.782808, @10%: 0.808951

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.013491

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.012491

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.011416

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.010435

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.009781
[Checkpoint] Validation metrics - AUC: 0.425651, AUPRC: 0.013618, Loss: 0.059288
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.000000, @5%: 0.090484, @10%: 0.450340

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.009402

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.009027

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.008474

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.007931

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.007190
[Checkpoint] Validation metrics - AUC: 0.419362, AUPRC: 0.013417, Loss: 0.054513
[Checkpoint] Validation lifts - @0.5%: 0.033206, @1%: 0.128675, @5%: 0.336201, @10%: 0.451585

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.006262

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.005229

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.004317

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.003836

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.003484
[Checkpoint] Validation metrics - AUC: 0.424703, AUPRC: 0.013795, Loss: 0.049330
[Checkpoint] Validation lifts - @0.5%: 0.024905, @1%: 0.141127, @5%: 0.600180, @10%: 0.600591

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.003513

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.003585

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.003860

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.003621

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.003330
[Checkpoint] Validation metrics - AUC: 0.425276, AUPRC: 0.013840, Loss: 0.048921
[Checkpoint] Validation lifts - @0.5%: 0.016603, @1%: 0.195088, @5%: 0.598520, @10%: 0.626325

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.002963

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.002630

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.002347

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.002144

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.001811
[Checkpoint] Validation metrics - AUC: 0.423618, AUPRC: 0.013744, Loss: 0.054097
[Checkpoint] Validation lifts - @0.5%: 0.024905, @1%: 0.145278, @5%: 0.564485, @10%: 0.600591

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.001675

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.001566

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.001473

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.001352

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.001248
[Checkpoint] Validation metrics - AUC: 0.424572, AUPRC: 0.013828, Loss: 0.060240
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.232445, @5%: 0.635876, @10%: 0.683188

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.001138

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.001047

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.000968

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.000944

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.000872
[Checkpoint] Validation metrics - AUC: 0.425550, AUPRC: 0.013904, Loss: 0.066368
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.190937, @5%: 0.659119, @10%: 0.709752

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.000833

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.000799

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.000808

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.000826

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.000780
[Checkpoint] Validation metrics - AUC: 0.426301, AUPRC: 0.013962, Loss: 0.070826
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.278104, @5%: 0.665760, @10%: 0.734655

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.000784

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.000715

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.000703

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.000651

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.000648
[Checkpoint] Validation metrics - AUC: 0.427442, AUPRC: 0.014038, Loss: 0.072926
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.244897, @5%: 0.693154, @10%: 0.756238

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.000650

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.014511

[Checkpoint] ====== Configuration 10/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 11/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 12/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 13/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.166089

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.156334

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.186589

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.130317

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.116872
[Checkpoint] Validation metrics - AUC: 0.568039, AUPRC: 0.020844, Loss: 0.111636
[Checkpoint] Validation lifts - @0.5%: 1.095811, @1%: 1.257693, @5%: 1.431135, @10%: 1.329020
[Checkpoint] New best model found! AUPRC: 0.020844 (previous best: 0.014522)

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.095918

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.066882

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.041620

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.025390

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.018147
[Checkpoint] Validation metrics - AUC: 0.438175, AUPRC: 0.014767, Loss: 0.031011
[Checkpoint] Validation lifts - @0.5%: 1.162224, @1%: 1.220335, @5%: 0.832615, @10%: 0.802725

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.016684

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.017842

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.019865

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.021969

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.023851
[Checkpoint] Validation metrics - AUC: 0.435672, AUPRC: 0.014435, Loss: 0.081702
[Checkpoint] Validation lifts - @0.5%: 1.004494, @1%: 0.730541, @5%: 0.719718, @10%: 0.736731

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.025441

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.026559

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.027274

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.027627

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.027415
[Checkpoint] Validation metrics - AUC: 0.436068, AUPRC: 0.014408, Loss: 0.488441
[Checkpoint] Validation lifts - @0.5%: 0.655827, @1%: 0.693184, @5%: 0.700625, @10%: 0.728014

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.026942

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.025982

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.024792

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.023084

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.021328
[Checkpoint] Validation metrics - AUC: 0.434777, AUPRC: 0.014290, Loss: 1.392253
[Checkpoint] Validation lifts - @0.5%: 0.381874, @1%: 0.510549, @5%: 0.691494, @10%: 0.711412

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.020161

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.019693

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.019008

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.017668

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.016423
[Checkpoint] Validation metrics - AUC: 0.433926, AUPRC: 0.014184, Loss: 0.791357
[Checkpoint] Validation lifts - @0.5%: 0.315461, @1%: 0.572811, @5%: 0.640026, @10%: 0.678207

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.015885

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.015654

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.015534

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.015407

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.015283
[Checkpoint] Validation metrics - AUC: 0.439382, AUPRC: 0.014685, Loss: 0.283810
[Checkpoint] Validation lifts - @0.5%: 0.896573, @1%: 0.834311, @5%: 0.804391, @10%: 0.801065

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.015174

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.015150

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.015152

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.015098

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.014990
[Checkpoint] Validation metrics - AUC: 0.436802, AUPRC: 0.014357, Loss: 0.147815
[Checkpoint] Validation lifts - @0.5%: 0.788652, @1%: 0.738843, @5%: 0.689004, @10%: 0.698545

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.014867

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.014766

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.014741

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.014721

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.014648
[Checkpoint] Validation metrics - AUC: 0.441347, AUPRC: 0.014708, Loss: 0.087039
[Checkpoint] Validation lifts - @0.5%: 0.772049, @1%: 0.747144, @5%: 0.806881, @10%: 0.818497

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.014607

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.014509

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.014450

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.014475

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.014408
[Checkpoint] Validation metrics - AUC: 0.438861, AUPRC: 0.014446, Loss: 0.083874
[Checkpoint] Validation lifts - @0.5%: 0.664128, @1%: 0.635073, @5%: 0.720548, @10%: 0.739221

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.014391

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.014360

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.014349

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.014352

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.014316
[Checkpoint] Validation metrics - AUC: 0.439628, AUPRC: 0.014527, Loss: 0.064716
[Checkpoint] Validation lifts - @0.5%: 0.489795, @1%: 0.626771, @5%: 0.779487, @10%: 0.760804

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.014308

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.014253

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.014258

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.014237

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.014230
[Checkpoint] Validation metrics - AUC: 0.438625, AUPRC: 0.014495, Loss: 0.062686
[Checkpoint] Validation lifts - @0.5%: 0.664128, @1%: 0.705636, @5%: 0.761225, @10%: 0.760389

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.014208

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.014205

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.014173

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.014161

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.014153
[Checkpoint] Validation metrics - AUC: 0.441851, AUPRC: 0.014611, Loss: 0.054870
[Checkpoint] Validation lifts - @0.5%: 0.564509, @1%: 0.639223, @5%: 0.774507, @10%: 0.794839

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.014135

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.014147

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.014100

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.014101

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.014082
[Checkpoint] Validation metrics - AUC: 0.445792, AUPRC: 0.014642, Loss: 0.050999
[Checkpoint] Validation lifts - @0.5%: 0.581112, @1%: 0.705636, @5%: 0.762885, @10%: 0.767030

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.014080

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.014082

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.014045

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.014059

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.014036
[Checkpoint] Validation metrics - AUC: 0.445743, AUPRC: 0.014631, Loss: 0.047169
[Checkpoint] Validation lifts - @0.5%: 0.630922, @1%: 0.689033, @5%: 0.765375, @10%: 0.766615

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.013996

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.014038

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.014019

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.013982

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.013990
[Checkpoint] Validation metrics - AUC: 0.445830, AUPRC: 0.014674, Loss: 0.046241
[Checkpoint] Validation lifts - @0.5%: 0.547906, @1%: 0.659977, @5%: 0.779487, @10%: 0.786538
[Checkpoint] Early stopping at epoch 80 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.020844

[Checkpoint] ====== Configuration 14/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 15/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.084582

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.082376

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.090133

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.069484

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.063922
[Checkpoint] Validation metrics - AUC: 0.560930, AUPRC: 0.020512, Loss: 0.068211
[Checkpoint] Validation lifts - @0.5%: 1.527495, @1%: 1.652019, @5%: 1.388799, @10%: 1.268007

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.054829

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.041552

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.030454

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.023289

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.019787
[Checkpoint] Validation metrics - AUC: 0.437033, AUPRC: 0.014430, Loss: 0.026967
[Checkpoint] Validation lifts - @0.5%: 0.630922, @1%: 0.589414, @5%: 0.716398, @10%: 0.740051

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.019927

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.021854

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.024154

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.025637

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.026352
[Checkpoint] Validation metrics - AUC: 0.437734, AUPRC: 0.014464, Loss: 0.045588
[Checkpoint] Validation lifts - @0.5%: 0.664128, @1%: 0.730541, @5%: 0.753753, @10%: 0.750428

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.026006

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.024796

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.022900

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.021209

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.020636
[Checkpoint] Validation metrics - AUC: 0.435243, AUPRC: 0.014258, Loss: 0.299052
[Checkpoint] Validation lifts - @0.5%: 0.265651, @1%: 0.531303, @5%: 0.679042, @10%: 0.712242

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.020039

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.019104

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.018194

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.017844

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.017677
[Checkpoint] Validation metrics - AUC: 0.437695, AUPRC: 0.014456, Loss: 0.114363
[Checkpoint] Validation lifts - @0.5%: 0.406778, @1%: 0.593565, @5%: 0.744622, @10%: 0.759974

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.017627

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.017468

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.017293

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.017148

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.017142
[Checkpoint] Validation metrics - AUC: 0.440361, AUPRC: 0.014638, Loss: 0.074775
[Checkpoint] Validation lifts - @0.5%: 0.855065, @1%: 0.846763, @5%: 0.780317, @10%: 0.784462

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.017073

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.017000

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.016897

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.016847

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.016785
[Checkpoint] Validation metrics - AUC: 0.441307, AUPRC: 0.014631, Loss: 0.057240
[Checkpoint] Validation lifts - @0.5%: 0.896573, @1%: 0.705636, @5%: 0.745452, @10%: 0.760389

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.016770

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.016749

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.016674

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.016617

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.016593
[Checkpoint] Validation metrics - AUC: 0.439039, AUPRC: 0.014429, Loss: 0.055050
[Checkpoint] Validation lifts - @0.5%: 0.589414, @1%: 0.626771, @5%: 0.693984, @10%: 0.725109

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.016537

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.016478

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.016438

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.016405

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.016380
[Checkpoint] Validation metrics - AUC: 0.464100, AUPRC: 0.015401, Loss: 0.047553
[Checkpoint] Validation lifts - @0.5%: 1.220335, @1%: 0.975438, @5%: 0.848388, @10%: 0.828459

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.026064

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.020512

[Checkpoint] ====== Configuration 16/72 ======
[Checkpoint] Training with lr=0.01, hidden=128, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 17/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.165104

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.135857

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.126429

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.064130

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.033009
[Checkpoint] Validation metrics - AUC: 0.433187, AUPRC: 0.014217, Loss: 0.027097
[Checkpoint] Validation lifts - @0.5%: 0.157730, @1%: 0.402628, @5%: 0.683193, @10%: 0.718468

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.018209

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.015063

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.016598

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.018702

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.020231
[Checkpoint] Validation metrics - AUC: 0.433903, AUPRC: 0.014250, Loss: 0.043707
[Checkpoint] Validation lifts - @0.5%: 0.224143, @1%: 0.539604, @5%: 0.692324, @10%: 0.720128

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.020885

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.020673

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.019475

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.017838

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.016337
[Checkpoint] Validation metrics - AUC: 0.434455, AUPRC: 0.014143, Loss: 0.061520
[Checkpoint] Validation lifts - @0.5%: 0.249048, @1%: 0.481493, @5%: 0.652478, @10%: 0.669076

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.016756

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.018061

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.016465

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.015488

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.015256
[Checkpoint] Validation metrics - AUC: 0.429317, AUPRC: 0.013759, Loss: 0.058374
[Checkpoint] Validation lifts - @0.5%: 0.240746, @1%: 0.415080, @5%: 0.342842, @10%: 0.466942

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.015251

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.015081

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.014614

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.013816

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.012801
[Checkpoint] Validation metrics - AUC: 0.427579, AUPRC: 0.013695, Loss: 0.054980
[Checkpoint] Validation lifts - @0.5%: 0.058111, @1%: 0.344516, @5%: 0.188438, @10%: 0.444529

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.011749

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.010673

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.009449

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.008024

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.006705
[Checkpoint] Validation metrics - AUC: 0.420944, AUPRC: 0.013479, Loss: 0.045585
[Checkpoint] Validation lifts - @0.5%: 0.000000, @1%: 0.311310, @5%: 0.136140, @10%: 0.434982

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.005610

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.004728

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.004003

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.003271

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.002539
[Checkpoint] Validation metrics - AUC: 0.432288, AUPRC: 0.014153, Loss: 0.048735
[Checkpoint] Validation lifts - @0.5%: 0.439985, @1%: 0.377723, @5%: 0.627574, @10%: 0.676962

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.002098

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.007042

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.014250

[Checkpoint] ====== Configuration 18/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 19/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.092173

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 20/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.046854

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 21/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 22/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.099306

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.133672

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.213184

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.196289

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.103775
[Checkpoint] Validation metrics - AUC: 0.451964, AUPRC: 0.016456, Loss: 0.063659
[Checkpoint] Validation lifts - @0.5%: 1.934273, @1%: 1.925972, @5%: 1.343972, @10%: 1.047195

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.066970

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.070234

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.047352

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.025307

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.014700
[Checkpoint] Validation metrics - AUC: 0.453158, AUPRC: 0.016018, Loss: 0.014080
[Checkpoint] Validation lifts - @0.5%: 1.535796, @1%: 1.743336, @5%: 1.150553, @10%: 0.962938

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.011448

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.011592

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.013030

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.014619

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.015910
[Checkpoint] Validation metrics - AUC: 0.478386, AUPRC: 0.016828, Loss: 0.020165
[Checkpoint] Validation lifts - @0.5%: 1.195431, @1%: 1.145621, @5%: 1.020223, @10%: 1.056326

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.016778

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.016828

[Checkpoint] ====== Configuration 23/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 24/72 ======
[Checkpoint] Training with lr=0.01, hidden=256, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 25/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 26/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.107958

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.106415

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.105238

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.104170

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.103139
[Checkpoint] Validation metrics - AUC: 0.562188, AUPRC: 0.020086, Loss: 0.101433
[Checkpoint] Validation lifts - @0.5%: 1.245240, @1%: 1.257693, @5%: 1.221944, @10%: 1.182089

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.102110

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.101087

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.100031

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.098966

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.097871
[Checkpoint] Validation metrics - AUC: 0.557886, AUPRC: 0.019692, Loss: 0.096460
[Checkpoint] Validation lifts - @0.5%: 1.311653, @1%: 1.158073, @5%: 1.166325, @10%: 1.147224

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.096745

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.095604

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.094407

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.093176

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.091881
[Checkpoint] Validation metrics - AUC: 0.524543, AUPRC: 0.018194, Loss: 0.090435
[Checkpoint] Validation lifts - @0.5%: 0.954684, @1%: 0.950533, @5%: 1.040977, @10%: 1.065458

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.090525

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.089101

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.087630

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.086069

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.084483
[Checkpoint] Validation metrics - AUC: 0.428724, AUPRC: 0.014076, Loss: 0.083068
[Checkpoint] Validation lifts - @0.5%: 0.531303, @1%: 0.493945, @5%: 0.644177, @10%: 0.679867

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.082834

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.081155

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.079421

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.077632

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.075821
[Checkpoint] Validation metrics - AUC: 0.429581, AUPRC: 0.014108, Loss: 0.074605
[Checkpoint] Validation lifts - @0.5%: 0.747144, @1%: 0.527152, @5%: 0.651648, @10%: 0.684433

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.073957

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.072025

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.070061

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.068048

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.066011
[Checkpoint] Validation metrics - AUC: 0.431698, AUPRC: 0.014184, Loss: 0.065492
[Checkpoint] Validation lifts - @0.5%: 0.323762, @1%: 0.523001, @5%: 0.693154, @10%: 0.706846

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.063930

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.061822

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.059717

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.057592

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.055436
[Checkpoint] Validation metrics - AUC: 0.431816, AUPRC: 0.014215, Loss: 0.055983
[Checkpoint] Validation lifts - @0.5%: 0.298858, @1%: 0.514699, @5%: 0.685683, @10%: 0.732580

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.053290

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.051162

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.049042

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.046929

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.044846
[Checkpoint] Validation metrics - AUC: 0.430797, AUPRC: 0.014223, Loss: 0.047028
[Checkpoint] Validation lifts - @0.5%: 0.556207, @1%: 0.473191, @5%: 0.694815, @10%: 0.728844

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.042787

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.040773

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.038800

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.036902

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.035037
[Checkpoint] Validation metrics - AUC: 0.425885, AUPRC: 0.014028, Loss: 0.039300
[Checkpoint] Validation lifts - @0.5%: 0.788652, @1%: 0.610168, @5%: 0.624254, @10%: 0.695225

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.033229

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.031521

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.029865

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.028297

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.026768
[Checkpoint] Validation metrics - AUC: 0.437536, AUPRC: 0.014751, Loss: 0.032386
[Checkpoint] Validation lifts - @0.5%: 0.871668, @1%: 0.792803, @5%: 0.847557, @10%: 0.855438

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.025349

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.025136

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.023809

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.022523

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.021273
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.439223, AUPRC: 0.015402, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.378066, @1%: 1.390518, @5%: 1.073351, @10%: 0.939695

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.020086

[Checkpoint] ====== Configuration 27/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 28/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 29/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 30/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.105742

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.102327

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.100697

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.099389

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.098378
[Checkpoint] Validation metrics - AUC: 0.549197, AUPRC: 0.019644, Loss: 0.094199
[Checkpoint] Validation lifts - @0.5%: 1.469384, @1%: 1.382217, @5%: 1.184588, @10%: 1.173373

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.097441

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.096480

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.095617

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.094748

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.094017
[Checkpoint] Validation metrics - AUC: 0.548915, AUPRC: 0.019822, Loss: 0.094109
[Checkpoint] Validation lifts - @0.5%: 1.660320, @1%: 1.585606, @5%: 1.231905, @10%: 1.190391

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.093214

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.092485

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.091756

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.090988

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.090249
[Checkpoint] Validation metrics - AUC: 0.550188, AUPRC: 0.019828, Loss: 0.094255
[Checkpoint] Validation lifts - @0.5%: 1.560701, @1%: 1.419574, @5%: 1.234396, @10%: 1.188315

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.089472

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.088740

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.087917

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.087107

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.086273
[Checkpoint] Validation metrics - AUC: 0.441397, AUPRC: 0.015282, Loss: 0.088713
[Checkpoint] Validation lifts - @0.5%: 1.776543, @1%: 1.689376, @5%: 0.963775, @10%: 0.838005

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.085423

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.084512

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.083573

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.082617

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.081634
[Checkpoint] Validation metrics - AUC: 0.458918, AUPRC: 0.016818, Loss: 0.081577
[Checkpoint] Validation lifts - @0.5%: 1.776543, @1%: 1.805598, @5%: 1.401251, @10%: 1.177524

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.080584

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.079553

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.078431

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.077285

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.076101
[Checkpoint] Validation metrics - AUC: 0.552254, AUPRC: 0.019888, Loss: 0.076485
[Checkpoint] Validation lifts - @0.5%: 1.485987, @1%: 1.361463, @5%: 1.278392, @10%: 1.211974

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.074867

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.073652

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.072383

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.071062

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.069750
[Checkpoint] Validation metrics - AUC: 0.550733, AUPRC: 0.019776, Loss: 0.075647
[Checkpoint] Validation lifts - @0.5%: 1.319955, @1%: 1.282598, @5%: 1.251828, @10%: 1.195371

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.068342

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.066997

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.065526

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.064092

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.062634
[Checkpoint] Validation metrics - AUC: 0.550853, AUPRC: 0.019869, Loss: 0.077911
[Checkpoint] Validation lifts - @0.5%: 1.427876, @1%: 1.411272, @5%: 1.254319, @10%: 1.199937

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.061103

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.059532

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.057965

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.056415

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.054802
[Checkpoint] Validation metrics - AUC: 0.551059, AUPRC: 0.019934, Loss: 0.076683
[Checkpoint] Validation lifts - @0.5%: 1.485987, @1%: 1.423725, @5%: 1.262620, @10%: 1.228161

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.053177

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.051554

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.049963

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.048254

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.046624
[Checkpoint] Validation metrics - AUC: 0.551061, AUPRC: 0.019919, Loss: 0.076382
[Checkpoint] Validation lifts - @0.5%: 1.593908, @1%: 1.419574, @5%: 1.246017, @10%: 1.202427

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.044998

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.043310

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.041682

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.039971

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.038428
[Checkpoint] Validation metrics - AUC: 0.550899, AUPRC: 0.019925, Loss: 0.081216
[Checkpoint] Validation lifts - @0.5%: 1.602209, @1%: 1.440328, @5%: 1.254319, @10%: 1.204088

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.036791

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.035215

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.033592

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.032018

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.030541
[Checkpoint] Validation metrics - AUC: 0.550976, AUPRC: 0.019912, Loss: 0.084366
[Checkpoint] Validation lifts - @0.5%: 1.560701, @1%: 1.448630, @5%: 1.276732, @10%: 1.200352

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.029099

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.027577

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.026213

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.024951

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.023662
[Checkpoint] Validation metrics - AUC: 0.496412, AUPRC: 0.017392, Loss: 0.078582
[Checkpoint] Validation lifts - @0.5%: 1.087510, @1%: 1.021097, @5%: 1.023544, @10%: 1.049270

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.030998

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.027960

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.024792

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.022311

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.019934

[Checkpoint] ====== Configuration 31/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 32/72 ======
[Checkpoint] Training with lr=0.001, hidden=32, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 33/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 34/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 35/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 36/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 37/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.174631

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.168732

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.164497

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.161867

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.159541
[Checkpoint] Validation metrics - AUC: 0.441522, AUPRC: 0.015053, Loss: 0.161984
[Checkpoint] Validation lifts - @0.5%: 1.220335, @1%: 1.191280, @5%: 0.966265, @10%: 0.836760

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.157183

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.154985

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.152665

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.150320

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.147858
[Checkpoint] Validation metrics - AUC: 0.453790, AUPRC: 0.016449, Loss: 0.157231
[Checkpoint] Validation lifts - @0.5%: 1.984083, @1%: 1.855408, @5%: 1.353934, @10%: 1.027687

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.145384

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.142737

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.139979

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.137059

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.133898
[Checkpoint] Validation metrics - AUC: 0.556452, AUPRC: 0.020948, Loss: 0.122521
[Checkpoint] Validation lifts - @0.5%: 1.959178, @1%: 1.901067, @5%: 1.478452, @10%: 1.329020
[Checkpoint] New best model found! AUPRC: 0.020948 (previous best: 0.020844)

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.130567

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.127166

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.123561

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.119693

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.115787
[Checkpoint] Validation metrics - AUC: 0.448790, AUPRC: 0.015916, Loss: 0.088104
[Checkpoint] Validation lifts - @0.5%: 1.909368, @1%: 1.921821, @5%: 1.092444, @10%: 0.925168

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.111655

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.107489

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.103181

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.098768

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.094237
[Checkpoint] Validation metrics - AUC: 0.448214, AUPRC: 0.015859, Loss: 0.069751
[Checkpoint] Validation lifts - @0.5%: 1.909368, @1%: 1.892765, @5%: 1.099915, @10%: 0.904415

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.089638

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.085095

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.080453

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.075911

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.071416
[Checkpoint] Validation metrics - AUC: 0.447449, AUPRC: 0.015757, Loss: 0.057839
[Checkpoint] Validation lifts - @0.5%: 2.008988, @1%: 1.892765, @5%: 1.034336, @10%: 0.908565

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.066926

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.062682

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.058542

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.054469

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.050583
[Checkpoint] Validation metrics - AUC: 0.435933, AUPRC: 0.014540, Loss: 0.056452
[Checkpoint] Validation lifts - @0.5%: 1.095811, @1%: 0.871668, @5%: 0.752093, @10%: 0.740051

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.046900

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.043439

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.040251

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.037279

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.034482
[Checkpoint] Validation metrics - AUC: 0.440867, AUPRC: 0.015113, Loss: 0.049592
[Checkpoint] Validation lifts - @0.5%: 1.394669, @1%: 1.419574, @5%: 0.946342, @10%: 0.835930

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.031972

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.029687

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.027717

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.025799

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.024162
[Checkpoint] Validation metrics - AUC: 0.452426, AUPRC: 0.016254, Loss: 0.040840
[Checkpoint] Validation lifts - @0.5%: 1.394669, @1%: 1.398820, @5%: 1.266771, @10%: 1.143074

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.022761

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.021453

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.020358

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.019381

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.018527
[Checkpoint] Validation metrics - AUC: 0.488008, AUPRC: 0.017866, Loss: 0.038938
[Checkpoint] Validation lifts - @0.5%: 1.386368, @1%: 1.382217, @5%: 1.331520, @10%: 1.240198

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.017827

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.033118

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.023006

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.021883

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.020048
[Checkpoint] Validation metrics - AUC: 0.453293, AUPRC: 0.015651, Loss: 0.031644
[Checkpoint] Validation lifts - @0.5%: 1.070907, @1%: 1.145621, @5%: 1.079992, @10%: 0.993237

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.018493

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.020948

[Checkpoint] ====== Configuration 38/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 39/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 40/72 ======
[Checkpoint] Training with lr=0.001, hidden=128, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 41/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.167956

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.163626

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.159183

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.155006

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.150900
[Checkpoint] Validation metrics - AUC: 0.565433, AUPRC: 0.020329, Loss: 0.146945
[Checkpoint] Validation lifts - @0.5%: 1.046002, @1%: 1.187129, @5%: 1.242697, @10%: 1.197447

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.146713

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.142419

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.137955

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.133314

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.128468
[Checkpoint] Validation metrics - AUC: 0.558962, AUPRC: 0.020567, Loss: 0.124330
[Checkpoint] Validation lifts - @0.5%: 1.801448, @1%: 1.635416, @5%: 1.387139, @10%: 1.251404

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.123378

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.118064

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.112579

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.106897

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.101094
[Checkpoint] Validation metrics - AUC: 0.457997, AUPRC: 0.015956, Loss: 0.097070
[Checkpoint] Validation lifts - @0.5%: 1.253542, @1%: 1.295050, @5%: 1.149723, @10%: 1.004859

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.095160

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.089136

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.083102

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.077086

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.071177
[Checkpoint] Validation metrics - AUC: 0.436470, AUPRC: 0.014282, Loss: 0.068448
[Checkpoint] Validation lifts - @0.5%: 0.199238, @1%: 0.373572, @5%: 0.695645, @10%: 0.726354

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.065413

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.059828

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.054511

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.049489

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.044800
[Checkpoint] Validation metrics - AUC: 0.433106, AUPRC: 0.014141, Loss: 0.045068
[Checkpoint] Validation lifts - @0.5%: 0.190937, @1%: 0.452437, @5%: 0.649988, @10%: 0.683188

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.040471

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.036514

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.032962

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.029821

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.027066
[Checkpoint] Validation metrics - AUC: 0.431337, AUPRC: 0.014082, Loss: 0.030503
[Checkpoint] Validation lifts - @0.5%: 0.215842, @1%: 0.390175, @5%: 0.618443, @10%: 0.672811

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.024677

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.022646

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.020930

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.019505

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.018327
[Checkpoint] Validation metrics - AUC: 0.420257, AUPRC: 0.013669, Loss: 0.024580
[Checkpoint] Validation lifts - @0.5%: 0.240746, @1%: 0.315461, @5%: 0.536261, @10%: 0.630475

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.017370

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.016599

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.015980

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.015498

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.015102
[Checkpoint] Validation metrics - AUC: 0.420271, AUPRC: 0.013615, Loss: 0.023981
[Checkpoint] Validation lifts - @0.5%: 0.439985, @1%: 0.439985, @5%: 0.472341, @10%: 0.637946

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.014801

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.014562

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.014383

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.014214

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.014098
[Checkpoint] Validation metrics - AUC: 0.422711, AUPRC: 0.013581, Loss: 0.025692
[Checkpoint] Validation lifts - @0.5%: 0.066413, @1%: 0.307159, @5%: 0.213342, @10%: 0.420040

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.014000

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.013911

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.013833

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.013766

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.013700
[Checkpoint] Validation metrics - AUC: 0.425785, AUPRC: 0.013685, Loss: 0.027702
[Checkpoint] Validation lifts - @0.5%: 0.107921, @1%: 0.394326, @5%: 0.324579, @10%: 0.432907

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.013635

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.013591

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.013519

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.013479

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.013425
[Checkpoint] Validation metrics - AUC: 0.422217, AUPRC: 0.013587, Loss: 0.029365
[Checkpoint] Validation lifts - @0.5%: 0.058111, @1%: 0.199238, @5%: 0.354463, @10%: 0.619684

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.013358

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.013311

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.013256

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.013195

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.013132
[Checkpoint] Validation metrics - AUC: 0.423558, AUPRC: 0.013643, Loss: 0.031138
[Checkpoint] Validation lifts - @0.5%: 0.190937, @1%: 0.219992, @5%: 0.375216, @10%: 0.620514

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.013090

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.013035

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.012972

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.012927

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.012860
[Checkpoint] Validation metrics - AUC: 0.423790, AUPRC: 0.013671, Loss: 0.031744
[Checkpoint] Validation lifts - @0.5%: 0.456588, @1%: 0.448287, @5%: 0.381027, @10%: 0.619684

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.012799

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.012736

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.012657

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.012569

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.012497
[Checkpoint] Validation metrics - AUC: 0.423353, AUPRC: 0.013667, Loss: 0.032115
[Checkpoint] Validation lifts - @0.5%: 0.498096, @1%: 0.448287, @5%: 0.384348, @10%: 0.625910

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.012402

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.012316

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.012204

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.012091

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.011969
[Checkpoint] Validation metrics - AUC: 0.422991, AUPRC: 0.013677, Loss: 0.032276
[Checkpoint] Validation lifts - @0.5%: 0.464890, @1%: 0.327913, @5%: 0.386008, @10%: 0.639607

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.011807

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.011654

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.011445

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.011230

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.010972
[Checkpoint] Validation metrics - AUC: 0.423287, AUPRC: 0.013667, Loss: 0.033167
[Checkpoint] Validation lifts - @0.5%: 0.249048, @1%: 0.253199, @5%: 0.383518, @10%: 0.626740

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.010638

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.010240

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.009786

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.009270

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.008729
[Checkpoint] Validation metrics - AUC: 0.422492, AUPRC: 0.013622, Loss: 0.031763
[Checkpoint] Validation lifts - @0.5%: 0.066413, @1%: 0.240746, @5%: 0.382688, @10%: 0.630475
[Checkpoint] Early stopping at epoch 85 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.020567

[Checkpoint] ====== Configuration 42/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 43/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 44/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 45/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 46/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 47/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 48/72 ======
[Checkpoint] Training with lr=0.001, hidden=256, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 49/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 50/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 51/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 52/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 1 layers
[Checkpoint] Total parameters: 45119396
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 53/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 54/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.109077

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.108511

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.107938

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.107539

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.107038
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.539639, AUPRC: 0.020645, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.876162, @1%: 1.842956, @5%: 1.528260, @10%: 1.322380

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.106651

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.106226

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.105866

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.105546

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.105196
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.517575, AUPRC: 0.019784, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.876162, @1%: 1.830503, @5%: 1.532411, @10%: 1.332756

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.104899

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.104654

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.104327

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.104157

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.103802
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.460404, AUPRC: 0.016372, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.818051, @1%: 1.851257, @5%: 1.209492, @10%: 0.968334

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.103577

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.103384

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.103110

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.102854

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.102666
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.453177, AUPRC: 0.015925, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.834654, @1%: 1.872011, @5%: 1.099085, @10%: 0.913546

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.102400

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.102226

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.102051

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.101867

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.101602
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.447011, AUPRC: 0.015795, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.859559, @1%: 1.867860, @5%: 1.116518, @10%: 0.908565

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.101494

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.101303

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.101103

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.100982

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.100807
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.447510, AUPRC: 0.015912, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.859559, @1%: 1.855408, @5%: 1.162175, @10%: 0.938034

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.100661

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.100425

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.100320

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.100184

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.100022
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.450532, AUPRC: 0.016161, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.842956, @1%: 1.855408, @5%: 1.247678, @10%: 0.989502

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.099892

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.099862

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.099568

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.099488

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.099372
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.453791, AUPRC: 0.016401, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.842956, @1%: 1.847106, @5%: 1.287524, @10%: 1.053421

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.099240

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.099071

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.098906

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.098802

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.098696
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.453137, AUPRC: 0.016313, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.851257, @1%: 1.847106, @5%: 1.241867, @10%: 1.033498

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.098521

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.098425

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.098240

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.098135

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.098032
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.448628, AUPRC: 0.015976, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.884464, @1%: 1.851257, @5%: 1.181268, @10%: 0.951731

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.097911

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.097777

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.097648

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.097566

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.097392
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.448689, AUPRC: 0.015966, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.867860, @1%: 1.847106, @5%: 1.174627, @10%: 0.940110

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.097285

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.097170

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.097049

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.096930

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.096810
[Checkpoint] WARNING: NaN detected in probabilities, replacing with 0.5
[Checkpoint] Validation metrics - AUC: 0.447909, AUPRC: 0.015882, Loss: nan
[Checkpoint] Validation lifts - @0.5%: 1.851257, @1%: 1.847106, @5%: 1.131460, @10%: 0.929318

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.096653

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.096564

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.096494

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.096334

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.096308
[Checkpoint] Validation metrics - AUC: 0.447240, AUPRC: 0.015799, Loss: 0.099525
[Checkpoint] Validation lifts - @0.5%: 1.842956, @1%: 1.851257, @5%: 1.096595, @10%: 0.905660

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.096125

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.095972

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.095866

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.095759

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.095653
[Checkpoint] Validation metrics - AUC: 0.446298, AUPRC: 0.015737, Loss: 0.098234
[Checkpoint] Validation lifts - @0.5%: 1.851257, @1%: 1.851257, @5%: 1.087464, @10%: 0.901094

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.095536

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.095384

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.095318

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.095229

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.095131
[Checkpoint] Validation metrics - AUC: 0.446016, AUPRC: 0.015729, Loss: 0.097132
[Checkpoint] Validation lifts - @0.5%: 1.876162, @1%: 1.855408, @5%: 1.079162, @10%: 0.894868

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.094945

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.094825

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.094687

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.094594

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.094447
[Checkpoint] Validation metrics - AUC: 0.446461, AUPRC: 0.015793, Loss: 0.096200
[Checkpoint] Validation lifts - @0.5%: 1.851257, @1%: 1.855408, @5%: 1.101576, @10%: 0.909395
[Checkpoint] Early stopping at epoch 80 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.020645

[Checkpoint] ====== Configuration 55/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 56/72 ======
[Checkpoint] Training with lr=0.0001, hidden=32, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 32 hidden channels, 3 layers
[Checkpoint] Total parameters: 45121508
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 57/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 58/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 59/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 60/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 1 layers
[Checkpoint] Total parameters: 45141380
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.047517

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.047328

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.047144

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.046985

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.046826
[Checkpoint] Validation metrics - AUC: 0.438215, AUPRC: 0.015050, Loss: 0.046627
[Checkpoint] Validation lifts - @0.5%: 1.494288, @1%: 1.622963, @5%: 0.916458, @10%: 0.822233

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.046678

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.046554

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.046415

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.046299

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.046184
[Checkpoint] Validation metrics - AUC: 0.431211, AUPRC: 0.014194, Loss: 0.046275
[Checkpoint] Validation lifts - @0.5%: 0.514699, @1%: 0.523001, @5%: 0.656629, @10%: 0.703941

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.046073

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.045968

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.045859

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.045761

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.045655
[Checkpoint] Validation metrics - AUC: 0.425755, AUPRC: 0.014045, Loss: 0.045911
[Checkpoint] Validation lifts - @0.5%: 0.539604, @1%: 0.560358, @5%: 0.659119, @10%: 0.693149

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.045561

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.045458

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.045381

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.045265

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.045172
[Checkpoint] Validation metrics - AUC: 0.426415, AUPRC: 0.014130, Loss: 0.045521
[Checkpoint] Validation lifts - @0.5%: 0.606017, @1%: 0.647525, @5%: 0.696475, @10%: 0.694810

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.045084

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.044985

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.044891

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.044789

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.044690
[Checkpoint] Validation metrics - AUC: 0.427038, AUPRC: 0.014187, Loss: 0.045112
[Checkpoint] Validation lifts - @0.5%: 0.664128, @1%: 0.697335, @5%: 0.723039, @10%: 0.685678

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.044590

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.044506

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.044409

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.044307

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.044217
[Checkpoint] Validation metrics - AUC: 0.426578, AUPRC: 0.014185, Loss: 0.044693
[Checkpoint] Validation lifts - @0.5%: 0.672430, @1%: 0.742993, @5%: 0.723039, @10%: 0.706431

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.044127

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.044031

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.043933

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.043835

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.043735
[Checkpoint] Validation metrics - AUC: 0.425118, AUPRC: 0.014087, Loss: 0.044276
[Checkpoint] Validation lifts - @0.5%: 0.664128, @1%: 0.651676, @5%: 0.693984, @10%: 0.698130

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.043644

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.043553

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.043458

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.043360

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.043267
[Checkpoint] Validation metrics - AUC: 0.424541, AUPRC: 0.014008, Loss: 0.043856
[Checkpoint] Validation lifts - @0.5%: 0.622620, @1%: 0.601866, @5%: 0.666590, @10%: 0.687754

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.043169

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.043067

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.042970

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.042868

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.042767
[Checkpoint] Validation metrics - AUC: 0.424008, AUPRC: 0.013974, Loss: 0.043440
[Checkpoint] Validation lifts - @0.5%: 0.589414, @1%: 0.597715, @5%: 0.631725, @10%: 0.681113

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.042671

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.042572

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.042468

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.042364

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.042264
[Checkpoint] Validation metrics - AUC: 0.423998, AUPRC: 0.013942, Loss: 0.043033
[Checkpoint] Validation lifts - @0.5%: 0.556207, @1%: 0.585263, @5%: 0.625084, @10%: 0.673226

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.042157

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.042053

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.041943

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.041843

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.041729
[Checkpoint] Validation metrics - AUC: 0.425233, AUPRC: 0.013952, Loss: 0.042560
[Checkpoint] Validation lifts - @0.5%: 0.531303, @1%: 0.556207, @5%: 0.627574, @10%: 0.680283

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.041625

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.041512

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.041398

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.041290

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.041175
[Checkpoint] Validation metrics - AUC: 0.426174, AUPRC: 0.013959, Loss: 0.042032
[Checkpoint] Validation lifts - @0.5%: 0.531303, @1%: 0.552057, @5%: 0.614292, @10%: 0.679867

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.041060

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.040948

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.040838

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.040715

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.040600
[Checkpoint] Validation metrics - AUC: 0.427032, AUPRC: 0.013973, Loss: 0.041436
[Checkpoint] Validation lifts - @0.5%: 0.547906, @1%: 0.547906, @5%: 0.633385, @10%: 0.678207

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.040482

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.040363

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.040242

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.040121

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.039999
[Checkpoint] Validation metrics - AUC: 0.429124, AUPRC: 0.014033, Loss: 0.040836
[Checkpoint] Validation lifts - @0.5%: 0.581112, @1%: 0.564509, @5%: 0.615123, @10%: 0.678622

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.039874

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.039750

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.039624

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.039498

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.039369
[Checkpoint] Validation metrics - AUC: 0.431175, AUPRC: 0.014054, Loss: 0.040282
[Checkpoint] Validation lifts - @0.5%: 0.556207, @1%: 0.552057, @5%: 0.636706, @10%: 0.677377

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.039242

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.039116

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.038983

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.038853

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.038722
[Checkpoint] Validation metrics - AUC: 0.430635, AUPRC: 0.014042, Loss: 0.039827
[Checkpoint] Validation lifts - @0.5%: 0.547906, @1%: 0.556207, @5%: 0.645837, @10%: 0.678207
[Checkpoint] Early stopping at epoch 80 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.015050

[Checkpoint] ====== Configuration 61/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 62/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 63/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.094796

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.093826

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.093060

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.092466

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.091984
[Checkpoint] Validation metrics - AUC: 0.476753, AUPRC: 0.017153, Loss: 0.087139
[Checkpoint] Validation lifts - @0.5%: 1.552400, @1%: 1.386368, @5%: 1.280883, @10%: 1.228161

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.091496

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.091140

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.090756

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.090511

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.090210
[Checkpoint] Validation metrics - AUC: 0.475953, AUPRC: 0.017037, Loss: 0.085891
[Checkpoint] Validation lifts - @0.5%: 1.485987, @1%: 1.390518, @5%: 1.280883, @10%: 1.202012

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.089950

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.089627

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.089411

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.089183

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.089018
[Checkpoint] Validation metrics - AUC: 0.443884, AUPRC: 0.015345, Loss: 0.090554
[Checkpoint] Validation lifts - @0.5%: 1.444479, @1%: 1.390518, @5%: 1.040146, @10%: 0.874530

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.088745

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.088611

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.088408

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.088245

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.088079
[Checkpoint] Validation metrics - AUC: 0.479519, AUPRC: 0.017174, Loss: 0.098886
[Checkpoint] Validation lifts - @0.5%: 1.461082, @1%: 1.361463, @5%: 1.163005, @10%: 1.145979

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.087881

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.087697

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.087510

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.087333

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.087161
[Checkpoint] Validation metrics - AUC: 0.536474, AUPRC: 0.019468, Loss: 0.099914
[Checkpoint] Validation lifts - @0.5%: 1.469384, @1%: 1.357312, @5%: 1.171306, @10%: 1.181259

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.087010

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.086855

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.086698

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.086528

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.086392
[Checkpoint] Validation metrics - AUC: 0.534280, AUPRC: 0.019369, Loss: 0.096618
[Checkpoint] Validation lifts - @0.5%: 1.477685, @1%: 1.365614, @5%: 1.192889, @10%: 1.173788

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.086230

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.086079

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.085918

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.085830

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.085630
[Checkpoint] Validation metrics - AUC: 0.452051, AUPRC: 0.015973, Loss: 0.093764
[Checkpoint] Validation lifts - @0.5%: 1.485987, @1%: 1.332407, @5%: 1.192059, @10%: 1.045120

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.085455

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.085310

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.085130

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.084983

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.084853
[Checkpoint] Validation metrics - AUC: 0.453142, AUPRC: 0.016168, Loss: 0.091552
[Checkpoint] Validation lifts - @0.5%: 1.469384, @1%: 1.361463, @5%: 1.174627, @10%: 1.137678

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.084725

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.084575

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.084433

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.084258

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.084098
[Checkpoint] Validation metrics - AUC: 0.466129, AUPRC: 0.016779, Loss: 0.089617
[Checkpoint] Validation lifts - @0.5%: 1.344860, @1%: 1.373915, @5%: 1.175457, @10%: 1.180844

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.083954

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.083805

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.083657

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.083489

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.083377
[Checkpoint] Validation metrics - AUC: 0.446092, AUPRC: 0.016035, Loss: 0.088005
[Checkpoint] Validation lifts - @0.5%: 1.992384, @1%: 1.888614, @5%: 1.209492, @10%: 0.989087

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.083228

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.083070

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.082874

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.082764

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.082595
[Checkpoint] Validation metrics - AUC: 0.451716, AUPRC: 0.016454, Loss: 0.086612
[Checkpoint] Validation lifts - @0.5%: 1.942575, @1%: 1.901067, @5%: 1.298315, @10%: 1.064628

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.082429

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.082281

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.082099

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.081981

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.081811
[Checkpoint] Validation metrics - AUC: 0.451067, AUPRC: 0.016358, Loss: 0.084839
[Checkpoint] Validation lifts - @0.5%: 1.884464, @1%: 1.901067, @5%: 1.297485, @10%: 1.030178

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.081642

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.081492

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.081357

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.081131

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.080986
[Checkpoint] Validation metrics - AUC: 0.451866, AUPRC: 0.016408, Loss: 0.083226
[Checkpoint] Validation lifts - @0.5%: 1.884464, @1%: 1.921821, @5%: 1.292504, @10%: 1.053836

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.080815

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.080656

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.080486

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.080339

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.080163
[Checkpoint] Validation metrics - AUC: 0.459482, AUPRC: 0.016960, Loss: 0.081767
[Checkpoint] Validation lifts - @0.5%: 1.876162, @1%: 1.905218, @5%: 1.375517, @10%: 1.182089

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.079995

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.079785

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.079601

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.079450

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.079245
[Checkpoint] Validation metrics - AUC: 0.482032, AUPRC: 0.018062, Loss: 0.080132
[Checkpoint] Validation lifts - @0.5%: 1.901067, @1%: 1.905218, @5%: 1.399591, @10%: 1.245594

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.079090

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.078943

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.078720

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.078535

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.078376
[Checkpoint] Validation metrics - AUC: 0.531985, AUPRC: 0.019817, Loss: 0.078615
[Checkpoint] Validation lifts - @0.5%: 1.884464, @1%: 1.909368, @5%: 1.404571, @10%: 1.260121

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.078175

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.077975

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.077821

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.077619

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.077425
[Checkpoint] Validation metrics - AUC: 0.473418, AUPRC: 0.017725, Loss: 0.077432
[Checkpoint] Validation lifts - @0.5%: 1.859559, @1%: 1.909368, @5%: 1.401251, @10%: 1.242688

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.077244

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.077064

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.076864

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.076662

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.076523
[Checkpoint] Validation metrics - AUC: 0.499586, AUPRC: 0.019004, Loss: 0.076596
[Checkpoint] Validation lifts - @0.5%: 1.909368, @1%: 1.917670, @5%: 1.418683, @10%: 1.283364

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.076331

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.076055

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.075858

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.075699

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.075466
[Checkpoint] Validation metrics - AUC: 0.453871, AUPRC: 0.016496, Loss: 0.075442
[Checkpoint] Validation lifts - @0.5%: 1.942575, @1%: 1.917670, @5%: 1.111537, @10%: 0.842156

[Checkpoint] --- Epoch 96/200 ---
[Checkpoint] Epoch 96 training loss: 0.075260

[Checkpoint] --- Epoch 97/200 ---
[Checkpoint] Epoch 97 training loss: 0.075058

[Checkpoint] --- Epoch 98/200 ---
[Checkpoint] Epoch 98 training loss: 0.074822

[Checkpoint] --- Epoch 99/200 ---
[Checkpoint] Epoch 99 training loss: 0.074606

[Checkpoint] --- Epoch 100/200 ---
[Checkpoint] Epoch 100 training loss: 0.074400
[Checkpoint] Validation metrics - AUC: 0.454258, AUPRC: 0.016208, Loss: 0.074542
[Checkpoint] Validation lifts - @0.5%: 1.934273, @1%: 1.925972, @5%: 1.031845, @10%: 0.888642

[Checkpoint] --- Epoch 101/200 ---
[Checkpoint] Epoch 101 training loss: 0.074208

[Checkpoint] --- Epoch 102/200 ---
[Checkpoint] Epoch 102 training loss: 0.073920

[Checkpoint] --- Epoch 103/200 ---
[Checkpoint] Epoch 103 training loss: 0.073736

[Checkpoint] --- Epoch 104/200 ---
[Checkpoint] Epoch 104 training loss: 0.073497

[Checkpoint] --- Epoch 105/200 ---
[Checkpoint] Epoch 105 training loss: 0.073322
[Checkpoint] Validation metrics - AUC: 0.452897, AUPRC: 0.016139, Loss: 0.073624
[Checkpoint] Validation lifts - @0.5%: 1.934273, @1%: 1.921821, @5%: 1.050938, @10%: 0.846306

[Checkpoint] --- Epoch 106/200 ---
[Checkpoint] Epoch 106 training loss: 0.073068

[Checkpoint] --- Epoch 107/200 ---
[Checkpoint] Epoch 107 training loss: 0.072869

[Checkpoint] --- Epoch 108/200 ---
[Checkpoint] Epoch 108 training loss: 0.072647

[Checkpoint] --- Epoch 109/200 ---
[Checkpoint] Epoch 109 training loss: 0.072430

[Checkpoint] --- Epoch 110/200 ---
[Checkpoint] Epoch 110 training loss: 0.072143
[Checkpoint] Validation metrics - AUC: 0.451785, AUPRC: 0.016230, Loss: 0.072205
[Checkpoint] Validation lifts - @0.5%: 1.934273, @1%: 1.901067, @5%: 1.036826, @10%: 0.914791

[Checkpoint] --- Epoch 111/200 ---
[Checkpoint] Epoch 111 training loss: 0.071949

[Checkpoint] --- Epoch 112/200 ---
[Checkpoint] Epoch 112 training loss: 0.071721

[Checkpoint] --- Epoch 113/200 ---
[Checkpoint] Epoch 113 training loss: 0.071474

[Checkpoint] --- Epoch 114/200 ---
[Checkpoint] Epoch 114 training loss: 0.071202

[Checkpoint] --- Epoch 115/200 ---
[Checkpoint] Epoch 115 training loss: 0.070961
[Checkpoint] Validation metrics - AUC: 0.451298, AUPRC: 0.016255, Loss: 0.071242
[Checkpoint] Validation lifts - @0.5%: 1.967480, @1%: 1.888614, @5%: 1.119008, @10%: 0.840080

[Checkpoint] --- Epoch 116/200 ---
[Checkpoint] Epoch 116 training loss: 0.070761

[Checkpoint] --- Epoch 117/200 ---
[Checkpoint] Epoch 117 training loss: 0.070523

[Checkpoint] --- Epoch 118/200 ---
[Checkpoint] Epoch 118 training loss: 0.070249

[Checkpoint] --- Epoch 119/200 ---
[Checkpoint] Epoch 119 training loss: 0.069993

[Checkpoint] --- Epoch 120/200 ---
[Checkpoint] Epoch 120 training loss: 0.069767
[Checkpoint] Validation metrics - AUC: 0.450916, AUPRC: 0.016228, Loss: 0.070042
[Checkpoint] Validation lifts - @0.5%: 1.975781, @1%: 1.888614, @5%: 1.045957, @10%: 0.863324

[Checkpoint] --- Epoch 121/200 ---
[Checkpoint] Epoch 121 training loss: 0.069515

[Checkpoint] --- Epoch 122/200 ---
[Checkpoint] Epoch 122 training loss: 0.069261

[Checkpoint] --- Epoch 123/200 ---
[Checkpoint] Epoch 123 training loss: 0.069043

[Checkpoint] --- Epoch 124/200 ---
[Checkpoint] Epoch 124 training loss: 0.068800

[Checkpoint] --- Epoch 125/200 ---
[Checkpoint] Epoch 125 training loss: 0.068453
[Checkpoint] Validation metrics - AUC: 0.450178, AUPRC: 0.016315, Loss: 0.069460
[Checkpoint] Validation lifts - @0.5%: 1.967480, @1%: 1.892765, @5%: 1.040977, @10%: 0.816007

[Checkpoint] --- Epoch 126/200 ---
[Checkpoint] Epoch 126 training loss: 0.068241

[Checkpoint] --- Epoch 127/200 ---
[Checkpoint] Epoch 127 training loss: 0.067981

[Checkpoint] --- Epoch 128/200 ---
[Checkpoint] Epoch 128 training loss: 0.067690

[Checkpoint] --- Epoch 129/200 ---
[Checkpoint] Epoch 129 training loss: 0.067430

[Checkpoint] --- Epoch 130/200 ---
[Checkpoint] Epoch 130 training loss: 0.067189
[Checkpoint] Validation metrics - AUC: 0.450284, AUPRC: 0.016154, Loss: 0.068004
[Checkpoint] Validation lifts - @0.5%: 1.984083, @1%: 1.888614, @5%: 1.022714, @10%: 0.811856

[Checkpoint] --- Epoch 131/200 ---
[Checkpoint] Epoch 131 training loss: 0.066912

[Checkpoint] --- Epoch 132/200 ---
[Checkpoint] Epoch 132 training loss: 0.066631

[Checkpoint] --- Epoch 133/200 ---
[Checkpoint] Epoch 133 training loss: 0.066385

[Checkpoint] --- Epoch 134/200 ---
[Checkpoint] Epoch 134 training loss: 0.066121

[Checkpoint] --- Epoch 135/200 ---
[Checkpoint] Epoch 135 training loss: 0.065929
[Checkpoint] Validation metrics - AUC: 0.449782, AUPRC: 0.016901, Loss: 0.067472
[Checkpoint] Validation lifts - @0.5%: 2.033892, @1%: 1.876162, @5%: 0.986188, @10%: 0.774501

[Checkpoint] --- Epoch 136/200 ---
[Checkpoint] Epoch 136 training loss: 0.065627

[Checkpoint] --- Epoch 137/200 ---
[Checkpoint] Epoch 137 training loss: 0.065308

[Checkpoint] --- Epoch 138/200 ---
[Checkpoint] Epoch 138 training loss: 0.065025

[Checkpoint] --- Epoch 139/200 ---
[Checkpoint] Epoch 139 training loss: 0.064700

[Checkpoint] --- Epoch 140/200 ---
[Checkpoint] Epoch 140 training loss: 0.064483
[Checkpoint] Validation metrics - AUC: 0.449329, AUPRC: 0.016167, Loss: 0.066837
[Checkpoint] Validation lifts - @0.5%: 2.025591, @1%: 1.876162, @5%: 1.055089, @10%: 0.831364

[Checkpoint] --- Epoch 141/200 ---
[Checkpoint] Epoch 141 training loss: 0.064242

[Checkpoint] --- Epoch 142/200 ---
[Checkpoint] Epoch 142 training loss: 0.063913

[Checkpoint] --- Epoch 143/200 ---
[Checkpoint] Epoch 143 training loss: 0.063672

[Checkpoint] --- Epoch 144/200 ---
[Checkpoint] Epoch 144 training loss: 0.063396

[Checkpoint] --- Epoch 145/200 ---
[Checkpoint] Epoch 145 training loss: 0.063122
[Checkpoint] Validation metrics - AUC: 0.449080, AUPRC: 0.016343, Loss: 0.066615
[Checkpoint] Validation lifts - @0.5%: 2.058797, @1%: 1.876162, @5%: 0.972906, @10%: 0.775746

[Checkpoint] --- Epoch 146/200 ---
[Checkpoint] Epoch 146 training loss: 0.062869

[Checkpoint] --- Epoch 147/200 ---
[Checkpoint] Epoch 147 training loss: 0.062527

[Checkpoint] --- Epoch 148/200 ---
[Checkpoint] Epoch 148 training loss: 0.062279

[Checkpoint] --- Epoch 149/200 ---
[Checkpoint] Epoch 149 training loss: 0.061995

[Checkpoint] --- Epoch 150/200 ---
[Checkpoint] Epoch 150 training loss: 0.061758
[Checkpoint] Validation metrics - AUC: 0.448807, AUPRC: 0.016013, Loss: 0.066696
[Checkpoint] Validation lifts - @0.5%: 2.033892, @1%: 1.876162, @5%: 0.982038, @10%: 0.877436

[Checkpoint] --- Epoch 151/200 ---
[Checkpoint] Epoch 151 training loss: 0.061459

[Checkpoint] --- Epoch 152/200 ---
[Checkpoint] Epoch 152 training loss: 0.061124

[Checkpoint] --- Epoch 153/200 ---
[Checkpoint] Epoch 153 training loss: 0.060864

[Checkpoint] --- Epoch 154/200 ---
[Checkpoint] Epoch 154 training loss: 0.060606

[Checkpoint] --- Epoch 155/200 ---
[Checkpoint] Epoch 155 training loss: 0.060261
[Checkpoint] Validation metrics - AUC: 0.448081, AUPRC: 0.016193, Loss: 0.066331
[Checkpoint] Validation lifts - @0.5%: 2.058797, @1%: 1.896916, @5%: 0.967926, @10%: 0.781142
[Checkpoint] Early stopping at epoch 155 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.019817

[Checkpoint] ====== Configuration 64/72 ======
[Checkpoint] Training with lr=0.0001, hidden=128, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 128 hidden channels, 3 layers
[Checkpoint] Total parameters: 45174404
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 65/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.170260

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.169627

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.169016

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.168535

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.168076
[Checkpoint] Validation metrics - AUC: 0.549694, AUPRC: 0.020106, Loss: 0.166996
[Checkpoint] Validation lifts - @0.5%: 1.178827, @1%: 1.282598, @5%: 1.349783, @10%: 1.312418

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.167624

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.167252

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.166891

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.166488

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.166115
[Checkpoint] Validation metrics - AUC: 0.544022, AUPRC: 0.020611, Loss: 0.165252
[Checkpoint] Validation lifts - @0.5%: 1.784844, @1%: 1.818051, @5%: 1.477622, @10%: 1.388789

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.165756

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.165389

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.165010

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.164658

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.164292
[Checkpoint] Validation metrics - AUC: 0.512219, AUPRC: 0.019423, Loss: 0.163687
[Checkpoint] Validation lifts - @0.5%: 1.801448, @1%: 1.722582, @5%: 1.476792, @10%: 1.359735

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.163904

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.163556

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.163191

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.162842

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.162472
[Checkpoint] Validation metrics - AUC: 0.469813, AUPRC: 0.016914, Loss: 0.162169
[Checkpoint] Validation lifts - @0.5%: 1.328256, @1%: 1.241090, @5%: 1.303296, @10%: 1.227331

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.162145

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.161791

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.161431

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.161085

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.160746
[Checkpoint] Validation metrics - AUC: 0.463029, AUPRC: 0.016470, Loss: 0.160579
[Checkpoint] Validation lifts - @0.5%: 1.386368, @1%: 1.357312, @5%: 1.293335, @10%: 1.107794

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.160375

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.160031

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.159679

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.159319

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.158982
[Checkpoint] Validation metrics - AUC: 0.447157, AUPRC: 0.015142, Loss: 0.158926
[Checkpoint] Validation lifts - @0.5%: 1.394669, @1%: 1.166375, @5%: 0.718058, @10%: 0.636701

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.158621

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.158271

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.157908

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.157570

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.157222
[Checkpoint] Validation metrics - AUC: 0.440889, AUPRC: 0.014677, Loss: 0.157253
[Checkpoint] Validation lifts - @0.5%: 0.871668, @1%: 0.776200, @5%: 0.743792, @10%: 0.677377

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.156852

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.156493

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.156141

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.155779

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.155402
[Checkpoint] Validation metrics - AUC: 0.437907, AUPRC: 0.014205, Loss: 0.155563
[Checkpoint] Validation lifts - @0.5%: 0.547906, @1%: 0.597715, @5%: 0.584408, @10%: 0.591460

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.155031

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.154665

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.154280

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.153903

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.153517
[Checkpoint] Validation metrics - AUC: 0.436437, AUPRC: 0.013829, Loss: 0.153756
[Checkpoint] Validation lifts - @0.5%: 0.265651, @1%: 0.381874, @5%: 0.566145, @10%: 0.561991

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.153135

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.152728

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.152343

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.151930

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.151545
[Checkpoint] Validation metrics - AUC: 0.435636, AUPRC: 0.014158, Loss: 0.151834
[Checkpoint] Validation lifts - @0.5%: 0.240746, @1%: 0.506398, @5%: 0.642517, @10%: 0.602666

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.151131

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.150727

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.150313

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.149884

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.149467
[Checkpoint] Validation metrics - AUC: 0.434547, AUPRC: 0.014138, Loss: 0.149910
[Checkpoint] Validation lifts - @0.5%: 0.207540, @1%: 0.477342, @5%: 0.605991, @10%: 0.670736

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.149041

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.148609

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.148163

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.147723

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.147272
[Checkpoint] Validation metrics - AUC: 0.434019, AUPRC: 0.013790, Loss: 0.147933
[Checkpoint] Validation lifts - @0.5%: 0.215842, @1%: 0.377723, @5%: 0.532110, @10%: 0.543728

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.146831

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.146377

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.145913

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.145454

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.144979
[Checkpoint] Validation metrics - AUC: 0.433652, AUPRC: 0.013728, Loss: 0.145962
[Checkpoint] Validation lifts - @0.5%: 0.190937, @1%: 0.402628, @5%: 0.561995, @10%: 0.602251

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.144506

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.144025

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.143540

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.143062

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.142561
[Checkpoint] Validation metrics - AUC: 0.433562, AUPRC: 0.013874, Loss: 0.143984
[Checkpoint] Validation lifts - @0.5%: 0.190937, @1%: 0.464890, @5%: 0.556184, @10%: 0.569047

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.142053

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.141546

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.141038

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.140517

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.139990
[Checkpoint] Validation metrics - AUC: 0.433482, AUPRC: 0.013902, Loss: 0.141930
[Checkpoint] Validation lifts - @0.5%: 0.207540, @1%: 0.460739, @5%: 0.535431, @10%: 0.565311

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.139448

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.138916

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.138374

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.137813

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.137251
[Checkpoint] Validation metrics - AUC: 0.433727, AUPRC: 0.013959, Loss: 0.139417
[Checkpoint] Validation lifts - @0.5%: 0.273953, @1%: 0.402628, @5%: 0.561995, @10%: 0.550784

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.136674

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.136106

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.135518

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.134934

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.134339
[Checkpoint] Validation metrics - AUC: 0.433975, AUPRC: 0.014187, Loss: 0.136366
[Checkpoint] Validation lifts - @0.5%: 0.240746, @1%: 0.531303, @5%: 0.620103, @10%: 0.606402
[Checkpoint] Early stopping at epoch 85 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.020611

[Checkpoint] ====== Configuration 66/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 67/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.090169

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.089844

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.089558

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.089318

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.089070
[Checkpoint] Validation metrics - AUC: 0.513546, AUPRC: 0.019510, Loss: 0.089685
[Checkpoint] Validation lifts - @0.5%: 1.909368, @1%: 1.643717, @5%: 1.424494, @10%: 1.356829

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.088861

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.088660

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.088435

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.088225

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.088030
[Checkpoint] Validation metrics - AUC: 0.506487, AUPRC: 0.018943, Loss: 0.088812
[Checkpoint] Validation lifts - @0.5%: 1.735035, @1%: 1.564852, @5%: 1.337331, @10%: 1.293740

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.087839

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.087626

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.087426

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.087225

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.087026
[Checkpoint] Validation metrics - AUC: 0.493396, AUPRC: 0.018319, Loss: 0.087932
[Checkpoint] Validation lifts - @0.5%: 1.718432, @1%: 1.569003, @5%: 1.314918, @10%: 1.281289

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.086819

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.086627

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.086414

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.086214

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.086012
[Checkpoint] Validation metrics - AUC: 0.475008, AUPRC: 0.017543, Loss: 0.087048
[Checkpoint] Validation lifts - @0.5%: 1.660320, @1%: 1.569003, @5%: 1.309107, @10%: 1.258460

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.085818

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.085616

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.085407

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.085199

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.085000
[Checkpoint] Validation metrics - AUC: 0.464113, AUPRC: 0.016894, Loss: 0.086146
[Checkpoint] Validation lifts - @0.5%: 1.643717, @1%: 1.560701, @5%: 1.304126, @10%: 1.185410

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.084794

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.084597

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.084385

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.084177

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.083965
[Checkpoint] Validation metrics - AUC: 0.459552, AUPRC: 0.016643, Loss: 0.085168
[Checkpoint] Validation lifts - @0.5%: 1.710130, @1%: 1.556550, @5%: 1.316578, @10%: 1.165487

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.083754

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.083539

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.083330

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.083110

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.082895
[Checkpoint] Validation metrics - AUC: 0.459973, AUPRC: 0.016704, Loss: 0.084112
[Checkpoint] Validation lifts - @0.5%: 1.776543, @1%: 1.564852, @5%: 1.344802, @10%: 1.150960

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.082672

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.082450

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.082221

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.081994

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.081758
[Checkpoint] Validation metrics - AUC: 0.456269, AUPRC: 0.016577, Loss: 0.083010
[Checkpoint] Validation lifts - @0.5%: 1.851257, @1%: 1.585606, @5%: 1.412873, @10%: 1.076664

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.081538

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.081302

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.081065

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.080830

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.080595
[Checkpoint] Validation metrics - AUC: 0.450361, AUPRC: 0.016161, Loss: 0.081888
[Checkpoint] Validation lifts - @0.5%: 1.834654, @1%: 1.818051, @5%: 1.229415, @10%: 0.949656

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.080352

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.080107

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.079860

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.079616

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.079363
[Checkpoint] Validation metrics - AUC: 0.447786, AUPRC: 0.015976, Loss: 0.080773
[Checkpoint] Validation lifts - @0.5%: 1.867860, @1%: 1.834654, @5%: 1.048448, @10%: 0.826799

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.079110

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.078852

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.078589

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.078328

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.078057
[Checkpoint] Validation metrics - AUC: 0.441784, AUPRC: 0.014743, Loss: 0.079675
[Checkpoint] Validation lifts - @0.5%: 1.162224, @1%: 0.821859, @5%: 0.677382, @10%: 0.689829

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.077782

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.077508

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.077233

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.076951

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.076669
[Checkpoint] Validation metrics - AUC: 0.439880, AUPRC: 0.014126, Loss: 0.078475
[Checkpoint] Validation lifts - @0.5%: 0.290556, @1%: 0.444136, @5%: 0.603501, @10%: 0.706846

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.076382

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.076090

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.075790

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.075496

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.075192
[Checkpoint] Validation metrics - AUC: 0.437055, AUPRC: 0.014182, Loss: 0.077167
[Checkpoint] Validation lifts - @0.5%: 0.323762, @1%: 0.485644, @5%: 0.592709, @10%: 0.582744

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.074891

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.074587

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.074272

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.073961

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.073644
[Checkpoint] Validation metrics - AUC: 0.435407, AUPRC: 0.014131, Loss: 0.075789
[Checkpoint] Validation lifts - @0.5%: 0.249048, @1%: 0.502247, @5%: 0.635046, @10%: 0.605572

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.073320

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.072996

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.072667

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.072348

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.072013
[Checkpoint] Validation metrics - AUC: 0.435586, AUPRC: 0.014170, Loss: 0.074127
[Checkpoint] Validation lifts - @0.5%: 0.166032, @1%: 0.419231, @5%: 0.644177, @10%: 0.622174

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.071682

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.071343

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.070998

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.070651

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.070306
[Checkpoint] Validation metrics - AUC: 0.436101, AUPRC: 0.014197, Loss: 0.072308
[Checkpoint] Validation lifts - @0.5%: 0.240746, @1%: 0.523001, @5%: 0.632555, @10%: 0.659114
[Checkpoint] Early stopping at epoch 80 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.019510

[Checkpoint] ====== Configuration 68/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=1, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 1 layers
[Checkpoint] Total parameters: 45199364
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] Epoch 1 training loss: 0.047260

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] Epoch 2 training loss: 0.046916

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] Epoch 3 training loss: 0.046612

[Checkpoint] --- Epoch 4/200 ---
[Checkpoint] Epoch 4 training loss: 0.046366

[Checkpoint] --- Epoch 5/200 ---
[Checkpoint] Epoch 5 training loss: 0.046143
[Checkpoint] Validation metrics - AUC: 0.549252, AUPRC: 0.019644, Loss: 0.045975
[Checkpoint] Validation lifts - @0.5%: 1.369764, @1%: 1.361463, @5%: 1.257639, @10%: 1.223595

[Checkpoint] --- Epoch 6/200 ---
[Checkpoint] Epoch 6 training loss: 0.045936

[Checkpoint] --- Epoch 7/200 ---
[Checkpoint] Epoch 7 training loss: 0.045741

[Checkpoint] --- Epoch 8/200 ---
[Checkpoint] Epoch 8 training loss: 0.045557

[Checkpoint] --- Epoch 9/200 ---
[Checkpoint] Epoch 9 training loss: 0.045377

[Checkpoint] --- Epoch 10/200 ---
[Checkpoint] Epoch 10 training loss: 0.045200
[Checkpoint] Validation metrics - AUC: 0.560348, AUPRC: 0.020205, Loss: 0.045241
[Checkpoint] Validation lifts - @0.5%: 1.378066, @1%: 1.423725, @5%: 1.265110, @10%: 1.232727

[Checkpoint] --- Epoch 11/200 ---
[Checkpoint] Epoch 11 training loss: 0.045030

[Checkpoint] --- Epoch 12/200 ---
[Checkpoint] Epoch 12 training loss: 0.044857

[Checkpoint] --- Epoch 13/200 ---
[Checkpoint] Epoch 13 training loss: 0.044667

[Checkpoint] --- Epoch 14/200 ---
[Checkpoint] Epoch 14 training loss: 0.044501

[Checkpoint] --- Epoch 15/200 ---
[Checkpoint] Epoch 15 training loss: 0.044326
[Checkpoint] Validation metrics - AUC: 0.561927, AUPRC: 0.020233, Loss: 0.044547
[Checkpoint] Validation lifts - @0.5%: 1.411272, @1%: 1.382217, @5%: 1.252658, @10%: 1.207823

[Checkpoint] --- Epoch 16/200 ---
[Checkpoint] Epoch 16 training loss: 0.044160

[Checkpoint] --- Epoch 17/200 ---
[Checkpoint] Epoch 17 training loss: 0.043987

[Checkpoint] --- Epoch 18/200 ---
[Checkpoint] Epoch 18 training loss: 0.043822

[Checkpoint] --- Epoch 19/200 ---
[Checkpoint] Epoch 19 training loss: 0.043662

[Checkpoint] --- Epoch 20/200 ---
[Checkpoint] Epoch 20 training loss: 0.043496
[Checkpoint] Validation metrics - AUC: 0.562365, AUPRC: 0.020248, Loss: 0.043850
[Checkpoint] Validation lifts - @0.5%: 1.402971, @1%: 1.373915, @5%: 1.255979, @10%: 1.194541

[Checkpoint] --- Epoch 21/200 ---
[Checkpoint] Epoch 21 training loss: 0.043334

[Checkpoint] --- Epoch 22/200 ---
[Checkpoint] Epoch 22 training loss: 0.043170

[Checkpoint] --- Epoch 23/200 ---
[Checkpoint] Epoch 23 training loss: 0.043019

[Checkpoint] --- Epoch 24/200 ---
[Checkpoint] Epoch 24 training loss: 0.042855

[Checkpoint] --- Epoch 25/200 ---
[Checkpoint] Epoch 25 training loss: 0.042705
[Checkpoint] Validation metrics - AUC: 0.562531, AUPRC: 0.020257, Loss: 0.043148
[Checkpoint] Validation lifts - @0.5%: 1.394669, @1%: 1.394669, @5%: 1.255149, @10%: 1.199522

[Checkpoint] --- Epoch 26/200 ---
[Checkpoint] Epoch 26 training loss: 0.042550

[Checkpoint] --- Epoch 27/200 ---
[Checkpoint] Epoch 27 training loss: 0.042381

[Checkpoint] --- Epoch 28/200 ---
[Checkpoint] Epoch 28 training loss: 0.042229

[Checkpoint] --- Epoch 29/200 ---
[Checkpoint] Epoch 29 training loss: 0.042076

[Checkpoint] --- Epoch 30/200 ---
[Checkpoint] Epoch 30 training loss: 0.041917
[Checkpoint] Validation metrics - AUC: 0.562587, AUPRC: 0.020262, Loss: 0.042428
[Checkpoint] Validation lifts - @0.5%: 1.402971, @1%: 1.407122, @5%: 1.254319, @10%: 1.203257

[Checkpoint] --- Epoch 31/200 ---
[Checkpoint] Epoch 31 training loss: 0.041763

[Checkpoint] --- Epoch 32/200 ---
[Checkpoint] Epoch 32 training loss: 0.041607

[Checkpoint] --- Epoch 33/200 ---
[Checkpoint] Epoch 33 training loss: 0.041451

[Checkpoint] --- Epoch 34/200 ---
[Checkpoint] Epoch 34 training loss: 0.041292

[Checkpoint] --- Epoch 35/200 ---
[Checkpoint] Epoch 35 training loss: 0.041129
[Checkpoint] Validation metrics - AUC: 0.563501, AUPRC: 0.020328, Loss: 0.041672
[Checkpoint] Validation lifts - @0.5%: 1.386368, @1%: 1.411272, @5%: 1.265110, @10%: 1.207823

[Checkpoint] --- Epoch 36/200 ---
[Checkpoint] Epoch 36 training loss: 0.040978

[Checkpoint] --- Epoch 37/200 ---
[Checkpoint] Epoch 37 training loss: 0.040814

[Checkpoint] --- Epoch 38/200 ---
[Checkpoint] Epoch 38 training loss: 0.040653

[Checkpoint] --- Epoch 39/200 ---
[Checkpoint] Epoch 39 training loss: 0.040494

[Checkpoint] --- Epoch 40/200 ---
[Checkpoint] Epoch 40 training loss: 0.040335
[Checkpoint] Validation metrics - AUC: 0.563757, AUPRC: 0.020400, Loss: 0.040902
[Checkpoint] Validation lifts - @0.5%: 1.369764, @1%: 1.423725, @5%: 1.268431, @10%: 1.219030

[Checkpoint] --- Epoch 41/200 ---
[Checkpoint] Epoch 41 training loss: 0.040169

[Checkpoint] --- Epoch 42/200 ---
[Checkpoint] Epoch 42 training loss: 0.040007

[Checkpoint] --- Epoch 43/200 ---
[Checkpoint] Epoch 43 training loss: 0.039840

[Checkpoint] --- Epoch 44/200 ---
[Checkpoint] Epoch 44 training loss: 0.039679

[Checkpoint] --- Epoch 45/200 ---
[Checkpoint] Epoch 45 training loss: 0.039515
[Checkpoint] Validation metrics - AUC: 0.563491, AUPRC: 0.020411, Loss: 0.040155
[Checkpoint] Validation lifts - @0.5%: 1.386368, @1%: 1.432026, @5%: 1.269261, @10%: 1.224010

[Checkpoint] --- Epoch 46/200 ---
[Checkpoint] Epoch 46 training loss: 0.039349

[Checkpoint] --- Epoch 47/200 ---
[Checkpoint] Epoch 47 training loss: 0.039183

[Checkpoint] --- Epoch 48/200 ---
[Checkpoint] Epoch 48 training loss: 0.039015

[Checkpoint] --- Epoch 49/200 ---
[Checkpoint] Epoch 49 training loss: 0.038844

[Checkpoint] --- Epoch 50/200 ---
[Checkpoint] Epoch 50 training loss: 0.038672
[Checkpoint] Validation metrics - AUC: 0.563084, AUPRC: 0.020352, Loss: 0.039423
[Checkpoint] Validation lifts - @0.5%: 1.411272, @1%: 1.432026, @5%: 1.262620, @10%: 1.211559

[Checkpoint] --- Epoch 51/200 ---
[Checkpoint] Epoch 51 training loss: 0.038501

[Checkpoint] --- Epoch 52/200 ---
[Checkpoint] Epoch 52 training loss: 0.038327

[Checkpoint] --- Epoch 53/200 ---
[Checkpoint] Epoch 53 training loss: 0.038151

[Checkpoint] --- Epoch 54/200 ---
[Checkpoint] Epoch 54 training loss: 0.037975

[Checkpoint] --- Epoch 55/200 ---
[Checkpoint] Epoch 55 training loss: 0.037799
[Checkpoint] Validation metrics - AUC: 0.561799, AUPRC: 0.020241, Loss: 0.038680
[Checkpoint] Validation lifts - @0.5%: 1.427876, @1%: 1.427876, @5%: 1.250998, @10%: 1.203257

[Checkpoint] --- Epoch 56/200 ---
[Checkpoint] Epoch 56 training loss: 0.037623

[Checkpoint] --- Epoch 57/200 ---
[Checkpoint] Epoch 57 training loss: 0.037440

[Checkpoint] --- Epoch 58/200 ---
[Checkpoint] Epoch 58 training loss: 0.037266

[Checkpoint] --- Epoch 59/200 ---
[Checkpoint] Epoch 59 training loss: 0.037080

[Checkpoint] --- Epoch 60/200 ---
[Checkpoint] Epoch 60 training loss: 0.036897
[Checkpoint] Validation metrics - AUC: 0.557608, AUPRC: 0.020098, Loss: 0.037936
[Checkpoint] Validation lifts - @0.5%: 1.452780, @1%: 1.432026, @5%: 1.243527, @10%: 1.194126

[Checkpoint] --- Epoch 61/200 ---
[Checkpoint] Epoch 61 training loss: 0.036711

[Checkpoint] --- Epoch 62/200 ---
[Checkpoint] Epoch 62 training loss: 0.036530

[Checkpoint] --- Epoch 63/200 ---
[Checkpoint] Epoch 63 training loss: 0.036345

[Checkpoint] --- Epoch 64/200 ---
[Checkpoint] Epoch 64 training loss: 0.036158

[Checkpoint] --- Epoch 65/200 ---
[Checkpoint] Epoch 65 training loss: 0.035969
[Checkpoint] Validation metrics - AUC: 0.554149, AUPRC: 0.020033, Loss: 0.037158
[Checkpoint] Validation lifts - @0.5%: 1.510892, @1%: 1.440328, @5%: 1.231905, @10%: 1.209068

[Checkpoint] --- Epoch 66/200 ---
[Checkpoint] Epoch 66 training loss: 0.035776

[Checkpoint] --- Epoch 67/200 ---
[Checkpoint] Epoch 67 training loss: 0.035586

[Checkpoint] --- Epoch 68/200 ---
[Checkpoint] Epoch 68 training loss: 0.035397

[Checkpoint] --- Epoch 69/200 ---
[Checkpoint] Epoch 69 training loss: 0.035203

[Checkpoint] --- Epoch 70/200 ---
[Checkpoint] Epoch 70 training loss: 0.035008
[Checkpoint] Validation metrics - AUC: 0.551968, AUPRC: 0.020036, Loss: 0.036433
[Checkpoint] Validation lifts - @0.5%: 1.627114, @1%: 1.485987, @5%: 1.229415, @10%: 1.233557

[Checkpoint] --- Epoch 71/200 ---
[Checkpoint] Epoch 71 training loss: 0.034813

[Checkpoint] --- Epoch 72/200 ---
[Checkpoint] Epoch 72 training loss: 0.034621

[Checkpoint] --- Epoch 73/200 ---
[Checkpoint] Epoch 73 training loss: 0.034427

[Checkpoint] --- Epoch 74/200 ---
[Checkpoint] Epoch 74 training loss: 0.034225

[Checkpoint] --- Epoch 75/200 ---
[Checkpoint] Epoch 75 training loss: 0.034026
[Checkpoint] Validation metrics - AUC: 0.552498, AUPRC: 0.020281, Loss: 0.035659
[Checkpoint] Validation lifts - @0.5%: 1.685225, @1%: 1.573154, @5%: 1.299976, @10%: 1.269252

[Checkpoint] --- Epoch 76/200 ---
[Checkpoint] Epoch 76 training loss: 0.033826

[Checkpoint] --- Epoch 77/200 ---
[Checkpoint] Epoch 77 training loss: 0.033622

[Checkpoint] --- Epoch 78/200 ---
[Checkpoint] Epoch 78 training loss: 0.033420

[Checkpoint] --- Epoch 79/200 ---
[Checkpoint] Epoch 79 training loss: 0.033214

[Checkpoint] --- Epoch 80/200 ---
[Checkpoint] Epoch 80 training loss: 0.033010
[Checkpoint] Validation metrics - AUC: 0.549725, AUPRC: 0.020465, Loss: 0.034830
[Checkpoint] Validation lifts - @0.5%: 1.527495, @1%: 1.436177, @5%: 1.369706, @10%: 1.333171

[Checkpoint] --- Epoch 81/200 ---
[Checkpoint] Epoch 81 training loss: 0.032809

[Checkpoint] --- Epoch 82/200 ---
[Checkpoint] Epoch 82 training loss: 0.032597

[Checkpoint] --- Epoch 83/200 ---
[Checkpoint] Epoch 83 training loss: 0.032390

[Checkpoint] --- Epoch 84/200 ---
[Checkpoint] Epoch 84 training loss: 0.032181

[Checkpoint] --- Epoch 85/200 ---
[Checkpoint] Epoch 85 training loss: 0.031974
[Checkpoint] Validation metrics - AUC: 0.467364, AUPRC: 0.016881, Loss: 0.033932
[Checkpoint] Validation lifts - @0.5%: 1.494288, @1%: 1.336558, @5%: 1.119008, @10%: 1.215294

[Checkpoint] --- Epoch 86/200 ---
[Checkpoint] Epoch 86 training loss: 0.031758

[Checkpoint] --- Epoch 87/200 ---
[Checkpoint] Epoch 87 training loss: 0.031549

[Checkpoint] --- Epoch 88/200 ---
[Checkpoint] Epoch 88 training loss: 0.031341

[Checkpoint] --- Epoch 89/200 ---
[Checkpoint] Epoch 89 training loss: 0.031122

[Checkpoint] --- Epoch 90/200 ---
[Checkpoint] Epoch 90 training loss: 0.030911
[Checkpoint] Validation metrics - AUC: 0.438393, AUPRC: 0.014671, Loss: 0.033060
[Checkpoint] Validation lifts - @0.5%: 1.427876, @1%: 0.904875, @5%: 0.678212, @10%: 0.730505

[Checkpoint] --- Epoch 91/200 ---
[Checkpoint] Epoch 91 training loss: 0.030696

[Checkpoint] --- Epoch 92/200 ---
[Checkpoint] Epoch 92 training loss: 0.030478

[Checkpoint] --- Epoch 93/200 ---
[Checkpoint] Epoch 93 training loss: 0.030267

[Checkpoint] --- Epoch 94/200 ---
[Checkpoint] Epoch 94 training loss: 0.030050

[Checkpoint] --- Epoch 95/200 ---
[Checkpoint] Epoch 95 training loss: 0.029829
[Checkpoint] Validation metrics - AUC: 0.436629, AUPRC: 0.014407, Loss: 0.032209
[Checkpoint] Validation lifts - @0.5%: 0.913176, @1%: 0.697335, @5%: 0.613462, @10%: 0.601421

[Checkpoint] --- Epoch 96/200 ---
[Checkpoint] Epoch 96 training loss: 0.029613

[Checkpoint] --- Epoch 97/200 ---
[Checkpoint] Epoch 97 training loss: 0.029401

[Checkpoint] --- Epoch 98/200 ---
[Checkpoint] Epoch 98 training loss: 0.029184

[Checkpoint] --- Epoch 99/200 ---
[Checkpoint] Epoch 99 training loss: 0.028966

[Checkpoint] --- Epoch 100/200 ---
[Checkpoint] Epoch 100 training loss: 0.028749
[Checkpoint] Validation metrics - AUC: 0.436741, AUPRC: 0.014583, Loss: 0.031304
[Checkpoint] Validation lifts - @0.5%: 1.153923, @1%: 0.722239, @5%: 0.603501, @10%: 0.587724

[Checkpoint] --- Epoch 101/200 ---
[Checkpoint] Epoch 101 training loss: 0.028531

[Checkpoint] --- Epoch 102/200 ---
[Checkpoint] Epoch 102 training loss: 0.028313

[Checkpoint] --- Epoch 103/200 ---
[Checkpoint] Epoch 103 training loss: 0.028097

[Checkpoint] --- Epoch 104/200 ---
[Checkpoint] Epoch 104 training loss: 0.027882

[Checkpoint] --- Epoch 105/200 ---
[Checkpoint] Epoch 105 training loss: 0.027664
[Checkpoint] Validation metrics - AUC: 0.436194, AUPRC: 0.014406, Loss: 0.030142
[Checkpoint] Validation lifts - @0.5%: 0.954684, @1%: 0.705636, @5%: 0.613462, @10%: 0.588554

[Checkpoint] --- Epoch 106/200 ---
[Checkpoint] Epoch 106 training loss: 0.027448

[Checkpoint] --- Epoch 107/200 ---
[Checkpoint] Epoch 107 training loss: 0.027227

[Checkpoint] --- Epoch 108/200 ---
[Checkpoint] Epoch 108 training loss: 0.027011

[Checkpoint] --- Epoch 109/200 ---
[Checkpoint] Epoch 109 training loss: 0.026798

[Checkpoint] --- Epoch 110/200 ---
[Checkpoint] Epoch 110 training loss: 0.026584
[Checkpoint] Validation metrics - AUC: 0.435848, AUPRC: 0.014253, Loss: 0.028902
[Checkpoint] Validation lifts - @0.5%: 0.796954, @1%: 0.593565, @5%: 0.558674, @10%: 0.563236

[Checkpoint] --- Epoch 111/200 ---
[Checkpoint] Epoch 111 training loss: 0.026367

[Checkpoint] --- Epoch 112/200 ---
[Checkpoint] Epoch 112 training loss: 0.026154

[Checkpoint] --- Epoch 113/200 ---
[Checkpoint] Epoch 113 training loss: 0.025940

[Checkpoint] --- Epoch 114/200 ---
[Checkpoint] Epoch 114 training loss: 0.025733

[Checkpoint] --- Epoch 115/200 ---
[Checkpoint] Epoch 115 training loss: 0.025517
[Checkpoint] Validation metrics - AUC: 0.435427, AUPRC: 0.014119, Loss: 0.027611
[Checkpoint] Validation lifts - @0.5%: 0.614319, @1%: 0.556207, @5%: 0.601010, @10%: 0.585649

[Checkpoint] --- Epoch 116/200 ---
[Checkpoint] Epoch 116 training loss: 0.025305

[Checkpoint] --- Epoch 117/200 ---
[Checkpoint] Epoch 117 training loss: 0.025091

[Checkpoint] --- Epoch 118/200 ---
[Checkpoint] Epoch 118 training loss: 0.024883

[Checkpoint] --- Epoch 119/200 ---
[Checkpoint] Epoch 119 training loss: 0.024675

[Checkpoint] --- Epoch 120/200 ---
[Checkpoint] Epoch 120 training loss: 0.024467
[Checkpoint] Validation metrics - AUC: 0.435428, AUPRC: 0.013873, Loss: 0.026516
[Checkpoint] Validation lifts - @0.5%: 0.481493, @1%: 0.539604, @5%: 0.589389, @10%: 0.578593

[Checkpoint] --- Epoch 121/200 ---
[Checkpoint] Epoch 121 training loss: 0.024256

[Checkpoint] --- Epoch 122/200 ---
[Checkpoint] Epoch 122 training loss: 0.024053

[Checkpoint] --- Epoch 123/200 ---
[Checkpoint] Epoch 123 training loss: 0.023850

[Checkpoint] --- Epoch 124/200 ---
[Checkpoint] Epoch 124 training loss: 0.023646

[Checkpoint] --- Epoch 125/200 ---
[Checkpoint] Epoch 125 training loss: 0.023442
[Checkpoint] Validation metrics - AUC: 0.435269, AUPRC: 0.013990, Loss: 0.025578
[Checkpoint] Validation lifts - @0.5%: 0.581112, @1%: 0.614319, @5%: 0.587728, @10%: 0.582328

[Checkpoint] --- Epoch 126/200 ---
[Checkpoint] Epoch 126 training loss: 0.023240

[Checkpoint] --- Epoch 127/200 ---
[Checkpoint] Epoch 127 training loss: 0.023037

[Checkpoint] --- Epoch 128/200 ---
[Checkpoint] Epoch 128 training loss: 0.022839

[Checkpoint] --- Epoch 129/200 ---
[Checkpoint] Epoch 129 training loss: 0.022640

[Checkpoint] --- Epoch 130/200 ---
[Checkpoint] Epoch 130 training loss: 0.022439
[Checkpoint] Validation metrics - AUC: 0.435783, AUPRC: 0.014027, Loss: 0.024444
[Checkpoint] Validation lifts - @0.5%: 0.539604, @1%: 0.506398, @5%: 0.581087, @10%: 0.575688

[Checkpoint] --- Epoch 131/200 ---
[Checkpoint] Epoch 131 training loss: 0.022241

[Checkpoint] --- Epoch 132/200 ---
[Checkpoint] Epoch 132 training loss: 0.022046

[Checkpoint] --- Epoch 133/200 ---
[Checkpoint] Epoch 133 training loss: 0.021850

[Checkpoint] --- Epoch 134/200 ---
[Checkpoint] Epoch 134 training loss: 0.021653

[Checkpoint] --- Epoch 135/200 ---
[Checkpoint] Epoch 135 training loss: 0.021465
[Checkpoint] Validation metrics - AUC: 0.435002, AUPRC: 0.014160, Loss: 0.023265
[Checkpoint] Validation lifts - @0.5%: 0.348667, @1%: 0.489795, @5%: 0.663270, @10%: 0.631721

[Checkpoint] --- Epoch 136/200 ---
[Checkpoint] Epoch 136 training loss: 0.021270

[Checkpoint] --- Epoch 137/200 ---
[Checkpoint] Epoch 137 training loss: 0.021083

[Checkpoint] --- Epoch 138/200 ---
[Checkpoint] Epoch 138 training loss: 0.020890

[Checkpoint] --- Epoch 139/200 ---
[Checkpoint] Epoch 139 training loss: 0.020702

[Checkpoint] --- Epoch 140/200 ---
[Checkpoint] Epoch 140 training loss: 0.020517
[Checkpoint] Validation metrics - AUC: 0.434819, AUPRC: 0.013871, Loss: 0.022077
[Checkpoint] Validation lifts - @0.5%: 0.348667, @1%: 0.481493, @5%: 0.571126, @10%: 0.562406

[Checkpoint] --- Epoch 141/200 ---
[Checkpoint] Epoch 141 training loss: 0.020334

[Checkpoint] --- Epoch 142/200 ---
[Checkpoint] Epoch 142 training loss: 0.020146

[Checkpoint] --- Epoch 143/200 ---
[Checkpoint] Epoch 143 training loss: 0.019964

[Checkpoint] --- Epoch 144/200 ---
[Checkpoint] Epoch 144 training loss: 0.019785

[Checkpoint] --- Epoch 145/200 ---
[Checkpoint] Epoch 145 training loss: 0.019606
[Checkpoint] Validation metrics - AUC: 0.434383, AUPRC: 0.014107, Loss: 0.021334
[Checkpoint] Validation lifts - @0.5%: 0.249048, @1%: 0.460739, @5%: 0.652478, @10%: 0.629645

[Checkpoint] --- Epoch 146/200 ---
[Checkpoint] Epoch 146 training loss: 0.019428

[Checkpoint] --- Epoch 147/200 ---
[Checkpoint] Epoch 147 training loss: 0.019254

[Checkpoint] --- Epoch 148/200 ---
[Checkpoint] Epoch 148 training loss: 0.019080

[Checkpoint] --- Epoch 149/200 ---
[Checkpoint] Epoch 149 training loss: 0.018908

[Checkpoint] --- Epoch 150/200 ---
[Checkpoint] Epoch 150 training loss: 0.018737
[Checkpoint] Validation metrics - AUC: 0.434164, AUPRC: 0.013821, Loss: 0.020366
[Checkpoint] Validation lifts - @0.5%: 0.265651, @1%: 0.493945, @5%: 0.560334, @10%: 0.579838

[Checkpoint] --- Epoch 151/200 ---
[Checkpoint] Epoch 151 training loss: 0.018568

[Checkpoint] --- Epoch 152/200 ---
[Checkpoint] Epoch 152 training loss: 0.018406

[Checkpoint] --- Epoch 153/200 ---
[Checkpoint] Epoch 153 training loss: 0.018239

[Checkpoint] --- Epoch 154/200 ---
[Checkpoint] Epoch 154 training loss: 0.018082

[Checkpoint] --- Epoch 155/200 ---
[Checkpoint] Epoch 155 training loss: 0.017916
[Checkpoint] Validation metrics - AUC: 0.433238, AUPRC: 0.014075, Loss: 0.019760
[Checkpoint] Validation lifts - @0.5%: 0.174334, @1%: 0.365270, @5%: 0.606821, @10%: 0.608062
[Checkpoint] Early stopping at epoch 155 (no AUPRC improvement for 15 evaluations)
[Checkpoint] Configuration completed. Best AUPRC: 0.020465

[Checkpoint] ====== Configuration 69/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.5, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 70/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.5, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 71/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.75, gamma=1.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Configuration 72/72 ======
[Checkpoint] Training with lr=0.0001, hidden=256, layers=3, alpha=0.75, gamma=2.0
[Checkpoint] Initializing EnhancedGCN with 5 input features, 32 embedding dim, 256 hidden channels, 3 layers
[Checkpoint] Total parameters: 45330948
[Checkpoint] Starting training for up to 200 epochs

[Checkpoint] --- Epoch 1/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=1

[Checkpoint] --- Epoch 2/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=2

[Checkpoint] --- Epoch 3/200 ---
[Checkpoint] WARNING: Non-finite loss detected, skipping backward pass
[Checkpoint] NaN loss detected, nan_epochs=3
[Checkpoint] Too many NaN epochs, skipping configuration
[Checkpoint] Configuration completed. Best AUPRC: 0.000000

[Checkpoint] ====== Final Evaluation ======
[Checkpoint] Evaluating best model
[Checkpoint] Best config (lr=0.001, hidden=128, layers=3, alpha=0.5, gamma=1.0):
[Checkpoint] Test AUPRC=0.031073
[Checkpoint] Test AUC=0.363503
[Checkpoint] Test EMP=0.000000
[Checkpoint] Test MP=0.000000
[Checkpoint] Test Lift@0.5%=0.096729
[Checkpoint] Test Lift@1%=0.133809
[Checkpoint] Test Lift@5%=0.203123
[Checkpoint] Test Lift@10%=0.199575

[Checkpoint] Saving best model predictions for analysis
[Checkpoint] Predictions saved as best_model_predictions_20250428_233019.csv
[Checkpoint] ====== Script Finished ======
