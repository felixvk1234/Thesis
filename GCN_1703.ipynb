{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\guest\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch_geometric.transforms as T\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "import numpy as np\n",
    "import itertools\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from EMP.metrics import empCreditScoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\guest\\Desktop\\OneDrive_2025-01-04\\Van Kerschaver & Xu - Benchmarking graph neural networks for churn prediction - shared folder\\Data\\Transformed data (csv format)\\Mobile Vikings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of churners in month 1:  14055\n"
     ]
    }
   ],
   "source": [
    "# Load all nodes that churn in month 1\n",
    "churners_m1 = pd.read_csv(\"L_M1.csv\")\n",
    "churners_list_m1 = churners_m1[churners_m1['churn_m1'] == 1]['USR'].tolist()\n",
    "print(\"Number of churners in month 1: \", len(churners_list_m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def remove_nodes(data, nodes_to_remove):\n",
    "    \"\"\"\n",
    "    Remove specified nodes from a PyTorch Geometric Data object and update all related attributes.\n",
    "    \n",
    "    Args:\n",
    "        data: PyTorch Geometric Data object\n",
    "        nodes_to_remove: List or tensor of node indices to remove\n",
    "    \n",
    "    Returns:\n",
    "        Updated Data object with nodes removed\n",
    "    \"\"\"\n",
    "    # Convert nodes_to_remove to a set for faster lookup\n",
    "    if not isinstance(nodes_to_remove, set):\n",
    "        nodes_to_remove = set(nodes_to_remove.tolist() if torch.is_tensor(nodes_to_remove) else nodes_to_remove)\n",
    "    \n",
    "    # Create a mask for nodes to keep\n",
    "    keep_nodes = torch.ones(data.num_nodes, dtype=torch.bool)\n",
    "    keep_nodes[list(nodes_to_remove)] = False\n",
    "    \n",
    "    # Create a mapping from old to new indices\n",
    "    new_indices = torch.cumsum(keep_nodes, dim=0) - 1\n",
    "    \n",
    "    # Filter edges: keep only edges where both source and target nodes are kept\n",
    "    edge_mask = torch.ones(data.edge_index.size(1), dtype=torch.bool)\n",
    "    for i in range(data.edge_index.size(1)):\n",
    "        src, dst = data.edge_index[:, i]\n",
    "        if src.item() in nodes_to_remove or dst.item() in nodes_to_remove:\n",
    "            edge_mask[i] = False\n",
    "    \n",
    "    # Create new data object with filtered nodes and edges\n",
    "    new_data = Data()\n",
    "    \n",
    "    # Update node features\n",
    "    if hasattr(data, 'x') and data.x is not None:\n",
    "        new_data.x = data.x[keep_nodes]\n",
    "    \n",
    "    # Update node labels\n",
    "    if hasattr(data, 'y') and data.y is not None:\n",
    "        new_data.y = data.y[keep_nodes]\n",
    "    \n",
    "    # Update edge indices and attributes\n",
    "    if hasattr(data, 'edge_index') and data.edge_index is not None:\n",
    "        # Filter edges\n",
    "        new_data.edge_index = data.edge_index[:, edge_mask]\n",
    "        # Update indices\n",
    "        for i in range(new_data.edge_index.size(1)):\n",
    "            new_data.edge_index[0, i] = new_indices[new_data.edge_index[0, i]]\n",
    "            new_data.edge_index[1, i] = new_indices[new_data.edge_index[1, i]]\n",
    "    \n",
    "    # Update edge attributes\n",
    "    if hasattr(data, 'edge_attr') and data.edge_attr is not None:\n",
    "        new_data.edge_attr = data.edge_attr[edge_mask]\n",
    "    \n",
    "    # Preserve other attributes\n",
    "    new_data.num_classes = data.num_classes\n",
    "    new_data.num_features = data.num_features\n",
    "    \n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USR</th>\n",
       "      <th>R_on</th>\n",
       "      <th>M_30_on</th>\n",
       "      <th>M_60_on</th>\n",
       "      <th>M_90_on</th>\n",
       "      <th>F_30_on</th>\n",
       "      <th>F_60_on</th>\n",
       "      <th>F_90_on</th>\n",
       "      <th>numDialing_30_on</th>\n",
       "      <th>numDialed_30_on</th>\n",
       "      <th>numDialing_60_on</th>\n",
       "      <th>numDialed_60_on</th>\n",
       "      <th>numDialing_90_on</th>\n",
       "      <th>numDialed_90_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1389.019590</td>\n",
       "      <td>3101.536954</td>\n",
       "      <td>6720.267202</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2847.647333</td>\n",
       "      <td>5487.314113</td>\n",
       "      <td>6696.261817</td>\n",
       "      <td>228</td>\n",
       "      <td>449</td>\n",
       "      <td>578</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>706.386715</td>\n",
       "      <td>2611.513490</td>\n",
       "      <td>4056.546870</td>\n",
       "      <td>29</td>\n",
       "      <td>118</td>\n",
       "      <td>218</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>15</td>\n",
       "      <td>837.415605</td>\n",
       "      <td>1107.172814</td>\n",
       "      <td>1153.624858</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1059.638912</td>\n",
       "      <td>1395.772800</td>\n",
       "      <td>3136.134856</td>\n",
       "      <td>78</td>\n",
       "      <td>116</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168347</th>\n",
       "      <td>168351.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168348</th>\n",
       "      <td>168353.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168349</th>\n",
       "      <td>168354.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168350</th>\n",
       "      <td>168355.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168351</th>\n",
       "      <td>168359.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168351 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             USR  R_on      M_30_on      M_60_on      M_90_on  F_30_on  \\\n",
       "1            1.0     0  1389.019590  3101.536954  6720.267202       54   \n",
       "2            2.0     0  2847.647333  5487.314113  6696.261817      228   \n",
       "3            3.0    11   706.386715  2611.513490  4056.546870       29   \n",
       "4            4.0    15   837.415605  1107.172814  1153.624858       55   \n",
       "5            5.0     0  1059.638912  1395.772800  3136.134856       78   \n",
       "...          ...   ...          ...          ...          ...      ...   \n",
       "168347  168351.0  1000     0.000000     0.000000     0.000000        0   \n",
       "168348  168353.0  1000     0.000000     0.000000     0.000000        0   \n",
       "168349  168354.0  1000     0.000000     0.000000     0.000000        0   \n",
       "168350  168355.0  1000     0.000000     0.000000     0.000000        0   \n",
       "168351  168359.0  1000     0.000000     0.000000     0.000000        0   \n",
       "\n",
       "        F_60_on  F_90_on  numDialing_30_on  numDialed_30_on  numDialing_60_on  \\\n",
       "1            94      214                 3                4                 6   \n",
       "2           449      578                 5                5                 6   \n",
       "3           118      218                 5                6                 5   \n",
       "4            74       78                 5                5                 5   \n",
       "5           116      259                 5                5                 5   \n",
       "...         ...      ...               ...              ...               ...   \n",
       "168347        0        0                 0                0                 0   \n",
       "168348        0        0                 0                0                 0   \n",
       "168349        0        0                 0                0                 0   \n",
       "168350        0        0                 0                0                 0   \n",
       "168351        0        0                 0                0                 0   \n",
       "\n",
       "        numDialed_60_on  numDialing_90_on  numDialed_90_on  \n",
       "1                     6                10                8  \n",
       "2                     5                 6                5  \n",
       "3                     6                 5                6  \n",
       "4                     6                 5                6  \n",
       "5                     5                 6                6  \n",
       "...                 ...               ...              ...  \n",
       "168347                0                 0                0  \n",
       "168348                0                 0                0  \n",
       "168349                0                 0                0  \n",
       "168350                0                 0                0  \n",
       "168351                0                 0                0  \n",
       "\n",
       "[168351 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_attr= pd.read_csv(\"train_rmf.csv\", sep=\",\",  header=0 )\n",
    "node_attr.index += 1 #to make sure the nodes start counting at 1\n",
    "display(node_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_on</th>\n",
       "      <th>M_30_on</th>\n",
       "      <th>M_60_on</th>\n",
       "      <th>M_90_on</th>\n",
       "      <th>F_30_on</th>\n",
       "      <th>F_60_on</th>\n",
       "      <th>F_90_on</th>\n",
       "      <th>numDialing_30_on</th>\n",
       "      <th>numDialed_30_on</th>\n",
       "      <th>numDialing_60_on</th>\n",
       "      <th>numDialed_60_on</th>\n",
       "      <th>numDialing_90_on</th>\n",
       "      <th>numDialed_90_on</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1389.019590</td>\n",
       "      <td>3101.536954</td>\n",
       "      <td>6720.267202</td>\n",
       "      <td>54</td>\n",
       "      <td>94</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2847.647333</td>\n",
       "      <td>5487.314113</td>\n",
       "      <td>6696.261817</td>\n",
       "      <td>228</td>\n",
       "      <td>449</td>\n",
       "      <td>578</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>706.386715</td>\n",
       "      <td>2611.513490</td>\n",
       "      <td>4056.546870</td>\n",
       "      <td>29</td>\n",
       "      <td>118</td>\n",
       "      <td>218</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>837.415605</td>\n",
       "      <td>1107.172814</td>\n",
       "      <td>1153.624858</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1059.638912</td>\n",
       "      <td>1395.772800</td>\n",
       "      <td>3136.134856</td>\n",
       "      <td>78</td>\n",
       "      <td>116</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168347</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168348</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168349</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168350</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168351</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168351 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        R_on      M_30_on      M_60_on      M_90_on  F_30_on  F_60_on  \\\n",
       "1          0  1389.019590  3101.536954  6720.267202       54       94   \n",
       "2          0  2847.647333  5487.314113  6696.261817      228      449   \n",
       "3         11   706.386715  2611.513490  4056.546870       29      118   \n",
       "4         15   837.415605  1107.172814  1153.624858       55       74   \n",
       "5          0  1059.638912  1395.772800  3136.134856       78      116   \n",
       "...      ...          ...          ...          ...      ...      ...   \n",
       "168347  1000     0.000000     0.000000     0.000000        0        0   \n",
       "168348  1000     0.000000     0.000000     0.000000        0        0   \n",
       "168349  1000     0.000000     0.000000     0.000000        0        0   \n",
       "168350  1000     0.000000     0.000000     0.000000        0        0   \n",
       "168351  1000     0.000000     0.000000     0.000000        0        0   \n",
       "\n",
       "        F_90_on  numDialing_30_on  numDialed_30_on  numDialing_60_on  \\\n",
       "1           214                 3                4                 6   \n",
       "2           578                 5                5                 6   \n",
       "3           218                 5                6                 5   \n",
       "4            78                 5                5                 5   \n",
       "5           259                 5                5                 5   \n",
       "...         ...               ...              ...               ...   \n",
       "168347        0                 0                0                 0   \n",
       "168348        0                 0                0                 0   \n",
       "168349        0                 0                0                 0   \n",
       "168350        0                 0                0                 0   \n",
       "168351        0                 0                0                 0   \n",
       "\n",
       "        numDialed_60_on  numDialing_90_on  numDialed_90_on  \n",
       "1                     6                10                8  \n",
       "2                     5                 6                5  \n",
       "3                     6                 5                6  \n",
       "4                     6                 5                6  \n",
       "5                     5                 6                6  \n",
       "...                 ...               ...              ...  \n",
       "168347                0                 0                0  \n",
       "168348                0                 0                0  \n",
       "168349                0                 0                0  \n",
       "168350                0                 0                0  \n",
       "168351                0                 0                0  \n",
       "\n",
       "[168351 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.41872848,  0.0314685 , -0.05325674,  0.14897139,  0.52507858],\n",
       "       [-0.41872848,  0.38266333,  1.18667903,  0.85624259,  0.89452061],\n",
       "       [-0.38580757, -0.13288949, -0.23140843,  0.85624259,  1.26396265],\n",
       "       ...,\n",
       "       [ 2.57408188, -0.30296672, -0.4380644 , -0.91193541, -0.95268956],\n",
       "       [ 2.57408188, -0.30296672, -0.4380644 , -0.91193541, -0.95268956],\n",
       "       [ 2.57408188, -0.30296672, -0.4380644 , -0.91193541, -0.95268956]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#don't need first column since this is USR \n",
    "node_attr= node_attr.iloc[:, 1:]\n",
    "display(node_attr)\n",
    "# List of columns you want to drop\n",
    "columns_to_drop = ['M_60_on', 'M_90_on','F_60_on','F_90_on','numDialing_60_on','numDialed_60_on','numDialing_90_on','numDialed_90_on']\n",
    "# Drop the specified columns\n",
    "node_attr = node_attr.drop(columns=columns_to_drop)\n",
    "# normalizing the attributes\n",
    "scale = StandardScaler()\n",
    "attrs_norm = scale.fit_transform(node_attr)\n",
    "#to have more numbers after the comma\n",
    "torch.set_printoptions(precision=10)\n",
    "display(attrs_norm)\n",
    "attrs_train = torch.tensor(attrs_norm, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5491</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29407</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30662</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47527</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51309</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497731</th>\n",
       "      <td>79862</td>\n",
       "      <td>167208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497732</th>\n",
       "      <td>145555</td>\n",
       "      <td>167243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497733</th>\n",
       "      <td>39480</td>\n",
       "      <td>167268</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497734</th>\n",
       "      <td>92195</td>\n",
       "      <td>167681</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497735</th>\n",
       "      <td>140824</td>\n",
       "      <td>167807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497736 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             i       j   x\n",
       "0         5491       1   1\n",
       "1        29407       1  47\n",
       "2        30662       1   1\n",
       "3        47527       1   2\n",
       "4        51309       1  61\n",
       "...        ...     ...  ..\n",
       "497731   79862  167208   1\n",
       "497732  145555  167243   1\n",
       "497733   39480  167268   2\n",
       "497734   92195  167681   3\n",
       "497735  140824  167807   1\n",
       "\n",
       "[497736 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  5491,  29407,  30662,  ..., 167268, 167681, 167807],\n",
       "        [     1,      1,      1,  ...,  39480,  92195, 140824]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995472\n",
      "tensor([ 1., 47.,  1.,  ...,  2.,  3.,  1.], dtype=torch.float64)\n",
      "995472\n"
     ]
    }
   ],
   "source": [
    "#read the adjacency matrix\n",
    "adj_train = pd.read_csv(\"SN_M2_c.csv\", sep=\",\",  header=0)\n",
    "display(adj_train)\n",
    "#make them into tensors\n",
    "edge_idx_train_dir0=torch.tensor([adj_train['i'], adj_train['j']], dtype=torch.long)\n",
    "edge_idx_train_dir1= torch.tensor([adj_train['j'], adj_train['i']], dtype=torch.long)\n",
    "edge_idx_train= torch.cat((edge_idx_train_dir0, edge_idx_train_dir1), dim=1)\n",
    "display(edge_idx_train)\n",
    "print(len(edge_idx_train[0]))\n",
    "#create edge_attr from SN_ data file (don't normalise!!)   \n",
    "#should we create tensor with only the attributes or also the edges?\n",
    "edge_attrs_train_1= torch.tensor(adj_train['x'], dtype=torch.float64) \n",
    "\n",
    "#need it twice since we needed the edges in both directions\n",
    "edge_attrs_train= torch.cat((edge_attrs_train_1,edge_attrs_train_1), dim=-1)\n",
    "print(edge_attrs_train)\n",
    "print(len(edge_attrs_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "labels_pd_train= pd.read_csv(\"L_M3.csv\", sep=\",\",  header=0)\n",
    "# now need to transform them to tensors\n",
    "labels_train = torch.tensor(labels_pd_train['churn_m3'], dtype=torch.long)\n",
    "print(labels_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[168351, 5], edge_index=[2, 995472], edge_attr=[995472], y=[168351], num_classes=2, num_features=5)\n"
     ]
    }
   ],
   "source": [
    "## create a PyTorch Geometric Data object for training a graph neural network\n",
    "class MobileVikings_train:\n",
    "    def __init__(self, attrs_train, edge_idx_train,edge_attrs_train,labels_train):\n",
    "        \n",
    "        self.data_train=Data(x=attrs_train, edge_index=edge_idx_train, edge_attr=edge_attrs_train,y=labels_train )\n",
    "        \n",
    "        self.data_train.num_classes=2\n",
    "        self.data_train.num_features= len(node_attr.columns)\n",
    "    \n",
    "dataset= MobileVikings_train(attrs_train, edge_idx_train,edge_attrs_train,labels_train)\n",
    "\n",
    "# we save this in data_train\n",
    "data_train= dataset.data_train\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[154296, 5], y=[154296], edge_index=[2, 929204], edge_attr=[929204], num_classes=2, num_features=5)\n"
     ]
    }
   ],
   "source": [
    "data_train= remove_nodes(data_train, churners_list_m1)\n",
    "print(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29407</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51309</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68448</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505620</th>\n",
       "      <td>135680</td>\n",
       "      <td>167507</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505621</th>\n",
       "      <td>65340</td>\n",
       "      <td>167616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505622</th>\n",
       "      <td>20350</td>\n",
       "      <td>167652</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505623</th>\n",
       "      <td>73780</td>\n",
       "      <td>167780</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505624</th>\n",
       "      <td>21770</td>\n",
       "      <td>168139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>505625 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             i       j   x\n",
       "0        29407       1  55\n",
       "1        47527       1   1\n",
       "2        51309       1  12\n",
       "3        68448       1  29\n",
       "4       114644       1   1\n",
       "...        ...     ...  ..\n",
       "505620  135680  167507   3\n",
       "505621   65340  167616   1\n",
       "505622   20350  167652   3\n",
       "505623   73780  167780   1\n",
       "505624   21770  168139   1\n",
       "\n",
       "[505625 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 29407,  47527,  51309,  ..., 167652, 167780, 168139],\n",
       "        [     1,      1,      1,  ...,  20350,  73780,  21770]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1011250\n"
     ]
    }
   ],
   "source": [
    "adj_val = pd.read_csv(\"SN_M3_c.csv\", sep=\",\",  header=0)\n",
    "display(adj_val)\n",
    "#make them into tensors\n",
    "edge_idx_val_dir0=torch.tensor([adj_val['i'], adj_val['j']], dtype=torch.long)\n",
    "edge_idx_val_dir1= torch.tensor([adj_val['j'], adj_val['i']], dtype=torch.long)\n",
    "edge_idx_val= torch.cat((edge_idx_val_dir0, edge_idx_val_dir1), dim=1)\n",
    "display(edge_idx_val)\n",
    "print(len(edge_idx_val[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([55.,  1., 12.,  ...,  3.,  1.,  1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "edge_attrs_val_1= torch.tensor(adj_val['x'], dtype=torch.float64) \n",
    "#need it twice since we needed the edges in both directions\n",
    "edge_attrs_val= torch.cat((edge_attrs_val_1,edge_attrs_val_1))\n",
    "print(edge_attrs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "labels_pd_val= pd.read_csv(\"L_M4.csv\", sep=\",\",  header=0)\n",
    "labels_val = torch.tensor(labels_pd_val['churn_m4'], dtype=torch.long)\n",
    "print(labels_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[168351, 5], edge_index=[2, 1011250], edge_attr=[1011250], y=[168351], num_classes=2, num_features=5)\n"
     ]
    }
   ],
   "source": [
    "class MobileVikings_val:\n",
    "    def __init__(self, attrs_train,edge_idx_val,edge_attrs_val,labels_val):\n",
    "        self.data_val=Data(x=attrs_train, edge_index=edge_idx_val, edge_attr=edge_attrs_val,y=labels_val )\n",
    "        self.data_val.num_classes=2\n",
    "        self.data_val.num_features= len(node_attr.columns)\n",
    "dataset=MobileVikings_val(attrs_train,edge_idx_val,edge_attrs_val,labels_val)\n",
    "data_val = dataset.data_val\n",
    "print(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[154296, 5], y=[154296], edge_index=[2, 943718], edge_attr=[943718], num_classes=2, num_features=5)\n"
     ]
    }
   ],
   "source": [
    "data_val= remove_nodes(data_val, churners_list_m1)\n",
    "print(data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3715719879, -0.2578698695, -0.3550667465,  0.1016500667,\n",
       "          0.8493221998],\n",
       "        [-0.3875837326,  0.2734937668,  0.7645937204,  0.4552221894,\n",
       "          0.8493221998],\n",
       "        [-0.3875837326, -0.1037445739,  0.0371710025,  0.4552221894,\n",
       "          0.8493221998],\n",
       "        ...,\n",
       "        [ 2.8147616386, -0.2963555157, -0.4406458735, -0.9590663314,\n",
       "         -1.0071097612],\n",
       "        [ 2.8147616386, -0.2963555157, -0.4406458735, -0.9590663314,\n",
       "         -1.0071097612],\n",
       "        [ 2.8147616386, -0.2963555157, -0.4406458735, -0.9590663314,\n",
       "         -1.0071097612]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_node_attr= pd.read_csv(\"test_rmf.csv\", sep=\",\",  header=0 )\n",
    "test_node_attr.index += 1 #to make sure the nodes start counting at 1\n",
    "\n",
    "#don't need first column since they is USR \n",
    "test_node_attr= test_node_attr.iloc[:, 1:]\n",
    "columns_to_drop = ['M_60_on', 'M_90_on','F_60_on','F_90_on','numDialing_60_on','numDialed_60_on','numDialing_90_on','numDialed_90_on']\n",
    "# Drop the specified columns\n",
    "test_node_attr = test_node_attr.drop(columns=columns_to_drop)\n",
    "\n",
    "# normalizing the attributes\n",
    "scale = StandardScaler()\n",
    "test_attrs_norm = scale.fit_transform(test_node_attr)\n",
    "\n",
    "#to have more numbers after the comma\n",
    "torch.set_printoptions(precision=10)\n",
    "\n",
    "#now need to transform them to tensors\n",
    "attrs_test = torch.tensor(test_attrs_norm, dtype=torch.float) #this can also be done in class\n",
    "display(attrs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>j</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29407</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34359</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47527</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48775</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51309</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476166</th>\n",
       "      <td>94740</td>\n",
       "      <td>167584</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476167</th>\n",
       "      <td>100201</td>\n",
       "      <td>167617</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476168</th>\n",
       "      <td>75692</td>\n",
       "      <td>167767</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476169</th>\n",
       "      <td>102971</td>\n",
       "      <td>168267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476170</th>\n",
       "      <td>60109</td>\n",
       "      <td>168344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476171 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             i       j   x\n",
       "0        29407       1  29\n",
       "1        34359       1   2\n",
       "2        47527       1  10\n",
       "3        48775       1  48\n",
       "4        51309       1  11\n",
       "...        ...     ...  ..\n",
       "476166   94740  167584   8\n",
       "476167  100201  167617   3\n",
       "476168   75692  167767   3\n",
       "476169  102971  168267   1\n",
       "476170   60109  168344   1\n",
       "\n",
       "[476171 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 29407,  34359,  47527,  ..., 167767, 168267, 168344],\n",
      "        [     1,      1,      1,  ...,  75692, 102971,  60109]])\n",
      "952342\n"
     ]
    }
   ],
   "source": [
    "adj_test = pd.read_csv(\"SN_M4_c.csv\", sep=\",\",  header=0)\n",
    "display(adj_test)\n",
    "edge_idx_test_dir0=torch.tensor([adj_test['i'], adj_test['j']], dtype=torch.long)\n",
    "edge_idx_test_dir1= torch.tensor([adj_test['j'], adj_test['i']], dtype=torch.long)\n",
    "edge_idx_test= torch.cat((edge_idx_test_dir0, edge_idx_test_dir1), dim=1)\n",
    "print(edge_idx_test)\n",
    "print(len(edge_idx_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([29.,  2., 10.,  ...,  3.,  1.,  1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "edge_attrs_test_1= torch.tensor(adj_test['x'], dtype=torch.float64) \n",
    "\n",
    "#need it twice since we needed the edges in both directions\n",
    "edge_attrs_test= torch.cat((edge_attrs_test_1,edge_attrs_test_1))\n",
    "print(edge_attrs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "labels_pd_test= pd.read_csv(\"L_test.csv\", sep=\",\",  header=0)\n",
    "\n",
    "#now need to transform them to tensors\n",
    "labels_test = torch.tensor(labels_pd_test['churn_test'], dtype=torch.long)\n",
    "print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[168351, 5], edge_index=[2, 952342], edge_attr=[952342], y=[168351], num_classes=2, num_features=5)\n"
     ]
    }
   ],
   "source": [
    "#creating the dataset\n",
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "class MobileVikings_test:\n",
    "    def __init__(self, attrs_test, edge_idx_test,edge_attrs_test,labels_test):\n",
    "        \n",
    "        self.data_test=Data(x=attrs_test, edge_index=edge_idx_test, edge_attr=edge_attrs_test,y=labels_test )\n",
    "        \n",
    "        self.data_test.num_classes=2\n",
    "        self.data_test.num_features= len(node_attr.columns)\n",
    "    \n",
    "dataset= MobileVikings_test(attrs_test, edge_idx_test,edge_attrs_test,labels_test)\n",
    "data_test= dataset.data_test\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[154296, 5], y=[154296], edge_index=[2, 890852], edge_attr=[890852], num_classes=2, num_features=5)\n"
     ]
    }
   ],
   "source": [
    "data_test= remove_nodes(data_test, churners_list_m1)\n",
    "print(data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, dropout_rate=0.5, out_channels=1):\n",
    "        super(GCN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Input layer\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        # Output layer\n",
    "        self.lin = nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "        # Graph convolution layers with ELU activation and dropout\n",
    "            for i in range(self.num_layers):\n",
    "                x = self.convs[i](x, edge_index)\n",
    "                x = F.elu(x)  # Using ELU activation as requested\n",
    "                x = F.dropout(x, p=self.dropout_rate, training=self.training)\n",
    "            \n",
    "            # Final linear layer\n",
    "            x = self.lin(x)\n",
    "            return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.9431902660], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#calculating the weights for the loss function\n",
    "total_weight_class_0 = 0\n",
    "total_weight_class_1 = 0\n",
    "\n",
    "# Iterate over the first 4 months (since test data looks different)\n",
    "for month in range(1, 5):\n",
    "    labels_pd = pd.read_csv(f\"L_M{month}.csv\", sep=\",\", header=0)\n",
    "    \n",
    "    #weight_for_class_0 = labels_pd.shape[0] / ((labels_pd[f'churn_m{month}'] == 0).sum() * 2)\n",
    "    weight_for_class_1 = labels_pd.shape[0] / ((labels_pd[f'churn_m{month}'] == 1).sum() * 2)\n",
    "    \n",
    "    # Add the weights to the total\n",
    "    #total_weight_class_0 += weight_for_class_0\n",
    "    total_weight_class_1 += weight_for_class_1\n",
    "\n",
    "#only test month needs to be done seperately\n",
    "labels_pd_m5 = pd.read_csv(f\"L_test.csv\", sep=\",\", header=0)\n",
    "    \n",
    "#weight_for_class_0_m5 = labels_pd.shape[0] / ((labels_pd_m5['churn_test'] == 0).sum() * 2)\n",
    "weight_for_class_1_m5 = labels_pd.shape[0] / ((labels_pd_m5['churn_test'] == 1).sum() * 2)\n",
    "\n",
    "#total_weight_class_0 +=  weight_for_class_0_m5\n",
    "total_weight_class_1 += weight_for_class_1_m5\n",
    "\n",
    "#avg_weight_for_class_0 = total_weight_class_0 / 5\n",
    "avg_weight_for_class_1 = total_weight_class_1 / 5\n",
    "\n",
    "\n",
    "# Create the weight tensor\n",
    "weight = torch.tensor([  avg_weight_for_class_1])\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, optimizer, criterion):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = criterion(out.squeeze(), data.y.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emp_score(y_true,y_prob):\n",
    "        output = empCreditScoring(y_prob, y_true, return_output=True,print_output=False)\n",
    "        emp_credit_score = float(output.EMPC)\n",
    "        return emp_credit_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lift(y_true, y_prob, percentage):\n",
    "    \"\"\"\n",
    "    Calculate the lift at a specific percentage\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: True labels\n",
    "    - y_prob: Predicted probabilities\n",
    "    - percentage: Percentage of population (0.005 for 0.5%, 0.05 for 5%)\n",
    "    \"\"\"\n",
    "    # Convert to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "    \n",
    "    # Sort indices by predicted probability (descending)\n",
    "    sorted_indices = np.argsort(y_prob)[::-1]\n",
    "    \n",
    "    # Calculate number of samples to consider\n",
    "    n_samples = len(y_true)\n",
    "    n_top = max(1, int(n_samples * percentage))\n",
    "    \n",
    "    # Get top n_top samples\n",
    "    top_indices = sorted_indices[:n_top]\n",
    "    \n",
    "    # Calculate lift\n",
    "    top_positive_rate = np.mean(y_true[top_indices])\n",
    "    overall_positive_rate = np.mean(y_true)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    if overall_positive_rate == 0:\n",
    "        return 0\n",
    "    \n",
    "    lift = top_positive_rate / overall_positive_rate\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out.squeeze(), data.y.float())\n",
    "        \n",
    "        # Get probabilities\n",
    "        probs = torch.sigmoid(out).squeeze().cpu().numpy()\n",
    "        y_true = data.y.cpu().numpy()\n",
    "        # AUC\n",
    "        auc = roc_auc_score(y_true, probs)\n",
    "        \n",
    "        # EMP using EMP-PY library\n",
    "        emp_score = 0\n",
    "\n",
    "        # Lift metrics\n",
    "        lift_005 = calculate_lift(y_true, probs, 0.005)  # 0.5% lift\n",
    "        lift_05 = calculate_lift(y_true, probs, 0.05)    # 5% lift\n",
    "        \n",
    "\n",
    "        # Binary predictions at threshold 0.5 for basic accuracy\n",
    "        pred_05 = (probs >= 0.5).astype(int)\n",
    "        accuracy = np.mean(pred_05 == y_true)\n",
    "        \n",
    "    return {\n",
    "        'loss': loss.item(),\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc,\n",
    "        'emp': emp_score,\n",
    "        'lift_005': lift_005,\n",
    "        'lift_05': lift_05\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(data_train, data_val, data_test, learning_rates, hidden_channels, layers, device, weight):\n",
    "    results_df = []\n",
    "    best_val_auc = 0\n",
    "    best_val_emp = 0\n",
    "    best_hyperparams = {}\n",
    "    best_model = None\n",
    "    \n",
    "    print(f\"Class imbalance weight: {weight.item()}\")\n",
    "    \n",
    "    # Create timestamp for unique CSV filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    csv_filename = f\"gcn_results_{timestamp}.csv\"\n",
    "    \n",
    "    # Set up CSV file with headers\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['lr', 'hidden_channels', 'layers', 'epoch', \n",
    "                     'train_loss', 'train_accuracy', 'train_auc', 'train_emp', 'train_lift_005', 'train_lift_05',\n",
    "                     'val_loss', 'val_accuracy', 'val_auc', 'val_emp', 'val_lift_005', 'val_lift_05']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for hidden in hidden_channels:\n",
    "            for num_layers in layers:\n",
    "                print(f\"\\nTraining with lr={lr}, hidden_channels={hidden}, layers={num_layers}\")\n",
    "                \n",
    "                # Initialize model\n",
    "                model = GCN(data_train.num_features, hidden, num_layers).to(device)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "                criterion = nn.BCEWithLogitsLoss(pos_weight=weight.to(device))\n",
    "                \n",
    "                # Track validation performance\n",
    "                best_epoch = 0\n",
    "                best_val_loss = float('inf')\n",
    "                best_val_auc_for_config = 0\n",
    "                best_val_emp_for_config = 0\n",
    "                patience = 15\n",
    "                epochs_no_improve = 0\n",
    "                \n",
    "                # Train for a maximum of 200 epochs\n",
    "                for epoch in range(1, 201):\n",
    "                    loss = train(model, data_train.to(device), optimizer, criterion)\n",
    "                    \n",
    "                    if epoch % 5 == 0 or epoch == 1:\n",
    "                        # Evaluate on training and validation sets\n",
    "                        train_metrics = evaluate(model, data_train.to(device), criterion)\n",
    "                        val_metrics = evaluate(model, data_val.to(device), criterion)\n",
    "                        \n",
    "                        # Print metrics\n",
    "                        print(f'Epoch: {epoch:03d}, Train Loss: {train_metrics[\"loss\"]:.4f}, '\n",
    "                              f'Val Loss: {val_metrics[\"loss\"]:.4f}, Val AUC: {val_metrics[\"auc\"]:.4f}, '\n",
    "                              f'Val EMP: {val_metrics[\"emp\"]:.4f}, Val 0.5% Lift: {val_metrics[\"lift_005\"]:.4f}')\n",
    "                        \n",
    "                        # Save to CSV\n",
    "                        with open(csv_filename, 'a', newline='') as csvfile:\n",
    "                            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "                            writer.writerow({\n",
    "                                'lr': lr,\n",
    "                                'hidden_channels': hidden,\n",
    "                                'layers': num_layers,\n",
    "                                'epoch': epoch,\n",
    "                                'train_loss': train_metrics[\"loss\"],\n",
    "                                'train_accuracy': train_metrics[\"accuracy\"],\n",
    "                                'train_auc': train_metrics[\"auc\"],\n",
    "                                'train_emp': train_metrics[\"emp\"],\n",
    "                                'train_lift_005': train_metrics[\"lift_005\"],\n",
    "                                'train_lift_05': train_metrics[\"lift_05\"],\n",
    "                                'val_loss': val_metrics[\"loss\"],\n",
    "                                'val_accuracy': val_metrics[\"accuracy\"],\n",
    "                                'val_auc': val_metrics[\"auc\"],\n",
    "                                'val_emp': val_metrics[\"emp\"],\n",
    "                                'val_lift_005': val_metrics[\"lift_005\"],\n",
    "                                'val_lift_05': val_metrics[\"lift_05\"]\n",
    "                            })\n",
    "                        \n",
    "                        # Track best model by both validation AUC and EMP\n",
    "                        improved = False\n",
    "                        \n",
    "                        if val_metrics[\"auc\"] > best_val_auc_for_config:\n",
    "                            best_val_auc_for_config = val_metrics[\"auc\"]\n",
    "                            improved = True\n",
    "                            \n",
    "                        if val_metrics[\"emp\"] > best_val_emp_for_config:\n",
    "                            best_val_emp_for_config = val_metrics[\"emp\"]\n",
    "                            improved = True\n",
    "                            \n",
    "                        if improved:\n",
    "                            best_val_loss = val_metrics[\"loss\"]\n",
    "                            best_epoch = epoch\n",
    "                            epochs_no_improve = 0\n",
    "                            \n",
    "                        else:\n",
    "                            epochs_no_improve += 1\n",
    "                            \n",
    "                        # Early stopping check\n",
    "                        if epochs_no_improve >= patience:\n",
    "                            print(f\"Early stopping at epoch {epoch}! Best epoch: {best_epoch}\")\n",
    "                            break\n",
    "    \n",
    "    # Print best hyperparameters\n",
    "    print(\"\\n=== Best Hyperparameters ===\")\n",
    "    print(f\"Learning Rate: {best_hyperparams['lr']}\")\n",
    "    print(f\"Hidden Channels: {best_hyperparams['hidden_channels']}\")\n",
    "    print(f\"Number of Layers: {best_hyperparams['layers']}\")\n",
    "    print(f\"Selected based on: {best_hyperparams.get('best_by', 'AUC')}\")\n",
    "    print(f\"Best Validation AUC: {best_hyperparams['val_auc']:.4f}\")\n",
    "    print(f\"Best Validation EMP: {best_hyperparams['val_emp']:.4f}\")\n",
    "    print(f\"Best Validation 0.5% Lift: {best_hyperparams['val_lift_005']:.4f}\")\n",
    "    print(f\"Best Validation 5% Lift: {best_hyperparams['val_lift_05']:.4f}\")\n",
    "    \n",
    "    # Test with best model\n",
    "    test_metrics = evaluate(best_model, data_test.to(device), criterion)\n",
    "    \n",
    "    print(\"\\n=== Test Performance ===\")\n",
    "    print(f\"Test Loss: {test_metrics['loss']:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Test AUC: {test_metrics['auc']:.4f}\")\n",
    "    print(f\"Test EMP: {test_metrics['emp']:.4f}\")\n",
    "    print(f\"Test 0.5% Lift: {test_metrics['lift_005']:.4f}\")\n",
    "    print(f\"Test 5% Lift: {test_metrics['lift_05']:.4f}\")\n",
    "    \n",
    "    # Write test results to CSV\n",
    "    test_results_filename = f\"gcn_test_results_{timestamp}.csv\"\n",
    "    with open(test_results_filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['lr', 'hidden_channels', 'layers', 'selection_criteria', 'test_loss', 'test_accuracy', \n",
    "                     'test_auc', 'test_emp', 'test_lift_005', 'test_lift_05']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerow({\n",
    "            'lr': best_hyperparams['lr'],\n",
    "            'hidden_channels': best_hyperparams['hidden_channels'],\n",
    "            'layers': best_hyperparams['layers'],\n",
    "            'selection_criteria': best_hyperparams.get('best_by', 'AUC'),\n",
    "            'test_loss': test_metrics['loss'],\n",
    "            'test_accuracy': test_metrics['accuracy'],\n",
    "            'test_auc': test_metrics['auc'],\n",
    "            'test_emp': test_metrics['emp'],\n",
    "            'test_lift_005': test_metrics['lift_005'],\n",
    "            'test_lift_05': test_metrics['lift_05']\n",
    "        })\n",
    "    \n",
    "    print(f\"Training results saved to: {csv_filename}\")\n",
    "    print(f\"Test results saved to: {test_results_filename}\")\n",
    "    \n",
    "    return best_model, best_hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Class imbalance weight: 5.9431902659718165\n",
      "\n",
      "Training with lr=0.01, hidden_channels=32, layers=1\n",
      "Epoch: 001, Train Loss: 0.8819, Val Loss: 0.9439, Val AUC: 0.5940, Val EMP: 0.0000, Val 0.5% Lift: 0.6353\n",
      "Epoch: 005, Train Loss: 0.8302, Val Loss: 0.9013, Val AUC: 0.6198, Val EMP: 0.0000, Val 0.5% Lift: 1.5047\n",
      "Epoch: 010, Train Loss: 0.7701, Val Loss: 0.8608, Val AUC: 0.6209, Val EMP: 0.0000, Val 0.5% Lift: 2.3072\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 115\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# Run the main training and hyperparameter tuning\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     best_model, best_hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# After training is done, analyze the results\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# (Uncomment this line after you have results to analyze)\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     best_configs \u001b[38;5;241m=\u001b[39m analyze_results(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgcn_results_YYYYMMDD_HHMMSS.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 12\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Run hyperparameter tuning\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m best_model, best_hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_model, best_hyperparams\n",
      "Cell \u001b[1;32mIn[43], line 42\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[1;34m(data_train, data_val, data_test, learning_rates, hidden_channels, layers, device, weight)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Train for a maximum of 200 epochs\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m201\u001b[39m):\n\u001b[1;32m---> 42\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;66;03m# Evaluate on training and validation sets\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         train_metrics \u001b[38;5;241m=\u001b[39m evaluate(model, data_train\u001b[38;5;241m.\u001b[39mto(device), criterion)\n",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data, optimizer, criterion)\u001b[0m\n\u001b[0;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[0;32m      5\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out\u001b[38;5;241m.\u001b[39msqueeze(), data\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m----> 6\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\guest\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guest\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\guest\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Hyperparameters to tune - using the specified parameters\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    hidden_channels = [32, 128, 256]\n",
    "    layers = [1, 3]\n",
    "    \n",
    "    # Run hyperparameter tuning\n",
    "    best_model, best_hyperparams = hyperparameter_tuning(\n",
    "        data_train, data_val, data_test, \n",
    "        learning_rates, hidden_channels, layers, \n",
    "        device, weight\n",
    "    )\n",
    "    \n",
    "    return best_model, best_hyperparams\n",
    "\n",
    "# Function to analyze and visualize results\n",
    "def analyze_results(results_file):\n",
    "    \"\"\"\n",
    "    Analyze hyperparameter tuning results and create visualizations\n",
    "    \n",
    "    Parameters:\n",
    "    - results_file: Path to the CSV file with training results\n",
    "    \"\"\"\n",
    "    results = pd.read_csv(results_file)\n",
    "    \n",
    "    # Create directory for plots\n",
    "    plots_dir = \"tuning_plots\"\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Plot validation metrics over epochs for each configuration\n",
    "    for lr in results['lr'].unique():\n",
    "        for hidden in results['hidden_channels'].unique():\n",
    "            for layer in results['layers'].unique():\n",
    "                subset = results[(results['lr'] == lr) & \n",
    "                                 (results['hidden_channels'] == hidden) & \n",
    "                                 (results['layers'] == layer)]\n",
    "                \n",
    "                if len(subset) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Skip if fewer than 3 data points\n",
    "                if len(subset) < 3:\n",
    "                    continue\n",
    "                \n",
    "                import matplotlib.pyplot as plt\n",
    "                \n",
    "                # Create plot\n",
    "                fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "                fig.suptitle(f'Metrics for lr={lr}, hidden={hidden}, layers={layer}')\n",
    "                \n",
    "                # Plot metrics\n",
    "                axs[0, 0].plot(subset['epoch'], subset['val_auc'], 'b-', label='Validation')\n",
    "                axs[0, 0].plot(subset['epoch'], subset['train_auc'], 'r--', label='Training')\n",
    "                axs[0, 0].set_title('AUC')\n",
    "                axs[0, 0].set_xlabel('Epoch')\n",
    "                axs[0, 0].set_ylabel('AUC')\n",
    "                axs[0, 0].legend()\n",
    "                \n",
    "                axs[0, 1].plot(subset['epoch'], subset['val_emp'], 'b-', label='Validation')\n",
    "                axs[0, 1].plot(subset['epoch'], subset['train_emp'], 'r--', label='Training')\n",
    "                axs[0, 1].set_title('EMP')\n",
    "                axs[0, 1].set_xlabel('Epoch')\n",
    "                axs[0, 1].set_ylabel('EMP')\n",
    "                axs[0, 1].legend()\n",
    "                \n",
    "                axs[1, 0].plot(subset['epoch'], subset['val_lift_005'], 'b-', label='Validation')\n",
    "                axs[1, 0].plot(subset['epoch'], subset['train_lift_005'], 'r--', label='Training')\n",
    "                axs[1, 0].set_title('0.5% Lift')\n",
    "                axs[1, 0].set_xlabel('Epoch')\n",
    "                axs[1, 0].set_ylabel('Lift')\n",
    "                axs[1, 0].legend()\n",
    "                \n",
    "                axs[1, 1].plot(subset['epoch'], subset['val_lift_05'], 'b-', label='Validation')\n",
    "                axs[1, 1].plot(subset['epoch'], subset['train_lift_05'], 'r--', label='Training')\n",
    "                axs[1, 1].set_title('5% Lift')\n",
    "                axs[1, 1].set_xlabel('Epoch')\n",
    "                axs[1, 1].set_ylabel('Lift')\n",
    "                axs[1, 1].legend()\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{plots_dir}/metrics_lr{lr}_hidden{hidden}_layers{layer}.png\")\n",
    "                plt.close()\n",
    "    \n",
    "    # Create summary plots for best configurations\n",
    "    best_configs = []\n",
    "    \n",
    "    # Find best config for each metric\n",
    "    metrics = ['val_auc', 'val_emp', 'val_lift_005', 'val_lift_05']\n",
    "    for metric in metrics:\n",
    "        # Group by hyperparameters and find maximum value for the metric\n",
    "        grouped = results.groupby(['lr', 'hidden_channels', 'layers'])[metric].max().reset_index()\n",
    "        best_config = grouped.loc[grouped[metric].idxmax()]\n",
    "        best_configs.append({\n",
    "            'metric': metric,\n",
    "            'lr': best_config['lr'],\n",
    "            'hidden_channels': best_config['hidden_channels'],\n",
    "            'layers': best_config['layers'],\n",
    "            'value': best_config[metric]\n",
    "        })\n",
    "    \n",
    "    # Print summary of best configurations\n",
    "    print(\"\\n=== Best Configurations by Metric ===\")\n",
    "    for config in best_configs:\n",
    "        print(f\"{config['metric']}: lr={config['lr']}, hidden={config['hidden_channels']}, layers={config['layers']}, value={config['value']:.4f}\")\n",
    "    \n",
    "    return best_configs\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the main training and hyperparameter tuning\n",
    "    best_model, best_hyperparams = main()\n",
    "    \n",
    "    # After training is done, analyze the results\n",
    "    # (Uncomment this line after you have results to analyze)\n",
    "    best_configs = analyze_results(\"gcn_results_YYYYMMDD_HHMMSS.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
